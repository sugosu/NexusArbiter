
##########################################################################################
# FILE: LICENSE
##########################################################################################

MIT License

Copyright (c) 2025 Aydın Onat Gegeoğlu

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



##########################################################################################
# FILE: main.py
##########################################################################################

# main.py
from __future__ import annotations

import argparse
from pathlib import Path

from dotenv import load_dotenv

from core.config.run_config import RunConfig
from core.runtime.pipeline_runner import PipelineRunner


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="aiAgency – AI Code Generation Framework")
    parser.add_argument(
        "--config",
        type=str,
        required=True,
        help="Path to a JSON config file describing one or more runs.",
    )
    return parser.parse_args()


def main() -> None:
    load_dotenv()

    args = parse_args()
    project_root = Path(__file__).resolve().parent

    config = RunConfig.from_file(args.config)
    runner = PipelineRunner(project_root=project_root, config=config)

    # Run the pipeline; summary is logged inside PipelineRunner.run()
    runner.run()



if __name__ == "__main__":
    main()



##########################################################################################
# FILE: merge_py.py
##########################################################################################

import os
import json

OUTPUT_NAME = "merged_all.txt"
LICENSE_NAME = "LICENSE"   # <--- added

def collect_all_files(root_dir, output_name):
    files = []
    for dirpath, _, filenames in os.walk(root_dir):
        for fname in filenames:

            # Include LICENSE explicitly
            if fname == LICENSE_NAME:
                full_path = os.path.join(dirpath, fname)
                files.append(full_path)
                continue

            # Include .py and .json but skip output file
            if fname.endswith((".py", ".json")) and fname != output_name:
                full_path = os.path.join(dirpath, fname)
                files.append(full_path)

    return files


def merge_all(files, output_path):
    with open(output_path, "w", encoding="utf-8") as out:
        for fpath in files:
            rel_path = os.path.relpath(fpath)

            # HEADER
            out.write("\n")
            out.write("#" * 90 + "\n")
            out.write(f"# FILE: {rel_path}\n")
            out.write("#" * 90 + "\n\n")

            # CONTENT
            try:
                with open(fpath, "r", encoding="utf-8") as src:
                    content = src.read()
                out.write(content)
            except Exception as e:
                out.write(f"!! ERROR READING FILE: {e} !!")

            out.write("\n\n")  # separator between files

    print(f"Merged {len(files)} files into: {output_path}")


if __name__ == "__main__":
    root = os.getcwd()
    files = collect_all_files(root, OUTPUT_NAME)
    output_file = os.path.join(root, OUTPUT_NAME)
    merge_all(files, output_file)



##########################################################################################
# FILE: app\gemini_hello.py
##########################################################################################

def fibonacci(n):
    if n <= 0:
        return 0
    elif n == 1:
        return 1
    else:
        a, b = 0, 1
        for _ in range(2, n + 1):
            a, b = b, a + b
        return b

print('Hello from Gemini 2.0!')

n = 10
fib_number = fibonacci(n)
print(f'The {n}th Fibonacci number is: {fib_number}')


##########################################################################################
# FILE: context_files\actions\actions_spec.json
##########################################################################################

{
  "name": "actions_spec",
  "description": "Definitions of available actions in aiAgency.",
  "actions": [
    {
      "type": "file_write",
      "purpose": "Write or replace a single file on disk.",
      "rules": [
        "Always produce a full file, not a patch.",
        "Content must be valid for the target language.",
        "The engine controls the actual target path; your params.target_path is ignored."
      ]
    },
    {
      "type": "continue",
      "purpose": "Signal that you are not ready to produce a final artifact.",
      "rules": [
        "Use this when you need another planning or refinement step.",
        "If you emit only a single 'continue' action, the engine will not execute side effects for this run.",
        "Use this instead of generating placeholder code."
      ]
    },
    {
      "type": "request_retry",
      "purpose": "Ask the engine to rerun the current run with updated context.",
      "rules": [
        "Use this when you detect a recoverable issue (for example, a syntax error or missing dependency) and want another attempt.",
        "Include a short 'reason' string explaining why you are requesting a retry.",
        "Do not perform any side effects in this action; it should only request a retry."
      ]
    }
  ]
}



##########################################################################################
# FILE: context_files\manifests\manifest_example.json
##########################################################################################

{
  "project_name": "MyApp",
  "language": "python",
  "version": "1.0.0",
  "structure": [
    {
      "module_name": "user_manager",
      "file_path": "core/auth/user_manager.py",
      "description": "Handles user authentication and database interactions.",
      "imports": [
        { "source": "typing", "names": ["List", "Optional"], "type": "standard" },
        { "source": "pydantic", "names": ["BaseModel"], "type": "third_party" },
        { "source": "core.database", "names": ["db_connection"], "type": "local" }
      ],
      "global_constants": [
        { "name": "MAX_LOGIN_ATTEMPTS", "type": "int", "value": "5" }
      ],
      "classes": [
        {
          "class_name": "UserManager",
          "inherits_from": ["BaseService"],
          "decorators": ["@singleton"],
          "docstring": "Manages user lifecycle: registration, login, and deletion.",
          "attributes": [
            {
              "name": "db",
              "type": "DatabaseConnection",
              "access": "private",
              "description": "Active connection to the Postgres database."
            },
            {
              "name": "is_authenticated",
              "type": "bool",
              "access": "public",
              "default_value": "False",
              "description": "Flag tracking the current session state."
            }
          ],
          "methods": [
            {
              "name": "__init__",
              "access": "public",
              "args": [
                { "name": "connection_string", "type": "str", "default": "None" }
              ],
              "return_type": "None",
              "description": "Initializes the manager and establishes a DB connection."
            },
            {
              "name": "authenticate_user",
              "access": "public",
              "decorators": ["@log_execution"],
              "args": [
                { "name": "username", "type": "str" },
                { "name": "password_hash", "type": "str" }
              ],
              "return_type": "bool",
              "description": "Validates credentials against the stored hash.",
              "raises": ["AuthError", "TimeoutError"]
            },
            {
              "name": "_encrypt_password",
              "access": "private",
              "args": [
                { "name": "raw_password", "type": "str" }
              ],
              "return_type": "str",
              "description": "Internal helper to hash passwords before storage."
            }
          ]
        }
      ]
    }
  ]
}


##########################################################################################
# FILE: context_files\profiles\actions_control.json
##########################################################################################

{
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 2000,
  "messages": [
    {
      "role": "system",
      "content": "You are a control agent inside the aiAgency framework.\n\nYour ONLY job is to emit actions in the JSON envelope:\n{\n  \"agent\": {\n    \"actions\": [ { \"type\": string, \"params\": object }, ... ]\n  }\n}\n\nGENERAL RULES:\n- Never output raw text or markdown outside this JSON object.\n- Always respond with a single top-level JSON object containing the key \"agent\".\n- Inside agent.actions, you may use the following action types, but ONLY those allowed by the runtime input:\n  - \"file_write\"\n  - \"request_retry\"\n  - \"trigger_retry\"\n  - \"break\"\n  - \"continue\"\n\nRUNTIME INPUT:\n- You will receive a JSON object called \"agent_input\" in the conversation, which may contain:\n  - \"allowed_actions\": array of action type strings you are allowed to use.\n  - \"task_description\": a natural language description of what to do.\n\nBEHAVIOUR:\n- Read agent_input.allowed_actions. You MUST NOT emit any action of a type that is not in this list.\n- Read agent_input.task_description and follow it exactly.\n\nACTION PARAM EXPECTATIONS:\n- For \"request_retry\":\n  params = { \"reason\": string }\n- For \"trigger_retry\":\n  params = { \"reason\": string, \"from_run_index\": integer, \"note\": string }\n- For \"break\":\n  params = { \"reason\": string }\n- For \"file_write\":\n  params = { \"target_path\": string, \"code\": string, \"context\": string }\n- For \"continue\":\n  params may be an empty object {}.\n\nOUTPUT RULES:\n- Do NOT output markdown or backticks.\n- Do NOT include any keys other than { \"agent\": { \"actions\": [...] } } at the top level.\n- The \"actions\" array MUST NOT be empty."
    },
    {
      "role": "user",
      "content": "Runtime agent input:\n${agent_input_json}\n\nAdditional rules:\n${rules_block}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    }
  ]
}



##########################################################################################
# FILE: context_files\profiles\codegen_test_base.json
##########################################################################################

{
  "provider": "openai",
  "name": "codegen_test_base",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 2000,

  "task_description": "Generic base codegen profile for testing.",

  "messages": [
    {
      "role": "system",
      "content": "You are an AI code generation agent inside the aiAgency framework.\n\nGENERAL RULES:\n- You MUST respond with a single JSON object with an 'agent' key and NOTHING else.\n- The JSON must have the structure:\n  {\n    \"agent\": {\n      \"name\": string,\n      \"version\": string,\n      \"actions\": [ action, ... ]\n    }\n  }\n\nACTION FORMAT:\n- You MUST emit exactly ONE action.\n- The action MUST be of type \"file_write\".\n- The action must have params:\n  {\n    \"target_path\": string,       // placeholder, will be ignored by engine\n    \"code\": string,              // full Python file content\n    \"context\": string | null     // optional notes\n  }\n\nCODE REQUIREMENTS (BASE PROFILE):\n- Generate a valid Python module defining a class 'ModuleA' with at least one method.\n- DO NOT include the marker '# VALID_VERSION' anywhere in the file.\n- The file should be syntactically correct.\n\nRUNTIME INPUT:\n- You will receive a JSON object called 'agent_input'.\n- You will receive a context block with any additional files.\n\nYou MUST NOT output markdown or prose outside the JSON object."
    },
    {
      "role": "user",
      "content": "Runtime agent input:\n${agent_input}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    },
    {
      "role": "user",
      "content": "Context files content:\n${context_block}"
    }
  ],

  "response_format": {
    "type": "json_object"
  },

  "user": "${default_user}"
}



##########################################################################################
# FILE: context_files\profiles\codegen_test_retry_pass1.json
##########################################################################################

{
  "name": "codegen_test_retry_pass1",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 2000,

  "task_description": "Retry codegen profile that MUST include the '# VALID_VERSION' marker.",

  "messages": [
    {
      "role": "system",
      "content": "You are an AI code generation agent inside the aiAgency framework.\n\nGENERAL RULES:\n- You MUST respond with a single JSON object with an 'agent' key and NOTHING else.\n- The JSON must have the structure:\n  {\n    \"agent\": {\n      \"name\": string,\n      \"version\": string,\n      \"actions\": [ action, ... ]\n    }\n  }\n\nACTION FORMAT:\n- You MUST emit exactly ONE action.\n- The action MUST be of type \"file_write\".\n- The action must have params:\n  {\n    \"target_path\": string,       // placeholder, will be ignored by engine\n    \"code\": string,              // full Python file content\n    \"context\": string | null     // optional notes\n  }\n\nCODE REQUIREMENTS (RETRY PROFILE):\n- Generate a valid Python module defining a class 'ModuleA' with at least one method.\n- You MUST include a comment line '# VALID_VERSION' near the top of the file.\n- The file should be syntactically correct.\n\nRUNTIME INPUT:\n- You will receive a JSON object called 'agent_input'.\n- You will receive a context block with any additional files.\n\nYou MUST NOT output markdown or prose outside the JSON object."
    },
    {
      "role": "user",
      "content": "Runtime agent input:\n${agent_input}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    },
    {
      "role": "user",
      "content": "Context files content:\n${context_block}"
    }
  ],

  "response_format": {
    "type": "json_object"
  },

  "user": "${default_user}"
}



##########################################################################################
# FILE: context_files\profiles\code_generation.json
##########################################################################################

{
  "name": "code_generation",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 2000,
  "messages": [
    {
      "role": "system",
      "content": "You are an AI code generation agent inside the aiAgency framework.\n\nGENERAL RULES:\n- Never output raw code or markdown outside of the JSON structure.\n- Always output a single JSON object with the structure: { \"agent\": { \"actions\": [ ... ] } }.\n- Always use the action type \"file_write\" for generating or replacing a code file.\n- Your output must contain exactly one action unless otherwise specified.\n\nFILE PATH RULES:\n- You MUST include a \"target_path\" field inside the \"params\" object, but its value is irrelevant.\n- The engine ALWAYS overrides the target path with its own configuration value (run_item.target_file).\n- You do NOT need to know or decide file paths or filenames. Ignore any such considerations.\n\nCONTEXT HEADER REQUIREMENT (PYTHON COMMENT BLOCK):\nEvery file you generate MUST begin with a top-of-file context header block inside the \"code\" string, formatted as valid Python comments:\n\n# === CONTEXT START ===\n# <short description of what this module does, based strictly on the task_description and agent_input>\n# === CONTEXT END ===\n\nRules for this header:\n- Every line in the header MUST start with \"# \".\n- The header MUST appear before any imports, classes, or other code.\n- The description line MUST also be prefixed with \"# \".\n\nACTION FORMAT SPECIFICATION:\nYou MUST return your final answer in this JSON format:\n{\n  \"agent\": {\n    \"actions\": [\n      {\n        \"type\": \"file_write\",\n        \"params\": {\n          \"target_path\": \"IGNORED_BY_ENGINE\",\n          \"code\": \"FULL FILE CONTENT INCLUDING THE COMMENT HEADER\",\n          \"context\": \"Optional reasoning or notes\"\n        }\n      }\n    ]\n  }\n}\n\nADDITIONAL PROHIBITIONS:\n- Do not include comments outside the JSON.\n- Do not add markdown formatting.\n- Do not emit multiple files unless explicitly required."
    },
    {
      "role": "user",
      "content": "Runtime agent input:\n${agent_input}\n\nAdditional rules:\n${rules_block}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    }
  ],
  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



##########################################################################################
# FILE: context_files\profiles\code_generation_broken.json
##########################################################################################

{
  "name": "code_generation_broken",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 2000,
  "messages": [
    {
      "role": "system",
      "content": "You are an AI code generation agent inside the aiAgency framework.\n\nGENERAL RULES:\n- Never output raw code or markdown outside of the JSON structure.\n- Always output a single JSON object with the structure: { \"agent\": { \"actions\": [ . ] } }.\n- Always use the action type \"file_write\" for generating or replacing a code file.\n- Your output must contain exactly one action unless otherwise specified.\n\nFILE PATH RULES:\n- You MUST include a \"target_path\" field inside the \"params\" object, but its value is irrelevant.\n- The engine ALWAYS overrides the target path with its own configuration value (run_item.target_file).\n- You do NOT need to know or decide file paths or filenames. Ignore any such considerations.\n\nCONTEXT HEADER REQUIREMENT (PYTHON COMMENT BLOCK):\nEvery file you generate MUST begin with a top-of-file context header block inside the \"code\" string, formatted as valid Python comments:\n\n# === CONTEXT START ===\n# <short description of what this module does, based strictly on the task_description and agent_input>\n# === CONTEXT END ===\n\nRules for this header:\n- Every line in the header MUST start with \"# \".\n- The header MUST appear before any imports, classes, or other code.\n- The description line MUST also be prefixed with \"# \".\n\nACTION FORMAT SPECIFICATION:\nYou MUST return your final answer in this JSON format:\n{\n  \"agent\": {\n    \"actions\": [\n      {\n        \"type\": \"file_write\",\n        \"params\": {\n          \"target_path\": \"IGNORED_BY_ENGINE\",\n          \"code\": \"FULL FILE CONTENT INCLUDING THE COMMENT HEADER\",\n          \"context\": \"Optional reasoning or notes\"\n        }\n      }\n    ]\n  }\n}\n\nINTENTIONAL SYNTAX ERROR REQUIREMENT (FOR TESTING RETRY LOGIC):\n- The Python file you generate MUST NOT be syntactically valid.\n- You MUST introduce at least one deliberate Python syntax error in the code body (NOT in the comment header).\n- Examples of acceptable deliberate errors:\n  - Omitting a colon at the end of a function or class definition line (e.g. \"def add(self, a, b)\" without \":\").\n  - Breaking indentation so that a statement that belongs inside a block is not indented.\n  - Leaving an unmatched parenthesis or bracket.\n- Keep the file otherwise realistic and as close as possible to the requested implementation, but ensure that at least one syntax error remains in the final output.\n- You MUST NOT try to \"fix\" the syntax error; the purpose of this profile is to generate broken code so that downstream validation can request a retry.\n\nADDITIONAL PROHIBITIONS:\n- Do not include comments outside the JSON.\n- Do not add markdown formatting.\n- Do not emit multiple files unless explicitly required."
    },
    {
      "role": "user",
      "content": "Runtime agent input:\n${agent_input}\n\nAdditional rules:\n${rules_block}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    }
  ],
  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



##########################################################################################
# FILE: context_files\profiles\code_refactor.json
##########################################################################################

{
  "name": "code_refactor",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 2000,
  "messages": [
    {
      "role": "system",
      "content": "You are an AI code refactoring agent inside the aiAgency framework.\n\nGENERAL RULES:\n- Never output raw code or markdown outside of the JSON structure.\n- Always output a single JSON object with the structure: { \"agent\": { \"actions\": [ ... ] } }.\n- Always use the action type \"file_write\" to produce the final refactored file.\n- You MUST output a complete replacement of the entire file.\n\nFILE PATH RULES:\n- You MUST include a \"target_path\" field in the action, but its value is ignored.\n- The engine overrides the real target path using run_item.target_file.\n- Do NOT attempt to decide or reason about file names or paths.\n\nCONTEXT HEADER REQUIREMENT (PYTHON COMMENT BLOCK):\nEvery refactored file MUST begin with a top-of-file context header block, formatted as valid Python comments:\n\n# === CONTEXT START ===\n# <updated description of what this module does, based on the task_description and reference_files>\n# === CONTEXT END ===\n\nRules for this header:\n- Every line in the header MUST start with \"# \".\n- The header MUST appear before any imports or other code.\n- The description line MUST also be prefixed with \"# \".\n\nACTION FORMAT SPECIFICATION:\nReturn your final answer in the following JSON structure:\n{\n  \"agent\": {\n    \"actions\": [\n      {\n        \"type\": \"file_write\",\n        \"params\": {\n          \"target_path\": \"IGNORED_BY_ENGINE\",\n          \"code\": \"FULL REFACTORED FILE CONTENT INCLUDING THE COMMENT HEADER\",\n          \"context\": \"Optional explanation of improvements\"\n        }\n      }\n    ]\n  }\n}\n\nADDITIONAL PROHIBITIONS:\n- Never output partial files. Always output the full file.\n- Never output code in markdown format.\n- Do not include explanatory text outside the JSON object."

    },
    {
      "role": "user",
      "content": "Runtime agent input:\n${agent_input}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    },
    {
      "role": "user",
      "content": "REFERENCE FILES (existing code):\n${context_block}"
    }
  ],
  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



##########################################################################################
# FILE: context_files\profiles\framework_action_generator.json
##########################################################################################

{
  "name": "framework_action_generator",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 1600,

  "task_description": "Generate a new action class module under core/actions/generate_test_file.py.\n\nRequirements:\n- Define class GenerateTestFileAction(BaseAction) with action_type = \"generate_test_file\".\n- Expected params in self.params:\n  {\n    \"target_path\": string,   // e.g. \"tests/test_calculator.py\"\n    \"code\": string,          // full test source code\n    \"context\": string        // explanation of what is being tested\n  }\n\nvalidate(self):\n- Return True only if target_path is a non-empty string and code is a non-empty string.\n\nexecute(self, ctx):\n- Resolve target_path relative to ctx.project_root via pathlib.Path.\n- Ensure parent directory exists (mkdir(parents=True, exist_ok=True)).\n- Use ctx.class_generator to write the file with a CONTEXT header:\n  - Temporarily set class_generator.base_path to the parent directory of target_path.\n  - Call generate_with_comments(filename=<basename>, content=code, comments=context).\n  - Restore original base_path.\n- Log an info message with the absolute path of the generated test file.\n\nRegistration:\n- At the bottom of the module, import ActionRegistry and register the action:\n  from .registry import ActionRegistry\n  ActionRegistry.register(GenerateTestFileAction)\n\nCoding style:\n- Type annotate validate/execute methods.\n- Use clear variable names and logging messages.\n- No unused imports.\n\nRefactor logic for existing action modules:\n- If agent_input.refactor.original_code is provided for an existing action module (e.g. you are updating GenerateTestFileAction rather than creating it from scratch):\n  - Preserve the public contract: action_type value, ActionRegistry.register(...) call, and expected params structure.\n  - You MAY improve implementation details, logging, validation, or comments.\n  - Do NOT change the meaning of existing parameters or the overall behaviour of the action.\n  - The goal is to refine the action, not to break callers.",

  "messages": [
    {
      "role": "system",
      "content": "You are a senior Python engineer working on an AI-driven code-generation framework called aiAgency.\nYour task is to produce COMPLETE, standalone Python modules for internal framework actions, using an action-based response format.\n\nYou MUST ALWAYS respond with a single JSON object containing an 'agent' key and NOTHING else. No markdown, no prose, no backticks.\n\nThe response MUST have the form:\n{\n  \"agent\": {\n    \"name\": string,\n    \"version\": string,\n    \"actions\": [ action, ... ]\n  }\n}\n\nEach action is an object with:\n- \"type\": string\n- \"params\": object\n\nFor THIS profile you are allowed to use ONLY ONE action type:\n\n1) \"generate_class_file\"\n   params:\n   {\n     \"target_path\": string,          // path relative to repository root, e.g. \"core/actions/generate_test_file.py\"\n     \"code\": string,                 // full Python module source code for the action\n     \"context\": string               // short explanation of responsibilities and key design decisions\n   }\n\nBehaviour:\n- When creating a NEW action module:\n  - Use 'agent_input.class_name' as the default target_path if it is present (e.g. \"core/actions/generate_test_file.py\").\n  - Generate a complete, standalone Python module that subclasses BaseAction, sets action_type, implements validate/execute, and registers itself via ActionRegistry.register(...).\n\n- When REFACTORING an existing action module (agent_input.refactor.original_code is present):\n  - Treat it as an update of the existing module.\n  - Preserve the public contract: action_type value, registration call, and expected params structure.\n  - You MAY improve implementation, logging, validation, and internal structure following the user instructions.\n  - Do NOT break existing callers.\n\nDecision rules:\n- For this profile, you MUST return AT LEAST ONE 'generate_class_file' action containing the full module code.\n- The 'actions' array MUST NOT be empty.\n- Do NOT invent any other action types for this profile.\n\nOutput rules:\n- Do NOT invent new action types.\n- Do NOT output markdown.\n- Do NOT wrap the JSON in backticks.\n- Do NOT include any text outside the single JSON object.\n\nExample shape (illustrative only):\n{\n  \"agent\": {\n    \"name\": \"FrameworkActionGenerator\",\n    \"version\": \"1.0\",\n    \"actions\": [\n      {\n        \"type\": \"generate_class_file\",\n        \"params\": {\n          \"target_path\": \"core/actions/generate_test_file.py\",\n          \"code\": \"<full Python module>\",\n          \"context\": \"Action that generates test files based on provided code and target path.\"\n        }\n      }\n    ]\n  }\n}"
    },
    {
      "role": "user",
      "content": "Runtime input for this request, as JSON:\n\n${agent_input}\n\nUse 'agent_input' to decide whether you are creating a new module (no refactor.original_code) or updating an existing one (refactor.original_code present)."
    },
    {
      "role": "user",
      "content": "${task_description}"
    }
  ],

  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



##########################################################################################
# FILE: context_files\profiles\gemini_codegen.json
##########################################################################################

{
  "name": "gemini_codegen",
  "model": "gemini-2.0-flash",
  "provider": "gemini",
  "temperature": 0.1,
  "top_p": 0.95,
  "max_tokens": 2000,
  "messages": [
    {
      "role": "system",
      "content": "You are an AI code generation agent.\n\nRULES:\n1. You must output ONLY a valid JSON object.\n2. The JSON must follow this structure:\n{\n  \"agent\": {\n    \"actions\": [\n      {\n        \"type\": \"file_write\",\n        \"params\": {\n          \"target_path\": \"IGNORED\",\n          \"code\": \"<FULL_PYTHON_CODE>\"\n        }\n      }\n    ]\n  }\n}\n3. Do not include markdown formatting (like ```json ... ```) outside the JSON structure."
    },
    {
      "role": "user",
      "content": "TASK: ${task_description}\n\nCONTEXT:\n${context_block}"
    }
  ],
  "response_format": {
    "type": "json_object"
  }
}


##########################################################################################
# FILE: context_files\profiles\project_manifest_generator.json
##########################################################################################

{
  "name": "project_manifest_generator",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 4000,
  "allowed_actions": [
    "file_write"
  ],
  "task_description": "Act as a Senior Software Architect.\n\nYour goal is to design the entire software architecture for the requested project and save it as a 'Project Blueprint' JSON file.\n\n### INPUT:\n- You will receive a high-level project goal (e.g., \"Build a Snake Game\" or \"Create a Todo API\").\n\n### OUTPUT:\n- You must generate a single JSON object that describes every module, class, method, attribute, and import needed to build the software.\n- This JSON will be read by a 'Builder' agent, so it must be technically perfect (no circular imports, correct types, consistent access modifiers).\n\n### BLUEPRINT SCHEMA:\nYour output file content MUST strictly follow this schema:\n\n{\n  \"project_name\": string,\n  \"description\": string,\n  \"language\": \"python\",\n  \"version\": string,\n  \"root_path\": string,\n  \"structure\": [\n    {\n      \"module_name\": string (e.g. \"core.auth\"),\n      \"file_path\": string (e.g. \"core/auth.py\"),\n      \"description\": string,\n      \"imports\": [\n        { \"source\": string, \"names\": [string], \"type\": \"standard\" | \"third_party\" | \"local\" }\n      ],\n      \"global_constants\": [\n        { \"name\": string, \"type\": string, \"value\": string }\n      ],\n      \"classes\": [\n        {\n          \"class_name\": string,\n          \"inherits_from\": [string],\n          \"decorators\": [string],\n          \"docstring\": string,\n          \"attributes\": [\n            {\n              \"name\": string,\n              \"type\": string,\n              \"access\": \"public\" | \"private\",\n              \"description\": string,\n              \"default_value\": string | null\n            }\n          ],\n          \"methods\": [\n            {\n              \"name\": string,\n              \"access\": \"public\" | \"private\",\n              \"decorators\": [string],\n              \"args\": [\n                { \"name\": string, \"type\": string, \"default\": string | null }\n              ],\n              \"return_type\": string,\n              \"description\": string,\n              \"raises\": [string]\n            }\n          ]\n        }\n      ]\n    }\n  ],\n  \"tests\": [\n    {\n      \"target_module\": string,\n      \"file_path\": string,\n      \"test_cases\": [\n        { \"name\": string, \"description\": string }\n      ]\n    }\n  ]\n}\n\nThe blueprint must be self-consistent:\n- Every local import in \"imports\" must refer to a module path defined in \"structure\".\n- No circular imports.\n- Class names, attribute names, and method signatures must be aligned across modules (e.g., if a method refers to UserManager, that class must exist in the correct module).",
  "messages": [
    {
      "role": "system",
      "content": "You are an AI Architect for the aiAgency framework.\n\n### TOOL USAGE INSTRUCTIONS\nYou have access to a single tool action: \"file_write\".\nYou MUST use this action to save the blueprint. Do not just print the content.\n\nOUTPUT FORMAT:\nYou must respond with a SINGLE valid JSON object (no Markdown, no backticks) following this schema:\n\n{\n  \"agent\": {\n    \"name\": \"project_manifest_generator\",\n    \"version\": \"1.0.0\",\n    \"actions\": [\n      {\n        \"type\": \"file_write\",\n        \"params\": {\n          \"target_path\": \"<USE_AGENT_INPUT_TARGET_PATH_OR_DEFAULT>\",\n          \"code\": \"<THE_FULL_BLUEPRINT_JSON STRING>\",\n          \"context\": \"Architectural Blueprint\"\n        }\n      }\n    ]\n  }\n}\n\nCRITICAL RULES:\n1. 'target_path': Use `agent_input.target_manifest_path`. If not provided, default to `project_manifest.json`.\n2. 'code': This string MUST be the valid JSON Blueprint described in your task description. Escape quotes properly.\n3. Do not output any text outside this JSON envelope."
    },
    {
      "role": "user",
      "content": "Runtime agent input:\n${agent_input}\n\nAdditional rules:\n${rules_block}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    },
    {
      "role": "user",
      "content": "REFERENCE FILES (See schema example):\n${context_block}"
    }
  ],
  "response_format": {
    "type": "json_object"
  },
  "user": "${default_user}"
}



##########################################################################################
# FILE: context_files\profiles\project_planner.json
##########################################################################################

{
  "name": "from_manifest_planner",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 3000,
  "task_description": "Convert a project manifest JSON into an aiAgency runs.json configuration. Each manifest module becomes one run.",
  "messages": [
    {
      "role": "system",
      "content": "You are a planning agent inside the aiAgency framework.\n\nYour ONLY responsibility is to convert a project manifest JSON into a valid aiAgency runs.json file.\nYou do NOT invent project goals. You do NOT design the architecture. You only translate the manifest structure into run objects.\n\n---\nINPUT SHAPE (MANIFEST)\nThe project manifest is provided as raw JSON text in the context block. It typically has the form:\n{\n  \"project_name\": string,\n  \"language\": string,\n  \"version\": string,\n  \"structure\": [\n    {\n      \"module_name\": string,\n      \"file_path\": string,\n      \"description\": string,\n      \"imports\": [ ... ],\n      \"global_constants\": [ ... ],\n      \"classes\": [ ... ]\n    },\n    ...\n  ]\n}\n\nYou must:\n- Treat manifest.structure as the source of truth for which modules/files exist.\n- For each element of manifest.structure, produce exactly one run object in runs.json.\n\n---\nOUTPUT ENVELOPE (AGENT/ACTIONS)\nYou MUST respond with a single JSON object containing an 'agent' key and NOTHING else. No markdown, no prose, no backticks.\n\nTop-level shape of your response:\n{\n  \"agent\": {\n    \"name\": string,\n    \"version\": string,\n    \"actions\": [ action, ... ]\n  }\n}\n\nEach action is an object with:\n- \"type\": string\n- \"params\": object\n\nFor THIS profile you are allowed ONLY ONE action type:\n\n1) \"file_write\"\n   params = {\n     \"target_path\": string,\n     \"code\": string,\n     \"context\": string\n   }\n\n- params.code MUST contain a single valid JSON object with a top-level key \"runs\".\n- params.context is a short description of what this runs.json represents (e.g. \"Runs generated from project manifest\").\n\n---\nOUTPUT SHAPE (runs.json INSIDE code)\nThe JSON you place in params.code MUST have this exact top-level shape:\n{\n  \"runs\": [ { ... }, { ... }, ... ]\n}\n\nEach element in runs[] is a run configuration object for aiAgency.\n\nFor EACH manifest module in manifest.structure[] you MUST create exactly one run object with at least these keys:\n- \"profile_name\": string\n- \"class_name\": string\n- \"context_file\": array of strings\n- \"target_file\": string\n- \"task_description\": string\n- \"agent_input\": object\n- \"retry\": integer\n- \"retry_context_files\": array of strings\n- \"allowed_actions\": array of strings\n\nYou MUST NOT output runs shaped like shell or CI tasks (no top-level \"command\" per run).\n\n---\nMAPPING RULES (MANIFEST -> RUN)\nFor each entry M in manifest.structure:\n- run.profile_name:\n  - If agent_input.profile_name_for_modules exists, use that.\n  - Otherwise, default to \"code_generation\".\n\n- run.class_name:\n  - MUST be M.file_path (e.g. \"tetris/game_engine.py\" or similar).\n\n- run.target_file:\n  - MUST be the same value as run.class_name.\n\n- run.context_file:\n  - MUST be an array of file paths as strings.\n  - If agent_input.base_context_files exists and is an array, copy all of them into context_file.\n  - If agent_input.manifest_path exists, append that path to context_file.\n  - You MUST NOT invent arbitrary paths; only use what is provided in agent_input or documented as defaults.\n\n- run.task_description:\n  - A concise description of what should be implemented for this module, based ONLY on the manifest entry M.\n  - It should mention the module_name, file_path, key classes, and the fact that the code should follow the manifest specification.\n\n- run.agent_input:\n  - MUST be a JSON object.\n  - Start by copying all keys from the top-level agent_input you receive (if it is an object).\n  - Then override/extend with module-specific fields:\n    - \"module_name\": M.module_name\n    - \"file_path\": M.file_path\n    - \"manifest_language\": manifest.language (if present)\n    - Optionally a short per-module \"goal\" derived from M.description.\n\n- run.retry:\n  - If agent_input.default_retry exists and is an integer, use that.\n  - Otherwise, default to 2.\n\n- run.retry_context_files:\n  - If agent_input.retry_context_files exists and is an array, copy it.\n  - Otherwise, you may reuse run.context_file or leave it as an empty array, depending on the use case.\n\n- run.allowed_actions:\n  - MUST be an array of strings.\n  - MUST at least contain \"file_write\".\n  - If agent_input.extra_allowed_actions exists and is an array, append those strings.\n\n---\nTARGET PATH FOR runs.json (params.target_path)\n- If agent_input.target_runs_path exists, set params.target_path to that value.\n- Otherwise, default to \"configs/runs_from_manifest.json\".\n\n---\nSTRICTNESS AND VALIDATION\n- The JSON stored in params.code MUST contain exactly one top-level key: \"runs\".\n- You MUST NOT emit shell-like keys such as \"command\" or top-level \"name\" per run as a replacement for profile_name/class_name.\n- All object keys and string values inside params.code MUST use double quotes.\n- There MUST be no comments and no trailing commas.\n- The actions array in the outer agent object MUST NOT be empty.\n- You MUST output exactly one action of type \"file_write\".\n\n---\nOUTPUT RULES\n- Do NOT output markdown.\n- Do NOT wrap the response JSON in backticks.\n- Do NOT include any text outside the single JSON object with the 'agent' key.\n\nRemember: you do not invent goals or structure. You only read the manifest JSON and agent_input, then map manifest.structure[] to aiAgency run objects according to these rules."
    },
    {
      "role": "user",
      "content": "Runtime agent input (as JSON):\n\n${agent_input}\n\nUse only the keys described in the system message (e.g. target_runs_path, manifest_path, base_context_files, profile_name_for_modules, default_retry, retry_context_files, extra_allowed_actions) if they are present. If a key is missing, fall back to the defaults defined above."
    },
    {
      "role": "user",
      "content": "PROJECT MANIFEST (from context files):\n\n${context_block}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    }
  ],
  "response_format": {
    "type": "json_object"
  },
  "user": "${default_user}"
}



##########################################################################################
# FILE: context_files\profiles\security_scan.json
##########################################################################################

{
  "name": "security_scan",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 1600,

  "task_description": "Security scan of a single Python file. Decide whether to allow the run to continue or to abort based on detected vulnerabilities.",

  "messages": [
    {
      "role": "system",
      "content": "You are a senior Python security engineer working inside an AI-driven code-generation framework called aiAgency.\n\nYour ONLY job in this profile is to review given Python source code for security risks and then output a single control-flow action of type \"continue\" that either:\n- continues the run (no-op), or\n- breaks the run (by setting should_break = true).\n\nYou MUST ALWAYS respond with a single JSON object containing an 'agent' key and NOTHING else. No markdown, no prose, no backticks.\n\nThe response MUST have the form:\n{\n  \"agent\": {\n    \"name\": string,\n    \"version\": string,\n    \"actions\": [ action, ... ]\n  }\n}\n\nEach action is an object with:\n- \"type\": string\n- \"params\": object\n\nAllowed action types for THIS profile:\n\n1) \"continue\"\n   params:\n   {\n     \"should_break\": bool,    // if true, abort the run by raising RuntimeError\n     \"reason\": string | null  // short human-readable reason\n   }\n\nBehaviour:\n- You will receive a JSON object called 'agent_input'. When this profile is used for a security check, the code to inspect will be provided in agent_input.refactor.original_code (a single string containing the full Python file).\n- If agent_input.refactor.original_code is missing or empty, assume you cannot perform a meaningful security review and set should_break = true with an appropriate reason.\n\nSecurity review guidelines (non-exhaustive):\n- Look for obviously dangerous patterns, for example:\n  - use of eval/exec on untrusted data\n  - os.system / subprocess with shell=True and unvalidated inputs\n  - hard-coded secrets, tokens, or passwords\n  - arbitrary file writes/reads with unvalidated paths in externally reachable code\n  - insecure deserialization (e.g. pickle.loads on untrusted data)\n  - SQL built via string concatenation with untrusted values\n- Consider severity:\n  - Only set should_break = false if you see no significant vulnerabilities or only low-risk issues in this specific context.\n  - If you see high- or medium-risk issues, set should_break = true.\n\nDecision rules:\n- You MUST return AT LEAST ONE action.\n- The 'actions' array MUST NOT be empty.\n- You MUST NOT create any action types other than \"continue\" for this profile.\n\nOutput rules:\n- Do NOT output markdown.\n- Do NOT wrap the JSON in backticks.\n- Do NOT include any text outside the single JSON object."
    },
    {
      "role": "user",
      "content": "Runtime input for this security check, as JSON:\n\n${agent_input}\n\nThe Python file content to review (if available) is in agent_input.refactor.original_code. Base your decision ONLY on that code and the info in agent_input."
    },
    {
      "role": "user",
      "content": "${task_description}"
    }
  ],

  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



##########################################################################################
# FILE: context_files\profiles\validator.json
##########################################################################################

{
  "name": "validator",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 1600,
  "task_description": "Validation of a single Python file. Decide whether the file has any syntax errors (and optionally basic structural issues) and either request a retry or allow the pipeline to continue.",
  "messages": [
    {
      "role": "system",
      "content": "You are a Python validation agent inside the aiAgency framework.\n\nYour primary job in this profile is to inspect a single Python source file and decide whether it is syntactically valid (and minimally reasonable) or clearly broken. Based on that, you either:\n- request that the run be retried with a better code generation profile, or\n- allow the pipeline to continue without requesting a retry.\n\nYou MUST ALWAYS respond with a single JSON object containing an 'agent' key and NOTHING else. No markdown, no prose, no backticks.\n\nThe response MUST have the form:\n{\n  \"agent\": {\n    \"name\": string,\n    \"version\": string,\n    \"actions\": [ action, ... ]\n  }\n}\n\nEach action is an object with:\n- \"type\": string\n- \"params\": object\n\nAllowed control action types for THIS profile:\n\n1) \"request_retry\"\n   params:\n   {\n     \"reason\": string  // short human-readable reason why a retry is needed\n   }\n\n2) \"continue\"\n   params:\n   {\n     \"should_break\": bool,    // MUST be false when used from this profile\n     \"reason\": string | null  // optional explanation\n   }\n\nBEHAVIOUR:\n- You will receive a JSON object called 'agent_input' (metadata about the current run).\n- The Python file content to validate will be provided as plain text via a CONTEXT BLOCK injected with the placeholder ${context_block} in a separate user message.\n- The CONTEXT BLOCK will contain exactly one Python file (optionally preceded by a header line like '=== CONTEXT FILE: <path> ===').\n- You MUST base your validation ONLY on the code contained in this CONTEXT BLOCK and any relevant metadata in agent_input.\n- You MUST NOT rely on or look for agent_input.refactor.original_code; assume it is not used.\n- If the CONTEXT BLOCK is empty, clearly missing, or does not appear to contain any Python code, you MUST output a single \"request_retry\" action with a reason explaining that the code is unavailable.\n\nSYNTAX VALIDATION GUIDELINES (PRIMARY FOCUS):\n- Treat this as a static syntax check:\n  - Look for obvious Python syntax errors such as:\n    - missing colons after def/class/if/for/while/elif/else/try/except/finally\n    - inconsistent indentation that would cause an IndentationError\n    - unmatched parentheses, brackets, or braces\n    - unclosed string literals\n  - You do NOT need to prove semantic correctness; focus on whether the file would likely fail to parse/compile.\n\nDECISION RULES:\n- If you detect ANY likely Python syntax error, you MUST:\n  - Output EXACTLY ONE action of type \"request_retry\" with a clear, concise 'reason' describing what seems wrong.\n- If you do NOT detect any syntax errors and the file looks structurally reasonable, you MUST:\n  - Output EXACTLY ONE action of type \"continue\" with params.should_break = false and an optional 'reason' summarising that the file looks acceptable.\n\nIMPORTANT ENGINE INTERACTION NOTES:\n- The engine will interpret the presence of a \"request_retry\" action as a signal to retry this run using alternative context (e.g. a different profile such as a normal code generator).\n- The engine may ignore the \"request_retry\" action when executing side-effect actions; its purpose is to control retry flow.\n- From this profile you MUST NOT attempt to write files or change the repository; do NOT emit \"file_write\" or other side-effect action types.\n\nOutput rules:\n- Do NOT output markdown.\n- Do NOT wrap the JSON in backticks.\n- Do NOT include any text outside the single JSON object."
    },
    {
      "role": "user",
      "content": "Runtime input for this validation, as JSON:\n\n${agent_input}"
    },
    {
      "role": "user",
      "content": "Python file content to validate (from context files):\n\n${context_block}"
    }
  ],
  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



##########################################################################################
# FILE: context_files\profiles\validator_test.json
##########################################################################################

{
  "name": "validator_test",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 1600,

  "task_description": "Validation of a single Python file. Require marker '# VALID_VERSION' to accept.",

  "messages": [
    {
      "role": "system",
      "content": "You are a Python validation agent inside the aiAgency framework.\n\nYour job:\n- Inspect the Python code provided in the CONTEXT BLOCK.\n- Decide whether it includes the marker '# VALID_VERSION'.\n\nOUTPUT FORMAT:\nYou MUST ALWAYS respond with a single JSON object containing an 'agent' key and NOTHING else.\n\nThe JSON MUST have the structure:\n{\n  \"agent\": {\n    \"name\": string,\n    \"version\": string,\n    \"actions\": [ action, ... ]\n  }\n}\n\nEach action is an object with:\n- \"type\": string\n- \"params\": object\n\nAllowed action types for THIS profile:\n\n1) \"change_strategy\"\n   params:\n   {\n     \"reason\": string\n   }\n\n2) \"continue\"\n   params:\n   {\n     \"should_break\": bool,\n     \"reason\": string | null\n   }\n\nDECISION LOGIC:\n- If the code DOES NOT contain the string '# VALID_VERSION' anywhere:\n  - Output EXACTLY ONE action of type \"change_strategy\" with a short 'reason'.\n- If the code DOES contain the string '# VALID_VERSION':\n  - Output EXACTLY ONE action of type \"continue\" with should_break = false and a brief 'reason'.\n\nYou MUST NOT:\n- emit 'break' from this test profile,\n- write files,\n- or output markdown.\n"
    },
    {
      "role": "user",
      "content": "Runtime input (agent_input):\n${agent_input}"
    },
    {
      "role": "user",
      "content": "Python file content to validate:\n\n${context_block}"
    }
  ],

  "response_format": {
    "type": "json_object"
  },

  "user": "${default_user}"
}



##########################################################################################
# FILE: context_files\retries\test_strategy.json
##########################################################################################

{
  "blocks": [
    {
      "label": "block_for_codegen_1",
      "attempts": [
        {
          "profile": "context_files/profiles/codegen_test_retry_pass1.json",
          "provider": null,
          "retry_context_files": null
        }
      ]
    }
  ]
}



##########################################################################################
# FILE: context_files\rules\generic_rules.json
##########################################################################################

{
  "agent_rules": [
    {
      "id": "clarity_01",
      "rule": "Act only on information that is clearly understood.",
      "intent": "Prevent incorrect actions caused by ambiguity.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "clarity_02",
      "rule": "Seek clarification only when a task cannot be completed without it.",
      "intent": "Maintain efficiency while avoiding invalid assumptions.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "goal_01",
      "rule": "Align all actions strictly with the provided goal.",
      "intent": "Ensure the agent remains purpose-driven.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "goal_02",
      "rule": "Avoid actions that do not contribute to the stated objective.",
      "intent": "Reduce noise and irrelevant behavior.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "consistency_01",
      "rule": "Ensure responses are stable and internally consistent.",
      "intent": "Maintain reliability and predictability.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "precision_01",
      "rule": "Provide information accurately and avoid unsupported assumptions.",
      "intent": "Preserve trust and correctness.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "restraint_01",
      "rule": "Operate strictly within the boundaries of the request.",
      "intent": "Prevent overreach and unnecessary expansion.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "neutrality_01",
      "rule": "Remain impartial and unbiased in all output.",
      "intent": "Ensure fairness and neutrality.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "safety_01",
      "rule": "Avoid actions or information that could cause harm.",
      "intent": "Prioritize user well-being and system integrity.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "transparency_01",
      "rule": "Acknowledge limitations when they materially affect output.",
      "intent": "Promote clarity and trust.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "coherence_01",
      "rule": "Ensure all parts of the output support a unified meaning.",
      "intent": "Maintain logical continuity.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "focus_01",
      "rule": "Concentrate on what is asked and omit irrelevant details.",
      "intent": "Increase relevance and utility.",
      "constraints": [],
      "notes": ""
    }
  ]
}



##########################################################################################
# FILE: context_files\rules\project_rules.json
##########################################################################################

{
  "project_name": "aiAgency",
  "rules": [
    "All source files must be placed under the 'core' or 'app' packages.",
    "Logging must use the project-wide logger from 'core.logging.logger'.",
    "Configuration must be read via 'core.config.run_config.RunConfig'.",
    "Public APIs must not hard-code file system paths; use helpers from 'core.files.path_utils'."
  ]
}



##########################################################################################
# FILE: context_files\runs\gemini_test.json
##########################################################################################

{
  "provider": "gemini",
  "runs": [
    {
      "name": "gemini_hello_world",
      "profile_file": "context_files/profiles/gemini_codegen.json",
      "task_description": "Write a Python script that prints 'Hello from Gemini 2.0!' and calculates the 10th Fibonacci number.",
      "context_file": [],
      "target_file": "app/gemini_hello.py",
      "allowed_actions": [
        "file_write"
      ]
    }
  ]
}


##########################################################################################
# FILE: context_files\runs\profile_file_test.json
##########################################################################################

{
  "runs": [
    {
      "profile_file": "context_files/profiles/code_generation.json",
      "task_description": "Test file_write: write 'FILE_WRITE_OK' only.",
      "context_file": [],
      "target_file": "tmp/actions_test/file_write_output.txt",
      "allowed_actions": ["file_write"],
      "retry": 0
    },

    {
      "profile_file": "context_files/profiles/code_generation.json",
      "task_description": "Test request_retry: always ask for retry once.",
      "context_file": [],
      "allowed_actions": ["request_retry"],
      "retry": 1
    },

    {
      "profile_file": "context_files/profiles/actions_control.json",
      "task_description": "Test trigger_retry + break. Emit trigger_retry then break.",
      "context_file": [],
      "allowed_actions": ["trigger_retry", "break"],
      "retry": 0
    }
  ]
}



##########################################################################################
# FILE: context_files\runs\test.json
##########################################################################################

{

  "runs": [
    {
      "name": "codegen_1",
      "profile_file": "context_files/profiles/codegen_test_base.json",
      "task_description": "Generate a simple Python module 'ModuleA' with one method.",
      "context_file": [],
      "target_file": "app/module_A.py",
      "allowed_actions": [
        "file_write",
        "continue"
      ]
    },

    {
      "name": "validator_1",
      "profile_file": "context_files/profiles/validator_test.json",
      "task_description": "Validate module_A.py. Require the marker '# VALID_VERSION' to accept.",
      "context_file": [
        "app/module_A.py"
      ],
      "target_file": "",

      "strategy_index": 0,
      "target_run": "codegen_1",
      "strategy_file": "context_files/retries/test_strategy.json",

      "allowed_actions": [
        "change_strategy",
        "continue",
        "break"
      ]
    }
  ]
}



##########################################################################################
# FILE: context_files\runs\test_tetris.json
##########################################################################################

{
  "provider": "openai",

  "retry_policy": {
    "system": {
      "max_attempts": 3,
      "retry_on_status": [429, 500, 502, 503, 504],
      "retry_on_network_errors": true,
      "backoff_seconds": [2, 4, 8]
    }
  },

  "runs": [
    {
      "name": "code_generation_1",
      "profile_file": "context_files/profiles/code_generation_1.json",
      "task_description": "Generate tetromino_block1.py for the first block.",
      "context_file": [
        "context_files/project_manifest_block1.json"
      ],
      "target_file": "app/tetris/tetromino_block1.py",

      "strategy_file": "retries/codegen_strategies.json",
      "strategy_block_index": 0,

      "retry": 0,
      "allowed_actions": [
        "file_write",
        "continue"
      ]
    },

    {
      "name": "validator_1",
      "profile_file": "context_files/profiles/validator_1.json",
      "task_description": "Validate tetromino_block1.py.",
      "context_file": [
        "app/tetris/tetromino_block1.py"
      ],
      "target_file": "",

      "retry": 0,
      "allowed_actions": [
        "change_strategy",
        "continue",
        "break"
      ]
    },

    {
      "name": "code_generation_2",
      "profile_file": "context_files/profiles/code_generation_2.json",
      "task_description": "Generate tetromino_block2.py for the second block.",
      "context_file": [
        "context_files/project_manifest_block2.json"
      ],
      "target_file": "app/tetris/tetromino_block2.py",

      "strategy_file": "retries/codegen_strategies.json",
      "strategy_block_index": 1,

      "retry": 0,
      "allowed_actions": [
        "file_write",
        "continue"
      ]
    },

    {
      "name": "validator_2",
      "profile_file": "context_files/profiles/validator_2.json",
      "task_description": "Validate tetromino_block2.py.",
      "context_file": [
        "app/tetris/tetromino_block2.py"
      ],
      "target_file": "",

      "retry": 0,
      "allowed_actions": [
        "change_strategy",
        "continue",
        "break"
      ]
    }
  ]
}



##########################################################################################
# FILE: core\app.py
##########################################################################################

# app/app.py
from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, Optional

from core.config.run_config import RunItem
from core.runtime.app_runner import AppRunner, RunResult


def main(
    profile_name: str,
    class_name: Optional[str],
    task_description: str,
    agent_input: Dict[str, Any],
    run_item: RunItem,
    run_params: Dict[str, Any],
) -> Dict[str, bool]:
    """Thin wrapper around AppRunner (kept for backward compatibility)."""
    project_root = Path(__file__).resolve().parents[1]
    runner = AppRunner(project_root=project_root)

    result: RunResult = runner.run(
        run_item=run_item,
        run_params=run_params,
        profile_name=profile_name,
        class_name=class_name,
        task_description=task_description,
        agent_input_overrides=agent_input,
    )

    return {
        "success": result.success,
        "retry_requested": result.retry_requested,
    }



##########################################################################################
# FILE: core\logger.py
##########################################################################################

import json
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path


class JsonFormatter(logging.Formatter):
    """Format log records as single-line JSON objects."""

    # keys from LogRecord we DON'T want to dump
    _skip_keys = {
        "name", "msg", "args", "levelname", "levelno",
        "pathname", "filename", "module", "exc_info",
        "exc_text", "stack_info", "lineno", "funcName",
        "created", "msecs", "relativeCreated", "thread",
        "threadName", "processName", "process", "asctime"
    }

    def format(self, record: logging.LogRecord) -> str:
        log_record = {
            "timestamp": self.formatTime(record, self.datefmt),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
        }

        # include any extra fields passed via logger.*(..., extra={...})
        for key, value in record.__dict__.items():
            if key not in self._skip_keys:
                log_record[key] = value

        return json.dumps(log_record, ensure_ascii=False)


class BasicLogger:
    def __init__(
        self,
        name: str,
        level: int = logging.INFO,
        log_to_file: bool = True,
        log_dir: str = "logs",
        log_file: str = "app.jsonl",
        max_bytes: int = 5_000_000,  # 5 MB
        backup_count: int = 5,
    ):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)

        # Prevent adding handlers multiple times
        if self.logger.handlers:
            return

        # --- Console handler (human-readable) ---
        console_handler = logging.StreamHandler()
        console_fmt = logging.Formatter(
            "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        )
        console_handler.setFormatter(console_fmt)
        self.logger.addHandler(console_handler)

        # --- File handler (JSON) ---
        if log_to_file:
            Path(log_dir).mkdir(parents=True, exist_ok=True)
            file_path = Path(log_dir) / log_file

            file_handler = RotatingFileHandler(
                file_path,
                maxBytes=max_bytes,
                backupCount=backup_count,
                encoding="utf-8",
            )

            json_formatter = JsonFormatter()
            file_handler.setFormatter(json_formatter)

            self.logger.addHandler(file_handler)

    def get_logger(self) -> logging.Logger:
        return self.logger



##########################################################################################
# FILE: core\__init__.py
##########################################################################################




##########################################################################################
# FILE: core\actions\base_action.py
##########################################################################################

from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict, Optional


@dataclass
class ActionContext:
    project_root: str
    target_file: Optional[str]
    run_name: str
    run_item: Any
    logger: Any

    # Control-flow flags
    should_continue: bool = False
    should_break: bool = False

    # Strategy-change flags
    change_strategy_requested: bool = False
    change_strategy_reason: Optional[str] = None


class BaseAction:
    """
    Base class for all actions inside aiAgency.
    Subclasses implement `execute(self, ctx, params)`.
    """

    action_type: str = ""

    def execute(self, ctx: ActionContext, params: Dict[str, Any]) -> None:
        raise NotImplementedError(f"{self.__class__.__name__}.execute() not implemented")



##########################################################################################
# FILE: core\actions\break_action.py
##########################################################################################

from __future__ import annotations

from typing import Any, Dict, Optional

from core.actions.base_action import BaseAction, ActionContext


class BreakAction(BaseAction):
    """
    Action type: 'break'

    Logical early termination of the pipeline.
    """

    action_type = "break"

    def execute(self, ctx: ActionContext, params: Dict[str, Any]) -> None:
        reason: Optional[str] = params.get("reason")
        ctx.should_break = True
        ctx.should_continue = False

        ctx.logger.info(f"[break] Pipeline break requested. Reason={reason!r}")



##########################################################################################
# FILE: core\actions\continue_action.py
##########################################################################################

from __future__ import annotations

from typing import Any, Dict

from core.actions.base_action import BaseAction, ActionContext


class ContinueAction(BaseAction):
    """
    Action type: 'continue'

    Signals that the pipeline should continue. The agent may optionally
    set should_break = true, but in your validator profiles you’ll use
    should_break = false.
    """

    action_type = "continue"

    def execute(self, ctx: ActionContext, params: Dict[str, Any]) -> None:
        should_break = bool(params.get("should_break", False))
        reason = params.get("reason")

        ctx.should_continue = True
        ctx.should_break = should_break

        ctx.logger.info(
            f"[continue] should_break={should_break}, reason={reason!r}"
        )



##########################################################################################
# FILE: core\actions\file_read.py
##########################################################################################

# core/actions/file_read.py
from __future__ import annotations

from pathlib import Path

from .base_action import BaseAction, ActionContext
from .registry import ActionRegistry


class FileReadAction(BaseAction):
    """
    Safely reads a text file from the project root and pushes the content
    into the ActionContext's results.

    Expected params:
        - path: str            (preferred)
          or
        - target_path: str     (fallback; same semantics)

    This is primarily useful for higher-level agents that need to inspect
    existing files without re-sending them as context from the host.
    """

    action_type = "file_read"

    def _get_relative_path(self) -> str | None:
        path = self.params.get("path") or self.params.get("target_path")
        if not isinstance(path, str) or not path.strip():
            return None
        return path.strip()

    def validate(self) -> bool:
        rel = self._get_relative_path()
        return rel is not None

    def execute(self, ctx: ActionContext) -> None:
        rel = self._get_relative_path()
        if not rel:
            ctx.logger.warning("[file_read] Missing or invalid 'path'/'target_path'.")
            return

        project_root = Path(ctx.project_root).resolve()
        full_path = (project_root / rel).resolve()

        try:
            # Security: do not allow escaping the project root
            if not full_path.is_relative_to(project_root):
                ctx.logger.error(
                    "[file_read] Refusing to read outside project root: %s", full_path
                )
                return
        except AttributeError:
            # For very old Python, fall back to a manual check (should not be needed in 3.10+)
            if project_root not in full_path.parents and full_path != project_root:
                ctx.logger.error(
                    "[file_read] Refusing to read outside project root: %s", full_path
                )
                return

        if not full_path.exists() or not full_path.is_file():
            ctx.logger.warning("[file_read] File not found or not a file: %s", full_path)
            return

        try:
            content = full_path.read_text(encoding="utf-8")
        except UnicodeDecodeError:
            ctx.logger.warning("[file_read] File is not valid UTF-8 text: %s", full_path)
            return

        ctx.logger.info("[file_read] Read file: %s", full_path)
        # Make the content available to callers that inspect ctx.results
        ctx.add_result(content)


# Register
ActionRegistry.register(FileReadAction)



##########################################################################################
# FILE: core\actions\file_write.py
##########################################################################################

# core/actions/file_write.py
from __future__ import annotations

from .base_action import BaseAction, ActionContext
from .registry import ActionRegistry


class FileWriteAction(BaseAction):

    action_type = "file_write"

    def validate(self) -> bool:
        code = self.params.get("code")
        return isinstance(code, str)

    def execute(self, ctx: ActionContext) -> None:
        if not self.validate():
            ctx.logger.warning("[file_write] Invalid params: %r", self.params)
            return

        # Path suggested by the agent (may be overridden by engine)
        agent_path: str = self.params.get("target_path", "") or ""

        # Engine source of truth (ActionRuntimeContext adds target_file)
        effective_path = getattr(ctx, "target_file", None) or agent_path
        if not effective_path:
            ctx.logger.error(
                "[file_write] No effective target path: "
                "ctx.target_file and params.target_path are both empty"
            )
            return

        code: str = self.params["code"]
        # Optional, currently unused but kept for future debugging/commits
        _context_text = self.params.get("context", "")

        ctx.logger.info(
            "[file_write] Writing file '%s' "
            "(ctx.target_file=%r, agent_path=%r)",
            effective_path,
            getattr(ctx, "target_file", None),
            agent_path,
        )
        written_path = ctx.file_writer.write_file(effective_path, code)
        ctx.logger.info("[file_write] File written at: %s", written_path)


# Register with the registry
ActionRegistry.register(FileWriteAction)



##########################################################################################
# FILE: core\actions\file_write_action.py
##########################################################################################

from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, Optional

from core.actions.base_action import BaseAction, ActionContext


class FileWriteAction(BaseAction):
    """
    Action type: 'file_write'

    Writes a full file to disk. The engine decides the final target path
    via ctx.target_file; if it's not set, we fall back to agent's target_path.
    """

    action_type = "file_write"

    def execute(self, ctx: ActionContext, params: Dict[str, Any]) -> None:
        code = params.get("code")
        if not isinstance(code, str):
            ctx.logger.error("[file_write] Missing or invalid 'code' param.")
            return

        # Engine source of truth
        effective_path: Optional[str] = ctx.target_file

        # Fallback to agent suggestion
        if not effective_path:
            effective_path = params.get("target_path")

        if not effective_path:
            ctx.logger.error(
                "[file_write] No target path: ctx.target_file and params.target_path are both empty."
            )
            return

        root = Path(ctx.project_root)
        full_path = (root / effective_path).resolve()

        try:
            full_path.parent.mkdir(parents=True, exist_ok=True)
            full_path.write_text(code, encoding="utf-8")
            ctx.logger.info(f"[file_write] Wrote file: {full_path}")
        except Exception as e:
            ctx.logger.error(f"[file_write] Error writing file '{full_path}': {e}", exc_info=True)
            return

        # This action itself doesn’t change control-flow flags.
        ctx.should_continue = True



##########################################################################################
# FILE: core\actions\registry.py
##########################################################################################

from __future__ import annotations
from typing import Dict, Type

from core.actions.base_action import BaseAction
from core.actions.file_write_action import FileWriteAction
from core.actions.continue_action import ContinueAction
from core.actions.break_action import BreakAction
from core.actions.rerun_action import RerunAction


class ActionRegistry:
    """
    Central registry for all action types in aiAgency.
    Model output actions are matched by their "type" field.
    """

    _registry: Dict[str, Type[BaseAction]] = {}

    @classmethod
    def register_defaults(cls) -> None:
        """
        Register all core built-in actions.
        This should be called once at AppRunner init.
        """
        cls.register(FileWriteAction)
        cls.register(ContinueAction)
        cls.register(BreakAction)
        cls.register(RerunAction)

    @classmethod
    def register(cls, action_cls: Type[BaseAction]) -> None:
        """
        Register a new action class.
        """
        action_type = getattr(action_cls, "action_type", None)
        if not isinstance(action_type, str) or not action_type:
            raise ValueError(
                f"Cannot register action {action_cls}: missing or invalid action_type"
            )

        cls._registry[action_type] = action_cls

    @classmethod
    def create(cls, action_type: str) -> BaseAction:
        """
        Instantiate a previously registered action class.
        """
        if action_type not in cls._registry:
            raise ValueError(
                f"Action type '{action_type}' is not registered. "
                f"Available: {list(cls._registry.keys())}"
            )

        return cls._registry[action_type]()



##########################################################################################
# FILE: core\actions\request_retry.py
##########################################################################################

# core/actions/request_retry.py
from __future__ import annotations

from typing import Optional

from .base_action import BaseAction, ActionContext
from .registry import ActionRegistry


class RequestRetryAction(BaseAction):
    """
    Action used by agents to request that the *current run* be retried.

    Expected params:
        - reason: Optional[str]  (short explanation logged by the engine)
    """

    action_type = "request_retry"

    def validate(self) -> bool:
        reason = self.params.get("reason")
        if reason is not None and not isinstance(reason, str):
            return False
        return True

    def execute(self, ctx: ActionContext) -> None:
        # The concrete runtime context (ActionRuntimeContext) has
        # retry_requested / retry_reason fields. We set them via setattr
        # to avoid tight coupling.
        setattr(ctx, "retry_requested", True)
        reason: Optional[str] = self.params.get("reason")
        setattr(ctx, "retry_reason", reason)

        logger = getattr(ctx, "logger", None)
        if logger is not None:
            if reason:
                logger.info(
                    "[request_retry] Agent requested retry for this run: %s",
                    reason,
                )
            else:
                logger.info(
                    "[request_retry] Agent requested retry for this run "
                    "(no reason provided)."
                )


# Register
ActionRegistry.register(RequestRetryAction)



##########################################################################################
# FILE: core\actions\rerun_action.py
##########################################################################################

# core/actions/rerun_action.py
from __future__ import annotations

from typing import Dict, Any

from core.actions.base_action import BaseAction, ActionContext


class RerunAction(BaseAction):
    """
    Action that requests rerunning a target run using the next
    strategy attempt defined in a rerun strategy file.

    Externally used with: type = "rerun".
    Internally it still uses the existing change_strategy_* flags,
    so the rest of the pipeline code does not need to change yet.
    """

    # This is what the registry looks for
    action_type = "rerun"

    def execute(self, ctx: ActionContext, params: Dict[str, Any]) -> None:
        reason = params.get("reason", "No reason provided")

        # Re-use the existing strategy-change flags so pipeline code stays the same
        ctx.change_strategy_requested = True
        ctx.change_strategy_reason = reason

        # This action does not in itself break or continue; it just signals a rerun
        ctx.should_continue = False
        ctx.should_break = False

        ctx.logger.info(f"[rerun] Rerun requested: {reason!r}")



##########################################################################################
# FILE: core\actions\trigger_retry.py
##########################################################################################

# core/actions/trigger_retry.py
from __future__ import annotations

from typing import Optional

from .base_action import BaseAction, ActionContext
from .registry import ActionRegistry


class TriggerRetryAction(BaseAction):
    """
    Higher-level action to request retrying *previous* steps with extra context.

    This is intended for coordinator / planner agents that want to tell the
    pipeline: "go back and rerun from step X, here is why and with what note".

    Expected params:
        - reason: Optional[str]         – human-readable reason
        - from_run_index: Optional[int] – 1-based index of run to restart from
        - note: Optional[str]           – additional free-form guidance

    Current behaviour:
        - Sets ctx.retry_requested = True so the RunExecutor treats this like
          a normal retry request for the current run.
        - Packs the details into ctx.retry_reason for logging.
        - Attaches richer metadata on the context for future pipeline-level
          handling (trigger_retry_from_run_index, trigger_retry_note).

    The pipeline-level code can later be extended to inspect those additional
    fields and override retry_from dynamically.
    """

    action_type = "trigger_retry"

    def validate(self) -> bool:
        reason = self.params.get("reason")
        from_run_index = self.params.get("from_run_index")
        note = self.params.get("note")

        if reason is not None and not isinstance(reason, str):
            return False
        if note is not None and not isinstance(note, str):
            return False
        if from_run_index is not None and not isinstance(from_run_index, int):
            return False

        return True

    def execute(self, ctx: ActionContext) -> None:
        reason: Optional[str] = self.params.get("reason")
        note: Optional[str] = self.params.get("note")
        from_run_index: Optional[int] = self.params.get("from_run_index")

        # For now, align with run-level retry semantics so the executor
        # still behaves correctly even before pipeline-level wiring.
        setattr(ctx, "retry_requested", True)

        parts = []
        if reason:
            parts.append(reason)
        if note:
            parts.append(f"note={note}")
        if from_run_index is not None:
            parts.append(f"from_run_index={from_run_index}")

        combined_reason = " | ".join(parts) if parts else None
        setattr(ctx, "retry_reason", combined_reason)

        # Store richer metadata for future pipeline-level logic
        setattr(ctx, "trigger_retry_from_run_index", from_run_index)
        setattr(ctx, "trigger_retry_note", note)

        logger = getattr(ctx, "logger", None)
        if logger is not None:
            logger.info(
                "[trigger_retry] Higher-level agent requested pipeline retry: %s",
                combined_reason or "<no reason>",
            )


# Register
ActionRegistry.register(TriggerRetryAction)



##########################################################################################
# FILE: core\actions\__init__.py
##########################################################################################

# core/actions/__init__.py

__all__: list[str] = []



##########################################################################################
# FILE: core\ai_client\ai_response_parser.py
##########################################################################################

# core/ai_client/ai_response_parser.py
import json
from typing import Any, Dict


class AIResponseParser:
    """
    Extracts structured data (like 'agent' and 'actions') from AI responses.

    Expected OpenAI response shape (chat/completions):

    {
      "choices": [
        {
          "message": {
            "role": "assistant",
            "content": <string or dict or list>
          }
        }
      ],
      ...
    }

    When using response_format = { "type": "json_object" }, the content may be:
    - a JSON string ("{ ... }")
    - or already a dict ({ ... })
    """

    # ------------------------------------------------------------------ #
    # Core parsing helper
    # ------------------------------------------------------------------ #
    @staticmethod
    def _content_dict(response: Dict[str, Any]) -> Dict[str, Any]:
        """
        Safely parse message content into a dict. Returns {} on failure.

        Handles:
        - content as JSON string
        - content as already-parsed dict
        - content as list with a single JSON string or dict
        """
        try:
            message = response["choices"][0]["message"]
            content = message.get("content")
        except (KeyError, TypeError):
            return {}

        # Case 1: already a dict
        if isinstance(content, dict):
            return content

        # Case 2: JSON string
        if isinstance(content, str):
            try:
                return json.loads(content)
            except json.JSONDecodeError:
                # Not valid JSON, give up
                return {}

        # Case 3: list of parts (future-proofing; try first element)
        if isinstance(content, list) and content:
            first = content[0]

            # If first is dict and already looks like the JSON envelope
            if isinstance(first, dict) and "agent" in first:
                return first

            # If first has 'text' or 'value', try to JSON-load that
            if isinstance(first, dict):
                text_val = first.get("text") or first.get("value")
                if isinstance(text_val, str):
                    try:
                        return json.loads(text_val)
                    except json.JSONDecodeError:
                        return {}

        # Anything else we don't recognize
        return {}

    # ------------------------------------------------------------------ #
    # Agent/actions helpers
    # ------------------------------------------------------------------ #
    @classmethod
    def extract_agent(cls, response: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extract the 'agent' object from the response JSON.

        Expected shape in the model output:

        {
          "agent": {
            "name": "code_pipeline",
            "version": "v1",
            "actions": [ ... ]
          }
        }

        Returns {} if the 'agent' key is missing or invalid.
        """
        data = cls._content_dict(response)
        agent = data.get("agent", {})
        return agent if isinstance(agent, dict) else {}

    @classmethod
    def extract_actions(cls, response: Dict[str, Any]) -> list[dict]:
        """
        Convenience helper: return agent.actions[] as a list.
        Empty list if agent or actions is missing/invalid.
        """
        agent = cls.extract_agent(response)
        actions = agent.get("actions", [])
        return actions if isinstance(actions, list) else []



##########################################################################################
# FILE: core\ai_client\gemini_client.py
##########################################################################################

import os
import json
from typing import Dict, Any, Optional, List
from google import genai
from google.genai import types
from core.logger import BasicLogger


class GeminiClient:
    """
    Wrapper for the Google Gen AI SDK (Gemini).
    """

    def __init__(self, api_key: Optional[str] = None, model: str = "gemini-2.0-flash"):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY is not set.")

        self.logger = BasicLogger(self.__class__.__name__).get_logger()
        self.model = model

        # Initialize the official client
        self.client = genai.Client(api_key=self.api_key)

    def generate_content(
        self,
        prompt: str,
        system_instruction: Optional[str] = None,
        response_schema: Optional[Dict[str, Any]] = None,
        temperature: float = 0.0,
    ) -> Dict[str, Any]:
        """
        Generates content using Gemini.
        Supports structured JSON output if response_schema is provided.

        Additionally, even when response_schema is not provided, this method
        attempts to parse the response as JSON first. If parsing fails, it
        falls back to returning a simple text wrapper.
        """
        self.logger.info(f"Sending request to Gemini ({self.model})...")

        config_args: Dict[str, Any] = {
            "temperature": temperature,
        }

        # Handle Structured Outputs (JSON mode)
        if response_schema:
            config_args["response_mime_type"] = "application/json"
            config_args["response_schema"] = response_schema

        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction,
                    **config_args,
                ),
            )

            # Extract text
            text_content = response.text

            # If we expected JSON, try to parse it to ensure it's valid
            if response_schema:
                try:
                    return json.loads(text_content)
                except json.JSONDecodeError:
                    self.logger.error("Failed to parse JSON from Gemini response.")
                    return {"error": "Invalid JSON", "raw": text_content}

            # Even when no explicit response_schema is passed, profiles may
            # instruct Gemini to return a full JSON agent object. Try JSON first.
            try:
                parsed = json.loads(text_content)
                return parsed
            except json.JSONDecodeError:
                self.logger.info(
                    "Gemini response is not valid JSON; returning raw text wrapper."
                )
                return {"content": text_content}

        except Exception as e:
            self.logger.error(f"Gemini API error: {str(e)}")
            raise e



##########################################################################################
# FILE: core\ai_client\openai_client.py
##########################################################################################

import json
from typing import Dict, Any, Optional

import requests
import os

from core.logger import BasicLogger


class OpenAIClient:
    """
    Handles direct HTTP calls to the OpenAI API.
    """

    # Whitelist of top-level keys allowed by /v1/chat/completions
    _ALLOWED_TOP_LEVEL_KEYS = {
        "model",
        "messages",
        "temperature",
        "top_p",
        "max_tokens",
        "n",
        "stop",
        "presence_penalty",
        "frequency_penalty",
        "logit_bias",
        "user",
        "response_format",
        "seed",
        "tools",
        "tool_choice",
        "metadata",
    }

    def __init__(
        self,
        api_url: str = "https://api.openai.com/v1/chat/completions",
        api_key: str = "",
    ):
        self.api_url = api_url

        # NEW: automatically use environment variable if argument empty
        self.api_key = api_key or os.getenv("OPENAI_API_KEY", "")

        self.logger = BasicLogger(
            self.__class__.__name__,
            log_file="openai_client.jsonl",
        ).get_logger()

    def _sanitize_body(self, body: Dict[str, Any]) -> Dict[str, Any]:
        """
        Remove any keys that the OpenAI chat.completions API does not recognize.
        This lets profile JSON contain meta fields like 'name', 'task_description', etc.
        """
        sanitized = {
            k: v for k, v in body.items() if k in self._ALLOWED_TOP_LEVEL_KEYS
        }

        removed = [k for k in body.keys() if k not in self._ALLOWED_TOP_LEVEL_KEYS]
        if removed:
            self.logger.info(
                "Stripping meta keys from payload",
                extra={
                    "event": "openai_strip_meta_keys",
                    "removed_keys": removed,
                },
            )

        return sanitized
    
    
    def call(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Backwards-compatible wrapper used by AppRunner._invoke_model.

        Accepts a ready-to-send payload (matching OpenAI's chat.completions schema),
        and returns the raw JSON response from the OpenAI API.
        """
        return self.send_request(payload)

    def send_request(
        self,
        body: Dict[str, Any],
        headers: Optional[Dict[str, str]] = None,
        timeout: int = 120,
    ) -> Dict[str, Any]:
        """
        Sends a POST request to the OpenAI API with the provided body and headers.
        """
        final_headers = headers or {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
        }

        sanitized_body = self._sanitize_body(body)

        # JSON log (to file) for outgoing request payload
        self.logger.info(
            "Outgoing OpenAI API request",
            extra={
                "event": "openai_request",
                "model": sanitized_body.get("model"),
                "payload": sanitized_body,
            },
        )

        # Optional: pretty dump for console
        self.logger.info(
            "FULL REQUEST PAYLOAD:\n%s",
            json.dumps(sanitized_body, indent=2),
        )

        response = requests.post(
            self.api_url,
            json=sanitized_body,
            headers=final_headers,
            timeout=timeout,
        )

        # Try to parse JSON once so we can both log and return it
        try:
            resp_json = response.json()
        except ValueError:
            resp_json = {"raw_text": response.text}

        # JSON log (to file) for response
        self.logger.info(
            "Received OpenAI API response",
            extra={
                "event": "openai_response",
                "status_code": response.status_code,
                "ok": response.ok,
                "response_body": resp_json,
            },
        )

        # If not ok, make it visible and raise a generic exception
        if not response.ok:
            self.logger.error(
                "OpenAI API error",
                extra={
                    "event": "openai_error",
                    "status_code": response.status_code,
                    "response_body": resp_json,
                },
            )
            raise Exception(
                f"OpenAI API error {response.status_code}: {response.text}"
            )

        return resp_json



##########################################################################################
# FILE: core\ai_client\__init__.py
##########################################################################################




##########################################################################################
# FILE: core\config\run_config.py
##########################################################################################

# core/config/run_config.py
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional, Dict, Any
import json


# ---------------------------------------------------------------------------
# Core Run Item representation
# ---------------------------------------------------------------------------

@dataclass
class RunItem:
    """
    Represents a single entry in runs.json.
    """

    name: str
    profile_file: str
    task_description: Optional[str]
    context_file: List[str]
    target_file: Optional[str]
    allowed_actions: List[str]

    # These fields apply ONLY to validator / rerun controller runs.
    # Code-generation runs must leave them as None.
    rerun_index: Optional[int] = None          # which rerun strategy block to use
    target_run: Optional[str] = None           # which codegen run to rerun
    rerun_strategy: Optional[str] = None       # path to rerun strategy .json file

    # Reserved for future or profile metadata:
    retry: Optional[int] = None
    profile_name: Optional[str] = None

    def is_validator(self) -> bool:
        """
        A run is considered a validator/rerun controller if all rerun-related
        fields are present.
        """
        return (
            self.rerun_index is not None
            and self.target_run is not None
            and self.rerun_strategy is not None
        )


# ---------------------------------------------------------------------------
# Full Run Configuration (the root of runs.json)
# ---------------------------------------------------------------------------

@dataclass
class RunConfig:
    """
    Represents the parsed content of the run configuration JSON.

    NOTE: Provider is intentionally NOT stored here anymore.
          Provider is now taken from profile files only (or rerun strategy overrides).
    """

    runs: List[RunItem]
    retry_policy: Optional[Dict[str, Any]] = None

    @staticmethod
    def from_file(path: Path | str) -> "RunConfig":
        """
        Load and parse runs.json.
        """
        if isinstance(path, str):
            path = Path(path)

        with path.open("r", encoding="utf-8") as f:
            raw = json.load(f)

        # Top-level `provider` is ignored now (backwards-compatible).
        retry_policy = raw.get("retry_policy")

        runs_section = raw.get("runs", [])
        runs: List[RunItem] = []

        for r in runs_section:
            # New preferred keys
            rerun_index = r.get("rerun_index")
            rerun_strategy = r.get("rerun_strategy")

            # Backwards compatibility: accept old names if present
            if rerun_index is None and "strategy_index" in r:
                rerun_index = r.get("strategy_index")

            if rerun_strategy is None and "strategy_file" in r:
                rerun_strategy = r.get("strategy_file")

            run_item = RunItem(
                name=r["name"],
                profile_file=r["profile_file"],
                task_description=r.get("task_description"),
                context_file=r.get("context_file", []),
                target_file=r.get("target_file"),
                allowed_actions=r.get("allowed_actions", []),

                # Validator-only fields (new names)
                rerun_index=rerun_index,
                target_run=r.get("target_run"),
                rerun_strategy=rerun_strategy,

                # Misc metadata:
                retry=r.get("retry"),
                profile_name=r.get("profile_name"),
            )
            runs.append(run_item)

        return RunConfig(
            runs=runs,
            retry_policy=retry_policy,
        )



##########################################################################################
# FILE: core\config\strategy_config.py
##########################################################################################

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Optional, List, Dict, Any
import json


# ---------------------------------------------------------------------------
# Attempt-level override
# ---------------------------------------------------------------------------

@dataclass
class StrategyAttempt:
    """
    A single retry attempt override.
    All fields are optional — engine falls back to the original RunItem.
    """

    profile: Optional[str] = None
    provider: Optional[str] = None
    retry_context_files: Optional[List[str]] = None


# ---------------------------------------------------------------------------
# A single block containing multiple attempts
# ---------------------------------------------------------------------------

@dataclass
class StrategyBlock:
    label: Optional[str]
    attempts: List[StrategyAttempt]


# ---------------------------------------------------------------------------
# The entire strategy file (list of blocks)
# ---------------------------------------------------------------------------

@dataclass
class StrategyFile:
    blocks: List[StrategyBlock]

    @staticmethod
    def from_file(path: Path | str) -> "StrategyFile":
        """
        Load a strategy JSON file.

        Example schema:
        {
          "blocks": [
            {
              "label": "first_codegen_block",
              "attempts": [
                { "profile": "abc.json", "provider": "openai", "retry_context_files": [...] },
                { ... }
              ]
            },
            ...
          ]
        }
        """
        if isinstance(path, str):
            path = Path(path)

        with path.open("r", encoding="utf-8") as f:
            raw = json.load(f)

        blocks_raw = raw.get("blocks", [])
        blocks_parsed: List[StrategyBlock] = []

        for block in blocks_raw:
            label = block.get("label")
            attempts_raw = block.get("attempts", [])

            attempts: List[StrategyAttempt] = []
            for att in attempts_raw:
                attempts.append(
                    StrategyAttempt(
                        profile=att.get("profile"),
                        provider=att.get("provider"),
                        retry_context_files=att.get("retry_context_files"),
                    )
                )

            blocks_parsed.append(
                StrategyBlock(label=label, attempts=attempts)
            )

        return StrategyFile(blocks=blocks_parsed)

    def get_attempt(self, block_index: int, attempt_index: int) -> Optional[StrategyAttempt]:
        """
        Safely fetch one attempt. Returns None if:
        - invalid block
        - invalid attempt index
        """
        if block_index < 0 or block_index >= len(self.blocks):
            return None

        block = self.blocks[block_index]

        if attempt_index < 0 or attempt_index >= len(block.attempts):
            return None

        return block.attempts[attempt_index]



##########################################################################################
# FILE: core\context\context_loader.py
##########################################################################################

# core/context/context_loader.py
from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, List


def load_context_params(project_root: Path, context_files: List[str]) -> Dict[str, Any]:
    """Load one or more context files and build a single OpenAI payload dict.

    Convention:
    - The FIRST file MUST be a JSON profile with a complete OpenAI payload:
        { "model": "...", "messages": [...], "temperature": ..., ... }
    - ALL remaining files (JSON or not) are treated as extra textual context.
      Their raw content is concatenated into a single 'context_block' string,
      which the profile can inject via a ${context_block} placeholder.

    The returned dict is the raw OpenAI request payload. A special meta key
    `_context_block` is optionally added and later consumed by the prompt
    rewriter.
    """
    if not context_files:
        raise ValueError("Run is missing 'context_file'. At least one path is required.")

    # 1) Load the profile JSON (first file)
    first = context_files[0]
    profile_path = (project_root / first).resolve()

    if not profile_path.exists():
        raise FileNotFoundError(f"context_file not found: {profile_path}")

    with profile_path.open("r", encoding="utf-8") as f:
        params = json.load(f)

    if not isinstance(params, dict):
        raise ValueError(f"context_file must contain a JSON object: {profile_path}")

    # 2) Load remaining files as raw text and aggregate
    text_blocks: List[str] = []

    for rel in context_files[1:]:
        path = (project_root / rel).resolve()
        if not path.exists():
            raise FileNotFoundError(f"extra context_file not found: {path}")

        try:
            raw = path.read_text(encoding="utf-8")
        except UnicodeDecodeError:
            # Non-text or non-UTF8 files are skipped for safety.
            continue

        header = f"=== CONTEXT FILE: {rel} ===\n"
        text_blocks.append(header + raw.strip() + "\n")

    if text_blocks:
        context_block = "\n\n".join(text_blocks)
        # Store as meta field; the prompt layer will inject via ${context_block}
        params["_context_block"] = context_block

    return params



##########################################################################################
# FILE: core\context\__init__.py
##########################################################################################




##########################################################################################
# FILE: core\files\file_writer.py
##########################################################################################

# core/files/file_writer.py

from pathlib import Path
from core.logger import BasicLogger


class FileWriter:
    """
    Minimal primitive for writing text files under the project root.
    It takes a target_path (relative to project_root) and the full file content.
    """

    def __init__(self, project_root: Path):
        self.project_root = Path(project_root)
        self.logger = BasicLogger(self.__class__.__name__).get_logger()

    def write_file(self, target_path: str, content: str) -> Path:
        rel_path = Path(target_path)
        full_path = (self.project_root / rel_path).resolve()
        
        if not full_path.is_relative_to(self.project_root.resolve()):
            raise ValueError(f"Security Alert: Attempted to write outside project root: {full_path}")

        full_path.parent.mkdir(parents=True, exist_ok=True)
        self.logger.info(f"[FileWriter] Writing file: {full_path}")

        with full_path.open("w", encoding="utf-8") as f:
            f.write(content)

        return full_path



##########################################################################################
# FILE: core\files\__init__.py
##########################################################################################




##########################################################################################
# FILE: core\git\commit_message_builder.py
##########################################################################################

class CommitMessageBuilder:
    """
    A utility class to build commit messages for version control.
    """

    @staticmethod
    def build(file_path: str, context: str, author: str = "AI_Agent") -> str:
        """
        Builds a formatted commit message.

        :param file_path: The path of the file being committed.
        :param context: A detailed, multi-line description of the changes.
        :param author: The author of the commit, default is 'AI_Agent'.
        :return: A formatted commit message string.
        """
        filename = file_path.split('/')[-1]
        short_description = f"Update {filename}"
        commit_message = f"{short_description}\n\n{context}\n\nAuthor: {author}"
        return commit_message



##########################################################################################
# FILE: core\git\git_client.py
##########################################################################################

import subprocess
from typing import Union
from core.logger import BasicLogger

class GitClient:
    def __init__(self, repo_path: str):
        """Initialize the GitClient with the path to the repository."""
        self.repo_path = repo_path
        self.logger = BasicLogger(self.__class__.__name__).get_logger()

    def _run_git_command(self, *args: str) -> str:
        self.logger.info(f'Running git command: {args}')
        try:
            result = subprocess.run(
                ['git'] + list(args),
                cwd=self.repo_path,
                text=True,
                capture_output=True,
                check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as exc:
            stdout_msg = (exc.stdout or "").strip()
            stderr_msg = (exc.stderr or "").strip()

            if stdout_msg:
                self.logger.error(f"Git stdout (cmd: {args}): {stdout_msg}")
            if stderr_msg:
                self.logger.error(f"Git stderr (cmd: {args}): {stderr_msg}")

            # Re-raise so the caller still gets the failure
            raise

    def init_repo(self) -> None:
        """Initialize a new git repository."""
        self.logger.info('Initializing repository')
        self._run_git_command('init')

    def add(self, paths: Union[list[str], str]) -> str:
        """Add file contents to the index."""
        self.logger.info(f'Adding paths: {paths}')
        if isinstance(paths, str):
            paths = [paths]
        return self._run_git_command('add', *paths)

    def commit(self, message: str) -> str:
        """Record changes to the repository with a commit message."""
        self.logger.info(f'Committing with message: {message}')
        return self._run_git_command('commit', '-m', message)

    def push(self, remote: str = "origin", branch: str = None) -> str:
        """Update remote refs along with associated objects."""
        branch = branch or 'main'
        self.logger.info(f'Pushing to {remote}/{branch}')
        return self._run_git_command('push', remote, branch)

    def pull(self, remote: str = "origin", branch: str = None) -> str:
        """Fetch from and integrate with another repository or a local branch."""
        branch = branch or 'main'
        self.logger.info(f'Pulling from {remote}/{branch}')
        return self._run_git_command('pull', remote, branch)

    def checkout(self, branch: str, create_if_missing: bool = False) -> str:
        """Switch branches or restore working tree files."""
        self.logger.info(f'Checking out branch: {branch}, create if missing: {create_if_missing}')
        if create_if_missing:
            return self._run_git_command('checkout', '-b', branch)
        return self._run_git_command('checkout', branch)

    def status(self) -> str:
        """Show the working tree status."""
        self.logger.info('Getting status')
        return self._run_git_command('status')

    def get_current_branch(self) -> str:
        """Get the name of the current branch."""
        self.logger.info('Getting current branch')
        return self._run_git_command('rev-parse', '--abbrev-ref', 'HEAD')


##########################################################################################
# FILE: core\git\git_manager.py
##########################################################################################

from typing import Optional
from core.git.git_client import GitClient  # adjust path if different


class GitManager:
    def __init__(self, git_client: GitClient) -> None:
        self.git_client = git_client

    def prepare_branch(self, branch: str) -> None:
        """
        Checkout the specified branch using the GitClient.
        """
        self.git_client.checkout(branch)

    def commit_generated_file(self, file_path: str, context: str) -> str:
        """
        Add the specified file and commit it with a message including the context.

        :param file_path: Path to the file to be committed.
        :param context: Context to include in the commit message.
        :return: The commit hash or output returned by the GitClient.
        """
        self.git_client.add(file_path)
        commit_message = f"Add/update generated file {file_path}. Context: {context[:120]}"
        return self.git_client.commit(commit_message)

    def sync_with_remote(self, remote: str = "origin", branch: str = "master") -> None:
        """
        Pull the latest changes from the specified remote and branch.
        """
        self.git_client.pull(remote, branch)

    def auto_push(self, commit_message: str, context: str = "") -> None:
        """
        Commit with the provided message and push to the remote.
        """
        full_message = (
            f"{commit_message}. Context: {context[:120]}" if context else commit_message
        )
#        self.git_client.commit(full_message)
        self.git_client.push("origin", "master")



##########################################################################################
# FILE: core\git\repo_config.py
##########################################################################################

from dataclasses import dataclass

@dataclass
class RepoConfig:
    """
    Configuration for a repository.

    Attributes:
        repo_path (str): The file path to the repository.
        default_branch (str): The default branch of the repository. Defaults to 'master'.
        remote_name (str): The name of the remote. Defaults to 'origin'.
        author_name (str): The name of the author. Defaults to 'AI Agent'.
        author_email (str): The email of the author. Defaults to 'ai@example.com'.
    """
    repo_path: str
    default_branch: str = "master"
    remote_name: str = "origin"
    author_name: str = "AI Agent"
    author_email: str = "ai@example.com"



##########################################################################################
# FILE: core\prompt\agent_input_builder.py
##########################################################################################

# core/prompt/agent_input_builder.py
from __future__ import annotations

import json
from typing import Any, Dict, List, Optional

from core.config.run_config import RunItem


def build_agent_input(
    run_item: RunItem,
    profile_name: str,
    class_name: Optional[str],
    base_agent_input: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    """Construct the agent_input object passed into the model.

    This combines:
    - static runtime info (profile_name, class_name)
    - per-run agent_input overrides from the profile/run
    - the target_file path if present
    - the resolved provider (if available)
    """
    agent_input_obj: Dict[str, Any] = {
        "profile_name": profile_name,
        "class_name": class_name or None,
    }

    if isinstance(base_agent_input, dict) and base_agent_input:
        agent_input_obj.update(base_agent_input)

    if run_item.target_file:
        agent_input_obj["target_file"] = run_item.target_file

    # Expose provider to the model (if configured)
    if getattr(run_item, "provider", None):
        agent_input_obj["provider"] = run_item.provider

    return agent_input_obj


def build_rules_block_for_run(run_item: RunItem) -> str:
    """Build a markdown-style rules block string for this run.

    - Uses per-run rules from runs.json (run_item.rules).
    - Adds a small set of global rules.
    - Deduplicates while preserving order.
    """
    base_rules: List[str] = [
        "Always respond strictly in the required JSON envelope.",
        "Never output markdown or prose outside the specified JSON format.",
    ]

    run_rules = run_item.rules or []

    combined: List[str] = []
    for r in base_rules + run_rules:
        if r not in combined:
            combined.append(r)

    return "\n".join(f"- {r}" for r in combined)


def inject_placeholders(
    run_params: Dict[str, Any],
    agent_input_obj: Dict[str, Any],
    rules_block: str,
    task_description: str,
    target_file: Optional[str],
    context_block: str,
) -> None:
    """Replace placeholder tokens in the model payload messages.

    Mutates `run_params` in-place. It expects the payload to have a `messages`
    list compatible with the OpenAI Chat Completions API.
    """
    agent_input_json = json.dumps(agent_input_obj, ensure_ascii=False, indent=2)

    for msg in run_params.get("messages", []):
        content = msg.get("content")
        if not isinstance(content, str):
            continue

        if "${agent_input}" in content:
            content = content.replace("${agent_input}", agent_input_json)

        if "${task_description}" in content:
            content = content.replace("${task_description}", task_description or "")

        if "${rules_block}" in content:
            content = content.replace("${rules_block}", rules_block)

        if "${target_file}" in content:
            content = content.replace("${target_file}", target_file or "")

        if "${context_block}" in content:
            content = content.replace("${context_block}", context_block or "")

        msg["content"] = content



##########################################################################################
# FILE: core\prompt\__init__.py
##########################################################################################




##########################################################################################
# FILE: core\runtime\app_runner.py
##########################################################################################

# core/runtime/app_runner.py
from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, List, Optional

from core.logger import BasicLogger
from core.actions.registry import ActionRegistry
from core.actions.base_action import ActionContext, BaseAction
from core.ai_client.openai_client import OpenAIClient
from core.ai_client.ai_response_parser import AIResponseParser
from core.ai_client.gemini_client import GeminiClient


class AppRunner:
    """
    Responsible for:
        - loading the profile JSON
        - assembling model input payload
        - calling the correct provider (OpenAI, Gemini, ...)
        - parsing model output into actions
        - filtering allowed actions
        - executing actions in order
        - returning an ActionContext summarizing what happened

    No retry logic happens here.
    """

    def __init__(self, project_root: Path | str):
        self.project_root = Path(project_root).resolve()
        self.logger = BasicLogger("AppRunner").get_logger()

        # Action registry must be available
        ActionRegistry.register_defaults()

    # ----------------------------------------------------------------------
    # Public main entrypoint
    # ----------------------------------------------------------------------
    def run_single(
        self,
        run_item: Any,
        profile_file: str,
        context_files: List[str],
        target_file: Optional[str],
        provider_override: Optional[str] = None,
    ) -> ActionContext:
        """
        Execute a single run step. This is called by RunExecutor.

        Provider resolution order:
            1) provider_override   (strategy attempt)
            2) profile["provider"] (profile JSON)
            3) "openai" (default)
        """

        # Load profile JSON
        resolved_profile = self._load_profile(profile_file)

        # Resolve provider
        provider_name: Optional[str] = provider_override
        if not provider_name:
            provider_name = resolved_profile.get("provider")
        if not provider_name:
            provider_name = "openai"

        self.logger.info(
            f"Selected provider '{provider_name}' for profile '{profile_file}' "
            f"(target_file='{target_file}')"
        )

        # Build model request
        payload = self._build_model_payload(
            resolved_profile,
            run_item,
            provider_name,
            context_files,
        )

        # Call provider
        agent_obj = self._invoke_model(provider_name, payload)

        # Prepare action context
        ctx = ActionContext(
            project_root=str(self.project_root),
            target_file=target_file,
            run_name=run_item.name,
            run_item=run_item,
            logger=self.logger,
        )

        # Parse + execute actions
        actions = agent_obj.get("actions", [])
        filtered = self._filter_actions(actions, run_item.allowed_actions)
        self._execute_actions(filtered, ctx)

        return ctx

    # ----------------------------------------------------------------------
    # Internal utilities
    # ----------------------------------------------------------------------
    def _load_profile(self, profile_file: str) -> Dict[str, Any]:
        """
        Load the profile JSON from disk.
        """
        profile_path = (self.project_root / profile_file).resolve()
        with profile_path.open("r", encoding="utf-8") as f:
            data = json.load(f)

        if not isinstance(data, dict):
            raise ValueError(f"Profile '{profile_file}' must contain a JSON object.")

        return data

    def _build_model_payload(
        self,
        profile_dict: Dict[str, Any],
        run_item: Any,
        provider_name: str,
        context_files: List[str],
    ) -> Dict[str, Any]:
        """
        Merge:
            - static profile JSON
            - run_item metadata
            - context files
        """

        # Inject runtime metadata into the profile
        profile_dict = dict(profile_dict)  # shallow copy

        # Build agent_input
        agent_input = {
            "profile_name": run_item.profile_file,
            "class_name": getattr(run_item, "class_name", None),
            "allowed_actions": run_item.allowed_actions,
            "provider": provider_name,
        }

        # Construct context block
        context_blocks: List[str] = []
        for cf in context_files:
            path = self.project_root / cf
            try:
                with path.open("r", encoding="utf-8") as f:
                    ctxdata = f.read()
                context_blocks.append(
                    f"=== CONTEXT FILE: {cf} ===\n{ctxdata}"
                )
            except Exception as e:
                context_blocks.append(
                    f"=== CONTEXT FILE: {cf} ===\n!! ERROR READING FILE: {e} !!"
                )

        # agent_input is placed inside the request
        payload: Dict[str, Any] = {
            "model": profile_dict.get("model"),
            "temperature": profile_dict.get("temperature", 0),
            "top_p": profile_dict.get("top_p", 1),
            "max_tokens": profile_dict.get("max_tokens", 2000),
            "messages": self._inject_messages(
                profile_dict.get("messages", []),
                agent_input,
                context_blocks,
                getattr(run_item, "task_description", None),
            ),
            "response_format": profile_dict.get(
                "response_format", {"type": "json_object"}
            ),
            "user": profile_dict.get("user", "${default_user}"),
        }

        self.logger.info(
            "Prepared model payload",
            extra={
                "event": "model_payload_built",
                "run_name": getattr(run_item, "name", None),
                "provider": provider_name,
                "model": payload.get("model"),
                "temperature": payload.get("temperature"),
                "max_tokens": payload.get("max_tokens"),
                "num_messages": len(payload.get("messages", [])),
                "num_context_files": len(context_files),
            },
        )

        self.logger.info("Starting model call via provider '%s'.", provider_name)
        return payload

    def _inject_messages(
        self,
        messages: List[Dict[str, Any]],
        agent_input: Dict[str, Any],
        context_blocks: List[str],
        task_description: Optional[str],
    ) -> List[Dict[str, Any]]:
        """
        Replace ${agent_input}, ${context_block}, ${task_description}
        placeholders inside the profile messages.
        """
        ctx_combined = "\n\n".join(context_blocks)

        result: List[Dict[str, Any]] = []
        for msg in messages:
            content = msg.get("content", "")

            content = content.replace(
                "${agent_input}", json.dumps(agent_input, indent=2)
            )
            content = content.replace("${context_block}", ctx_combined)

            if task_description:
                content = content.replace("${task_description}", task_description)

            result.append({
                "role": msg["role"],
                "content": content,
            })
        return result

    def _invoke_model(self, provider_name: str, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Dispatch to the correct provider client and normalize response
        into an 'agent' object understood by the action layer.
        """
        temperature = payload.get("temperature", 0.0)
        model_name = payload.get("model")

        if provider_name == "openai":
            client = OpenAIClient()
            response = client.call(payload)
            return AIResponseParser.extract_agent(response)

        elif provider_name == "gemini":
            # If the JSON still says an OpenAI model, default to a Gemini model
            if not model_name or "gpt" in model_name:
                model_name = "gemini-2.0-flash"

            client = GeminiClient(model=model_name)

            # Extract messages to format prompt
            messages = payload.get("messages", [])
            system_instruction = None
            user_parts: List[str] = []

            for msg in messages:
                role = msg.get("role")
                content = msg.get("content", "")
                if role == "system" and not system_instruction:
                    system_instruction = content
                else:
                    # Keep it simple: ROLE: content
                    user_parts.append(f"{role.upper()}: {content}")

            final_prompt = "\n\n".join(user_parts)

            # Map OpenAI-style response_format → Gemini structured output schema
            response_schema: Optional[Dict[str, Any]] = None
            response_format = payload.get("response_format")

            if isinstance(response_format, dict) and response_format.get("type") == "json_object":
                # Minimal schema for:
                # {
                #   "agent": {
                #     "actions": [
                #       {
                #         "type": "file_write",
                #         "params": { "target_path": "...", "code": "..." }
                #       }
                #     ]
                #   }
                # }
                # IMPORTANT: no `additionalProperties` – Gemini API does not support it.
                response_schema = {
                    "type": "object",
                    "properties": {
                        "agent": {
                            "type": "object",
                            "properties": {
                                "actions": {
                                    "type": "array",
                                    "items": {
                                        "type": "object",
                                        "properties": {
                                            "type": {"type": "string"},
                                            "params": {
                                                "type": "object",
                                                "properties": {
                                                    "target_path": {"type": "string"},
                                                    "code": {"type": "string"},
                                                },
                                                "required": ["code"],
                                            },
                                        },
                                        "required": ["type", "params"],
                                    },
                                }
                            },
                            "required": ["actions"],
                        }
                    },
                    "required": ["agent"],
                }

            response_dict = client.generate_content(
                prompt=final_prompt,
                system_instruction=system_instruction,
                response_schema=response_schema,
                temperature=temperature,
            )

            # Normalize to the shape AIResponseParser expects
            return AIResponseParser.extract_agent(
                {"choices": [{"message": {"content": response_dict}}]}
            )

        else:
            raise NotImplementedError(f"Provider '{provider_name}' not implemented.")




    def _filter_actions(
        self,
        actions: List[Dict[str, Any]],
        allowed: List[str],
    ) -> List[Dict[str, Any]]:
        """
        Keep only actions whose type is allowed by run_item.
        """
        kept: List[Dict[str, Any]] = []
        for a in actions:
            if a.get("type") in allowed:
                kept.append(a)
            else:
                self.logger.warning(
                    f"Action '{a.get('type')}' rejected; not in allowed_actions={allowed}"
                )
        if not kept:
            self.logger.warning(
                f"No actions left after allowed_actions filter. "
                f"Original actions: {actions}"
            )
        return kept

    def _execute_actions(self, actions: List[Dict[str, Any]], ctx: ActionContext) -> None:
        """
        Execute actions in sequence.
        """
        for idx, action_dict in enumerate(actions, start=1):
            action_type = action_dict.get("type")
            params = action_dict.get("params", {})

            action_obj: BaseAction = ActionRegistry.create(action_type)

            ctx.logger.info(f"Executing action #{idx}: {action_type}")

            try:
                action_obj.execute(ctx, params)
            except Exception as e:
                ctx.logger.error(
                    f"Exception during action '{action_type}': {e}",
                    exc_info=True,
                )
                # leave ctx flags as-is; executor will stop run.
                break



##########################################################################################
# FILE: core\runtime\pipeline_runner.py
##########################################################################################

# core/runtime/pipeline_runner.py
from __future__ import annotations

from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from core.logger import BasicLogger
from core.runtime.run_executor import RunExecutor, RunResult
from core.config.run_config import RunConfig, RunItem
from core.config.strategy_config import StrategyFile


class PipelineRunner:
    """
    Orchestrates execution of the entire runs.json pipeline.

    Key responsibilities:
      - execute runs in sequence
      - detect change_strategy requests from validator runs
      - maintain attempt counters per (target_run, strategy_index)
      - load strategy file and apply overrides
      - re-run the target codegen run with the correct attempt settings
      - detect break / success / exhaustion
    """

    def __init__(self, project_root: str, config: RunConfig):
        self.project_root = Path(project_root)
        self.config = config
        self.logger = BasicLogger("PipelineRunner").get_logger()

        self.executor = RunExecutor(project_root=str(self.project_root))

        # Track number of attempts for each (target_run, strategy_index)
        # Key: (str, int) -> (target_run_name, strategy_block_index)
        # Value: int  -> number of change_strategy attempts already used
        self.strategy_attempt_counters: Dict[Tuple[str, int], int] = {}

        # Correlate one full pipeline execution in the logs
        self.run_id = datetime.utcnow().strftime("%Y%m%d-%H%M%S-%f")

    # ------------------------------------------------------------------
    # Main pipeline execution entrypoint
    # ------------------------------------------------------------------
    def run(self) -> None:
        total_runs = len(self.config.runs)
        succeeded = 0

        self.logger.info(
    "Warp field stabilized",
    extra={"event": "warp_stabilized"}
)

        self.logger.info(
            "Pipeline started",
            extra={
                "event": "pipeline_start",
                "run_id": self.run_id,
                "project_root": str(self.project_root),
                "total_runs": total_runs,
            },
        )

        

        for index, run_item in enumerate(self.config.runs):
            self.logger.info(
                f"[RUN] Starting '{run_item.name}'",
                extra={
                    "event": "run_start",
                    "run_id": self.run_id,
                    "run_index": index,
                    "total_runs": total_runs,
                    "run_name": run_item.name,
                    "profile_file": run_item.profile_file,
                    "target_file": run_item.target_file,
                    "context_files": list(run_item.context_file),
                    "is_validator": run_item.is_validator(),
                },
            )

            result = self._execute_run_item(run_item)

            # Break requested by an action
            if result.should_break:
                self.logger.info(
                    f"[RUN] '{run_item.name}' requested break. Pipeline stopping.",
                    extra={
                        "event": "run_break",
                        "run_id": self.run_id,
                        "run_name": run_item.name,
                    },
                )
                break

            if not result.success:
                self.logger.error(
                    f"[RUN] '{run_item.name}' failed. Pipeline stopping.",
                    extra={
                        "event": "run_failed",
                        "run_id": self.run_id,
                        "run_name": run_item.name,
                        "change_strategy_requested": result.change_strategy_requested,
                        "change_strategy_reason": result.change_strategy_reason,
                    },
                )
                break

            self.logger.info(
                f"[RUN] '{run_item.name}' succeeded.",
                extra={
                    "event": "run_succeeded",
                    "run_id": self.run_id,
                    "run_name": run_item.name,
                },
            )
            succeeded += 1

        self.logger.info(
            "Pipeline finished",
            extra={
                "event": "pipeline_finished",
                "run_id": self.run_id,
                "succeeded_runs": succeeded,
                "total_runs": total_runs,
            },
        )

    # ------------------------------------------------------------------
    # Execute a single run item (possibly triggers strategy reruns)
    # ------------------------------------------------------------------
    def _execute_run_item(self, run_item: RunItem) -> RunResult:
        # Normal single execution for codegen or validator
        base_result = self._execute_once(run_item)

        if base_result.change_strategy_requested:
            # Must be a validator run (by design)
            self.logger.info(
                f"[RUN] '{run_item.name}' requested change_strategy.",
                extra={
                    "event": "run_change_strategy_requested",
                    "run_id": self.run_id,
                    "run_name": run_item.name,
                    "change_strategy_reason": base_result.change_strategy_reason,
                },
            )
            return self._handle_change_strategy(run_item, base_result)

        return base_result

    # ------------------------------------------------------------------
    # Actual single execution call to RunExecutor
    # ------------------------------------------------------------------
    def _execute_once(self, run_item: RunItem) -> RunResult:
        profile_file = run_item.profile_file
        context_files = run_item.context_file
        target_file = run_item.target_file

        # Provider now comes from profile (or strategy overrides),
        # so for a normal run we pass no override.
        provider_override: Optional[str] = None

        return self.executor.execute_once(
            run_item=run_item,
            context_files=context_files,
            profile_file=profile_file,
            target_file=target_file,
            provider_override=provider_override,
        )

    # ------------------------------------------------------------------
    # NOTE:
    # _handle_change_strategy(...) and _find_run_item(...) remain as you
    # currently have them. You already have detailed logs inside that
    # method; they will continue to show up with run_id included in
    # the higher-level entries above.
    # ------------------------------------------------------------------



##########################################################################################
# FILE: core\runtime\run_executor.py
##########################################################################################

# core/runtime/run_executor.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Optional, List

from core.logger import BasicLogger
from core.runtime.app_runner import AppRunner
from core.config.run_config import RunItem


# ---------------------------------------------------------------------------
# Result returned to PipelineRunner after a single run execution
# ---------------------------------------------------------------------------

@dataclass
class RunResult:
    success: bool
    change_strategy_requested: bool = False
    change_strategy_reason: Optional[str] = None
    should_break: bool = False


# ---------------------------------------------------------------------------
# RunExecutor — runs a single step by invoking AppRunner
# ---------------------------------------------------------------------------

class RunExecutor:
    """
    Executes individual run steps.

    Responsibilities:
    - Invoke AppRunner.run_single()
    - Convert its ActionContext into a RunResult
    - NO RETRY LOGIC HERE. That belongs to PipelineRunner.
    """

    def __init__(self, project_root: str | None):
        self.project_root = project_root
        self.app_runner = AppRunner(project_root)
        # IMPORTANT: use the underlying logging.Logger
        self.logger = BasicLogger("RunExecutor").get_logger()

    # ------------------------------------------------------------------
    # Executes a single run step once (no retry loops here)
    # ------------------------------------------------------------------
    def execute_once(
        self,
        run_item: RunItem,
        context_files: List[str],
        profile_file: str,
        target_file: str | None,
        provider_override: str | None,
    ) -> RunResult:

        self.logger.info(
            "[RunExecutor] Starting run step",
            extra={
                "event": "run_step_start",
                "run_name": run_item.name,
                "profile_file": profile_file,
                "target_file": target_file,
                "context_files": list(context_files),
                "provider_override": provider_override,
            },
        )

        ctx = self.app_runner.run_single(
            run_item=run_item,
            profile_file=profile_file,
            context_files=context_files,
            target_file=target_file,
            provider_override=provider_override,
        )

        result = RunResult(
            success=not ctx.change_strategy_requested and not ctx.should_break,
            change_strategy_requested=ctx.change_strategy_requested,
            change_strategy_reason=ctx.change_strategy_reason,
            should_break=ctx.should_break,
        )

        self.logger.info(
            "[RunExecutor] Completed run step",
            extra={
                "event": "run_step_end",
                "run_name": run_item.name,
                "success": result.success,
                "change_strategy_requested": result.change_strategy_requested,
                "change_strategy_reason": result.change_strategy_reason,
                "should_break": result.should_break,
            },
        )

        return result



##########################################################################################
# FILE: core\runtime\__init__.py
##########################################################################################



