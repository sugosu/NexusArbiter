
================================================================================
FILE: C:\projects\aiAgency\main.py
================================================================================

# main.py
from __future__ import annotations

import argparse
from pathlib import Path

from dotenv import load_dotenv

from core.config.run_config import RunConfig
from core.runtime.pipeline_runner import PipelineRunner


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="aiAgency â€“ AI Code Generation Framework")
    parser.add_argument(
        "--config",
        type=str,
        required=True,
        help="Path to a JSON config file describing one or more runs.",
    )
    return parser.parse_args()


def main() -> None:
    load_dotenv()

    args = parse_args()
    project_root = Path(__file__).resolve().parent

    config = RunConfig.from_file(args.config)
    runner = PipelineRunner(project_root=project_root, config=config)

    result = runner.run()

    # Optional: exit code or final summary
    print(
        f"Pipeline finished: {result.succeeded}/{result.total_runs} succeeded, "
        f"{result.failed} failed, pipeline_retried={result.pipeline_retried}"
    )


if __name__ == "__main__":
    main()



================================================================================
FILE: C:\projects\aiAgency\merge_py.py
================================================================================

import os
import json

OUTPUT_NAME = "merged_all.txt"

def collect_all_files(root_dir, output_name):
    files = []
    for dirpath, _, filenames in os.walk(root_dir):
        for fname in filenames:
            # include .py and .json
            if fname.endswith((".py", ".json")) and fname != output_name:
                files.append(os.path.join(dirpath, fname))
    return files


def merge_all(files, output_path):
    with open(output_path, "w", encoding="utf-8") as out:
        for f in files:
            out.write("\n")
            out.write("=" * 80 + "\n")
            out.write(f"FILE: {f}\n")
            out.write("=" * 80 + "\n\n")

            try:
                with open(f, "r", encoding="utf-8") as src:
                    content = src.read()
                out.write(content)
            except Exception as e:
                out.write(f"!! ERROR READING FILE: {e} !!")

            out.write("\n\n")

    print(f"Merged {len(files)} files into: {output_path}")


if __name__ == "__main__":
    root = os.getcwd()
    files = collect_all_files(root, OUTPUT_NAME)
    output_file = os.path.join(root, OUTPUT_NAME)
    merge_all(files, output_file)



================================================================================
FILE: C:\projects\aiAgency\context_files\actions\actions_spec.json
================================================================================

{
  "name": "actions_spec",
  "description": "Definitions of available actions in aiAgency.",
  "actions": [
    {
      "type": "file_write",
      "purpose": "Write or replace a single file on disk.",
      "rules": [
        "Always produce a full file, not a patch.",
        "Content must be valid for the target language.",
        "The engine controls the actual target path; your params.target_path is ignored."
      ]
    },
    {
      "type": "continue",
      "purpose": "Signal that you are not ready to produce a final artifact.",
      "rules": [
        "Use this when you need another planning or refinement step.",
        "If you emit only a single 'continue' action, the engine will not execute side effects for this run.",
        "Use this instead of generating placeholder code."
      ]
    },
    {
      "type": "request_retry",
      "purpose": "Ask the engine to rerun the current run with updated context.",
      "rules": [
        "Use this when you detect a recoverable issue (for example, a syntax error or missing dependency) and want another attempt.",
        "Include a short 'reason' string explaining why you are requesting a retry.",
        "Do not perform any side effects in this action; it should only request a retry."
      ]
    }
  ]
}



================================================================================
FILE: C:\projects\aiAgency\context_files\manifests\manifest_example.json
================================================================================

{
  "project_name": "MyApp",
  "language": "python",
  "version": "1.0.0",
  "structure": [
    {
      "module_name": "user_manager",
      "file_path": "core/auth/user_manager.py",
      "description": "Handles user authentication and database interactions.",
      "imports": [
        { "source": "typing", "names": ["List", "Optional"], "type": "standard" },
        { "source": "pydantic", "names": ["BaseModel"], "type": "third_party" },
        { "source": "core.database", "names": ["db_connection"], "type": "local" }
      ],
      "global_constants": [
        { "name": "MAX_LOGIN_ATTEMPTS", "type": "int", "value": "5" }
      ],
      "classes": [
        {
          "class_name": "UserManager",
          "inherits_from": ["BaseService"],
          "decorators": ["@singleton"],
          "docstring": "Manages user lifecycle: registration, login, and deletion.",
          "attributes": [
            {
              "name": "db",
              "type": "DatabaseConnection",
              "access": "private",
              "description": "Active connection to the Postgres database."
            },
            {
              "name": "is_authenticated",
              "type": "bool",
              "access": "public",
              "default_value": "False",
              "description": "Flag tracking the current session state."
            }
          ],
          "methods": [
            {
              "name": "__init__",
              "access": "public",
              "args": [
                { "name": "connection_string", "type": "str", "default": "None" }
              ],
              "return_type": "None",
              "description": "Initializes the manager and establishes a DB connection."
            },
            {
              "name": "authenticate_user",
              "access": "public",
              "decorators": ["@log_execution"],
              "args": [
                { "name": "username", "type": "str" },
                { "name": "password_hash", "type": "str" }
              ],
              "return_type": "bool",
              "description": "Validates credentials against the stored hash.",
              "raises": ["AuthError", "TimeoutError"]
            },
            {
              "name": "_encrypt_password",
              "access": "private",
              "args": [
                { "name": "raw_password", "type": "str" }
              ],
              "return_type": "str",
              "description": "Internal helper to hash passwords before storage."
            }
          ]
        }
      ]
    }
  ]
}


================================================================================
FILE: C:\projects\aiAgency\context_files\profiles\actions_control.json
================================================================================

{
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 2000,
  "messages": [
    {
      "role": "system",
      "content": "You are a control agent inside the aiAgency framework.\n\nYour ONLY job is to emit actions in the JSON envelope:\n{\n  \"agent\": {\n    \"actions\": [ { \"type\": string, \"params\": object }, ... ]\n  }\n}\n\nGENERAL RULES:\n- Never output raw text or markdown outside this JSON object.\n- Always respond with a single top-level JSON object containing the key \"agent\".\n- Inside agent.actions, you may use the following action types, but ONLY those allowed by the runtime input:\n  - \"file_write\"\n  - \"request_retry\"\n  - \"trigger_retry\"\n  - \"break\"\n  - \"continue\"\n\nRUNTIME INPUT:\n- You will receive a JSON object called \"agent_input\" in the conversation, which may contain:\n  - \"allowed_actions\": array of action type strings you are allowed to use.\n  - \"task_description\": a natural language description of what to do.\n\nBEHAVIOUR:\n- Read agent_input.allowed_actions. You MUST NOT emit any action of a type that is not in this list.\n- Read agent_input.task_description and follow it exactly.\n\nACTION PARAM EXPECTATIONS:\n- For \"request_retry\":\n  params = { \"reason\": string }\n- For \"trigger_retry\":\n  params = { \"reason\": string, \"from_run_index\": integer, \"note\": string }\n- For \"break\":\n  params = { \"reason\": string }\n- For \"file_write\":\n  params = { \"target_path\": string, \"code\": string, \"context\": string }\n- For \"continue\":\n  params may be an empty object {}.\n\nOUTPUT RULES:\n- Do NOT output markdown or backticks.\n- Do NOT include any keys other than { \"agent\": { \"actions\": [...] } } at the top level.\n- The \"actions\" array MUST NOT be empty."
    },
    {
      "role": "user",
      "content": "Runtime agent input:\n${agent_input_json}\n\nAdditional rules:\n${rules_block}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    }
  ]
}



================================================================================
FILE: C:\projects\aiAgency\context_files\profiles\code_generation.json
================================================================================

{
  "name": "code_generation",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 2000,
  "messages": [
    {
      "role": "system",
      "content": "You are an AI code generation agent inside the aiAgency framework.\n\nGENERAL RULES:\n- Never output raw code or markdown outside of the JSON structure.\n- Always output a single JSON object with the structure: { \"agent\": { \"actions\": [ ... ] } }.\n- Always use the action type \"file_write\" for generating or replacing a code file.\n- Your output must contain exactly one action unless otherwise specified.\n\nFILE PATH RULES:\n- You MUST include a \"target_path\" field inside the \"params\" object, but its value is irrelevant.\n- The engine ALWAYS overrides the target path with its own configuration value (run_item.target_file).\n- You do NOT need to know or decide file paths or filenames. Ignore any such considerations.\n\nCONTEXT HEADER REQUIREMENT (PYTHON COMMENT BLOCK):\nEvery file you generate MUST begin with a top-of-file context header block inside the \"code\" string, formatted as valid Python comments:\n\n# === CONTEXT START ===\n# <short description of what this module does, based strictly on the task_description and agent_input>\n# === CONTEXT END ===\n\nRules for this header:\n- Every line in the header MUST start with \"# \".\n- The header MUST appear before any imports, classes, or other code.\n- The description line MUST also be prefixed with \"# \".\n\nACTION FORMAT SPECIFICATION:\nYou MUST return your final answer in this JSON format:\n{\n  \"agent\": {\n    \"actions\": [\n      {\n        \"type\": \"file_write\",\n        \"params\": {\n          \"target_path\": \"IGNORED_BY_ENGINE\",\n          \"code\": \"FULL FILE CONTENT INCLUDING THE COMMENT HEADER\",\n          \"context\": \"Optional reasoning or notes\"\n        }\n      }\n    ]\n  }\n}\n\nADDITIONAL PROHIBITIONS:\n- Do not include comments outside the JSON.\n- Do not add markdown formatting.\n- Do not emit multiple files unless explicitly required."
    },
    {
      "role": "user",
      "content": "Runtime agent input:\n${agent_input}\n\nAdditional rules:\n${rules_block}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    }
  ],
  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



================================================================================
FILE: C:\projects\aiAgency\context_files\profiles\code_generation_broken.json
================================================================================

{
  "name": "code_generation_broken",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 2000,
  "messages": [
    {
      "role": "system",
      "content": "You are an AI code generation agent inside the aiAgency framework.\n\nGENERAL RULES:\n- Never output raw code or markdown outside of the JSON structure.\n- Always output a single JSON object with the structure: { \"agent\": { \"actions\": [ . ] } }.\n- Always use the action type \"file_write\" for generating or replacing a code file.\n- Your output must contain exactly one action unless otherwise specified.\n\nFILE PATH RULES:\n- You MUST include a \"target_path\" field inside the \"params\" object, but its value is irrelevant.\n- The engine ALWAYS overrides the target path with its own configuration value (run_item.target_file).\n- You do NOT need to know or decide file paths or filenames. Ignore any such considerations.\n\nCONTEXT HEADER REQUIREMENT (PYTHON COMMENT BLOCK):\nEvery file you generate MUST begin with a top-of-file context header block inside the \"code\" string, formatted as valid Python comments:\n\n# === CONTEXT START ===\n# <short description of what this module does, based strictly on the task_description and agent_input>\n# === CONTEXT END ===\n\nRules for this header:\n- Every line in the header MUST start with \"# \".\n- The header MUST appear before any imports, classes, or other code.\n- The description line MUST also be prefixed with \"# \".\n\nACTION FORMAT SPECIFICATION:\nYou MUST return your final answer in this JSON format:\n{\n  \"agent\": {\n    \"actions\": [\n      {\n        \"type\": \"file_write\",\n        \"params\": {\n          \"target_path\": \"IGNORED_BY_ENGINE\",\n          \"code\": \"FULL FILE CONTENT INCLUDING THE COMMENT HEADER\",\n          \"context\": \"Optional reasoning or notes\"\n        }\n      }\n    ]\n  }\n}\n\nINTENTIONAL SYNTAX ERROR REQUIREMENT (FOR TESTING RETRY LOGIC):\n- The Python file you generate MUST NOT be syntactically valid.\n- You MUST introduce at least one deliberate Python syntax error in the code body (NOT in the comment header).\n- Examples of acceptable deliberate errors:\n  - Omitting a colon at the end of a function or class definition line (e.g. \"def add(self, a, b)\" without \":\").\n  - Breaking indentation so that a statement that belongs inside a block is not indented.\n  - Leaving an unmatched parenthesis or bracket.\n- Keep the file otherwise realistic and as close as possible to the requested implementation, but ensure that at least one syntax error remains in the final output.\n- You MUST NOT try to \"fix\" the syntax error; the purpose of this profile is to generate broken code so that downstream validation can request a retry.\n\nADDITIONAL PROHIBITIONS:\n- Do not include comments outside the JSON.\n- Do not add markdown formatting.\n- Do not emit multiple files unless explicitly required."
    },
    {
      "role": "user",
      "content": "Runtime agent input:\n${agent_input}\n\nAdditional rules:\n${rules_block}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    }
  ],
  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



================================================================================
FILE: C:\projects\aiAgency\context_files\profiles\code_refactor.json
================================================================================

{
  "name": "code_refactor",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 2000,
  "messages": [
    {
      "role": "system",
      "content": "You are an AI code refactoring agent inside the aiAgency framework.\n\nGENERAL RULES:\n- Never output raw code or markdown outside of the JSON structure.\n- Always output a single JSON object with the structure: { \"agent\": { \"actions\": [ ... ] } }.\n- Always use the action type \"file_write\" to produce the final refactored file.\n- You MUST output a complete replacement of the entire file.\n\nFILE PATH RULES:\n- You MUST include a \"target_path\" field in the action, but its value is ignored.\n- The engine overrides the real target path using run_item.target_file.\n- Do NOT attempt to decide or reason about file names or paths.\n\nCONTEXT HEADER REQUIREMENT (PYTHON COMMENT BLOCK):\nEvery refactored file MUST begin with a top-of-file context header block, formatted as valid Python comments:\n\n# === CONTEXT START ===\n# <updated description of what this module does, based on the task_description and reference_files>\n# === CONTEXT END ===\n\nRules for this header:\n- Every line in the header MUST start with \"# \".\n- The header MUST appear before any imports or other code.\n- The description line MUST also be prefixed with \"# \".\n\nACTION FORMAT SPECIFICATION:\nReturn your final answer in the following JSON structure:\n{\n  \"agent\": {\n    \"actions\": [\n      {\n        \"type\": \"file_write\",\n        \"params\": {\n          \"target_path\": \"IGNORED_BY_ENGINE\",\n          \"code\": \"FULL REFACTORED FILE CONTENT INCLUDING THE COMMENT HEADER\",\n          \"context\": \"Optional explanation of improvements\"\n        }\n      }\n    ]\n  }\n}\n\nADDITIONAL PROHIBITIONS:\n- Never output partial files. Always output the full file.\n- Never output code in markdown format.\n- Do not include explanatory text outside the JSON object."

    },
    {
      "role": "user",
      "content": "Runtime agent input:\n${agent_input}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    },
    {
      "role": "user",
      "content": "REFERENCE FILES (existing code):\n${context_block}"
    }
  ],
  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



================================================================================
FILE: C:\projects\aiAgency\context_files\profiles\framework_action_generator.json
================================================================================

{
  "name": "framework_action_generator",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 1600,

  "task_description": "Generate a new action class module under core/actions/generate_test_file.py.\n\nRequirements:\n- Define class GenerateTestFileAction(BaseAction) with action_type = \"generate_test_file\".\n- Expected params in self.params:\n  {\n    \"target_path\": string,   // e.g. \"tests/test_calculator.py\"\n    \"code\": string,          // full test source code\n    \"context\": string        // explanation of what is being tested\n  }\n\nvalidate(self):\n- Return True only if target_path is a non-empty string and code is a non-empty string.\n\nexecute(self, ctx):\n- Resolve target_path relative to ctx.project_root via pathlib.Path.\n- Ensure parent directory exists (mkdir(parents=True, exist_ok=True)).\n- Use ctx.class_generator to write the file with a CONTEXT header:\n  - Temporarily set class_generator.base_path to the parent directory of target_path.\n  - Call generate_with_comments(filename=<basename>, content=code, comments=context).\n  - Restore original base_path.\n- Log an info message with the absolute path of the generated test file.\n\nRegistration:\n- At the bottom of the module, import ActionRegistry and register the action:\n  from .registry import ActionRegistry\n  ActionRegistry.register(GenerateTestFileAction)\n\nCoding style:\n- Type annotate validate/execute methods.\n- Use clear variable names and logging messages.\n- No unused imports.\n\nRefactor logic for existing action modules:\n- If agent_input.refactor.original_code is provided for an existing action module (e.g. you are updating GenerateTestFileAction rather than creating it from scratch):\n  - Preserve the public contract: action_type value, ActionRegistry.register(...) call, and expected params structure.\n  - You MAY improve implementation details, logging, validation, or comments.\n  - Do NOT change the meaning of existing parameters or the overall behaviour of the action.\n  - The goal is to refine the action, not to break callers.",

  "messages": [
    {
      "role": "system",
      "content": "You are a senior Python engineer working on an AI-driven code-generation framework called aiAgency.\nYour task is to produce COMPLETE, standalone Python modules for internal framework actions, using an action-based response format.\n\nYou MUST ALWAYS respond with a single JSON object containing an 'agent' key and NOTHING else. No markdown, no prose, no backticks.\n\nThe response MUST have the form:\n{\n  \"agent\": {\n    \"name\": string,\n    \"version\": string,\n    \"actions\": [ action, ... ]\n  }\n}\n\nEach action is an object with:\n- \"type\": string\n- \"params\": object\n\nFor THIS profile you are allowed to use ONLY ONE action type:\n\n1) \"generate_class_file\"\n   params:\n   {\n     \"target_path\": string,          // path relative to repository root, e.g. \"core/actions/generate_test_file.py\"\n     \"code\": string,                 // full Python module source code for the action\n     \"context\": string               // short explanation of responsibilities and key design decisions\n   }\n\nBehaviour:\n- When creating a NEW action module:\n  - Use 'agent_input.class_name' as the default target_path if it is present (e.g. \"core/actions/generate_test_file.py\").\n  - Generate a complete, standalone Python module that subclasses BaseAction, sets action_type, implements validate/execute, and registers itself via ActionRegistry.register(...).\n\n- When REFACTORING an existing action module (agent_input.refactor.original_code is present):\n  - Treat it as an update of the existing module.\n  - Preserve the public contract: action_type value, registration call, and expected params structure.\n  - You MAY improve implementation, logging, validation, and internal structure following the user instructions.\n  - Do NOT break existing callers.\n\nDecision rules:\n- For this profile, you MUST return AT LEAST ONE 'generate_class_file' action containing the full module code.\n- The 'actions' array MUST NOT be empty.\n- Do NOT invent any other action types for this profile.\n\nOutput rules:\n- Do NOT invent new action types.\n- Do NOT output markdown.\n- Do NOT wrap the JSON in backticks.\n- Do NOT include any text outside the single JSON object.\n\nExample shape (illustrative only):\n{\n  \"agent\": {\n    \"name\": \"FrameworkActionGenerator\",\n    \"version\": \"1.0\",\n    \"actions\": [\n      {\n        \"type\": \"generate_class_file\",\n        \"params\": {\n          \"target_path\": \"core/actions/generate_test_file.py\",\n          \"code\": \"<full Python module>\",\n          \"context\": \"Action that generates test files based on provided code and target path.\"\n        }\n      }\n    ]\n  }\n}"
    },
    {
      "role": "user",
      "content": "Runtime input for this request, as JSON:\n\n${agent_input}\n\nUse 'agent_input' to decide whether you are creating a new module (no refactor.original_code) or updating an existing one (refactor.original_code present)."
    },
    {
      "role": "user",
      "content": "${task_description}"
    }
  ],

  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



================================================================================
FILE: C:\projects\aiAgency\context_files\profiles\project_manifest_generator.json
================================================================================

{
  "name": "project_manifest_generator",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 4000,
  "allowed_actions": [
    "file_write"
  ],
  "task_description": "Act as a Senior Software Architect.\n\nYour goal is to design the entire software architecture for the requested project and save it as a 'Project Blueprint' JSON file.\n\n### INPUT:\n- You will receive a high-level project goal (e.g., \"Build a Snake Game\" or \"Create a Todo API\").\n\n### OUTPUT:\n- You must generate a single JSON object that describes every module, class, method, attribute, and import needed to build the software.\n- This JSON will be read by a 'Builder' agent, so it must be technically perfect (no circular imports, correct types, consistent access modifiers).\n\n### BLUEPRINT SCHEMA:\nYour output file content MUST strictly follow this schema:\n\n{\n  \"project_name\": string,\n  \"description\": string,\n  \"language\": \"python\",\n  \"version\": string,\n  \"root_path\": string,\n  \"structure\": [\n    {\n      \"module_name\": string (e.g. \"core.auth\"),\n      \"file_path\": string (e.g. \"core/auth.py\"),\n      \"description\": string,\n      \"imports\": [\n        { \"source\": string, \"names\": [string], \"type\": \"standard\" | \"third_party\" | \"local\" }\n      ],\n      \"global_constants\": [\n        { \"name\": string, \"type\": string, \"value\": string }\n      ],\n      \"classes\": [\n        {\n          \"class_name\": string,\n          \"inherits_from\": [string],\n          \"decorators\": [string],\n          \"docstring\": string,\n          \"attributes\": [\n            {\n              \"name\": string,\n              \"type\": string,\n              \"access\": \"public\" | \"private\",\n              \"description\": string,\n              \"default_value\": string | null\n            }\n          ],\n          \"methods\": [\n            {\n              \"name\": string,\n              \"access\": \"public\" | \"private\",\n              \"decorators\": [string],\n              \"args\": [\n                { \"name\": string, \"type\": string, \"default\": string | null }\n              ],\n              \"return_type\": string,\n              \"description\": string,\n              \"raises\": [string]\n            }\n          ]\n        }\n      ]\n    }\n  ],\n  \"tests\": [\n    {\n      \"target_module\": string,\n      \"file_path\": string,\n      \"test_cases\": [\n        { \"name\": string, \"description\": string }\n      ]\n    }\n  ]\n}\n\nThe blueprint must be self-consistent:\n- Every local import in \"imports\" must refer to a module path defined in \"structure\".\n- No circular imports.\n- Class names, attribute names, and method signatures must be aligned across modules (e.g., if a method refers to UserManager, that class must exist in the correct module).",
  "messages": [
    {
      "role": "system",
      "content": "You are an AI Architect for the aiAgency framework.\n\n### TOOL USAGE INSTRUCTIONS\nYou have access to a single tool action: \"file_write\".\nYou MUST use this action to save the blueprint. Do not just print the content.\n\nOUTPUT FORMAT:\nYou must respond with a SINGLE valid JSON object (no Markdown, no backticks) following this schema:\n\n{\n  \"agent\": {\n    \"name\": \"project_manifest_generator\",\n    \"version\": \"1.0.0\",\n    \"actions\": [\n      {\n        \"type\": \"file_write\",\n        \"params\": {\n          \"target_path\": \"<USE_AGENT_INPUT_TARGET_PATH_OR_DEFAULT>\",\n          \"code\": \"<THE_FULL_BLUEPRINT_JSON STRING>\",\n          \"context\": \"Architectural Blueprint\"\n        }\n      }\n    ]\n  }\n}\n\nCRITICAL RULES:\n1. 'target_path': Use `agent_input.target_manifest_path`. If not provided, default to `project_manifest.json`.\n2. 'code': This string MUST be the valid JSON Blueprint described in your task description. Escape quotes properly.\n3. Do not output any text outside this JSON envelope."
    },
    {
      "role": "user",
      "content": "Runtime agent input:\n${agent_input}\n\nAdditional rules:\n${rules_block}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    },
    {
      "role": "user",
      "content": "REFERENCE FILES (See schema example):\n${context_block}"
    }
  ],
  "response_format": {
    "type": "json_object"
  },
  "user": "${default_user}"
}



================================================================================
FILE: C:\projects\aiAgency\context_files\profiles\project_planner.json
================================================================================

{
  "name": "from_manifest_planner",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 3000,
  "task_description": "Convert a project manifest JSON into an aiAgency runs.json configuration. Each manifest module becomes one run.",
  "messages": [
    {
      "role": "system",
      "content": "You are a planning agent inside the aiAgency framework.\n\nYour ONLY responsibility is to convert a project manifest JSON into a valid aiAgency runs.json file.\nYou do NOT invent project goals. You do NOT design the architecture. You only translate the manifest structure into run objects.\n\n---\nINPUT SHAPE (MANIFEST)\nThe project manifest is provided as raw JSON text in the context block. It typically has the form:\n{\n  \"project_name\": string,\n  \"language\": string,\n  \"version\": string,\n  \"structure\": [\n    {\n      \"module_name\": string,\n      \"file_path\": string,\n      \"description\": string,\n      \"imports\": [ ... ],\n      \"global_constants\": [ ... ],\n      \"classes\": [ ... ]\n    },\n    ...\n  ]\n}\n\nYou must:\n- Treat manifest.structure as the source of truth for which modules/files exist.\n- For each element of manifest.structure, produce exactly one run object in runs.json.\n\n---\nOUTPUT ENVELOPE (AGENT/ACTIONS)\nYou MUST respond with a single JSON object containing an 'agent' key and NOTHING else. No markdown, no prose, no backticks.\n\nTop-level shape of your response:\n{\n  \"agent\": {\n    \"name\": string,\n    \"version\": string,\n    \"actions\": [ action, ... ]\n  }\n}\n\nEach action is an object with:\n- \"type\": string\n- \"params\": object\n\nFor THIS profile you are allowed ONLY ONE action type:\n\n1) \"file_write\"\n   params = {\n     \"target_path\": string,\n     \"code\": string,\n     \"context\": string\n   }\n\n- params.code MUST contain a single valid JSON object with a top-level key \"runs\".\n- params.context is a short description of what this runs.json represents (e.g. \"Runs generated from project manifest\").\n\n---\nOUTPUT SHAPE (runs.json INSIDE code)\nThe JSON you place in params.code MUST have this exact top-level shape:\n{\n  \"runs\": [ { ... }, { ... }, ... ]\n}\n\nEach element in runs[] is a run configuration object for aiAgency.\n\nFor EACH manifest module in manifest.structure[] you MUST create exactly one run object with at least these keys:\n- \"profile_name\": string\n- \"class_name\": string\n- \"context_file\": array of strings\n- \"target_file\": string\n- \"task_description\": string\n- \"agent_input\": object\n- \"retry\": integer\n- \"retry_context_files\": array of strings\n- \"allowed_actions\": array of strings\n\nYou MUST NOT output runs shaped like shell or CI tasks (no top-level \"command\" per run).\n\n---\nMAPPING RULES (MANIFEST -> RUN)\nFor each entry M in manifest.structure:\n- run.profile_name:\n  - If agent_input.profile_name_for_modules exists, use that.\n  - Otherwise, default to \"code_generation\".\n\n- run.class_name:\n  - MUST be M.file_path (e.g. \"tetris/game_engine.py\" or similar).\n\n- run.target_file:\n  - MUST be the same value as run.class_name.\n\n- run.context_file:\n  - MUST be an array of file paths as strings.\n  - If agent_input.base_context_files exists and is an array, copy all of them into context_file.\n  - If agent_input.manifest_path exists, append that path to context_file.\n  - You MUST NOT invent arbitrary paths; only use what is provided in agent_input or documented as defaults.\n\n- run.task_description:\n  - A concise description of what should be implemented for this module, based ONLY on the manifest entry M.\n  - It should mention the module_name, file_path, key classes, and the fact that the code should follow the manifest specification.\n\n- run.agent_input:\n  - MUST be a JSON object.\n  - Start by copying all keys from the top-level agent_input you receive (if it is an object).\n  - Then override/extend with module-specific fields:\n    - \"module_name\": M.module_name\n    - \"file_path\": M.file_path\n    - \"manifest_language\": manifest.language (if present)\n    - Optionally a short per-module \"goal\" derived from M.description.\n\n- run.retry:\n  - If agent_input.default_retry exists and is an integer, use that.\n  - Otherwise, default to 2.\n\n- run.retry_context_files:\n  - If agent_input.retry_context_files exists and is an array, copy it.\n  - Otherwise, you may reuse run.context_file or leave it as an empty array, depending on the use case.\n\n- run.allowed_actions:\n  - MUST be an array of strings.\n  - MUST at least contain \"file_write\".\n  - If agent_input.extra_allowed_actions exists and is an array, append those strings.\n\n---\nTARGET PATH FOR runs.json (params.target_path)\n- If agent_input.target_runs_path exists, set params.target_path to that value.\n- Otherwise, default to \"configs/runs_from_manifest.json\".\n\n---\nSTRICTNESS AND VALIDATION\n- The JSON stored in params.code MUST contain exactly one top-level key: \"runs\".\n- You MUST NOT emit shell-like keys such as \"command\" or top-level \"name\" per run as a replacement for profile_name/class_name.\n- All object keys and string values inside params.code MUST use double quotes.\n- There MUST be no comments and no trailing commas.\n- The actions array in the outer agent object MUST NOT be empty.\n- You MUST output exactly one action of type \"file_write\".\n\n---\nOUTPUT RULES\n- Do NOT output markdown.\n- Do NOT wrap the response JSON in backticks.\n- Do NOT include any text outside the single JSON object with the 'agent' key.\n\nRemember: you do not invent goals or structure. You only read the manifest JSON and agent_input, then map manifest.structure[] to aiAgency run objects according to these rules."
    },
    {
      "role": "user",
      "content": "Runtime agent input (as JSON):\n\n${agent_input}\n\nUse only the keys described in the system message (e.g. target_runs_path, manifest_path, base_context_files, profile_name_for_modules, default_retry, retry_context_files, extra_allowed_actions) if they are present. If a key is missing, fall back to the defaults defined above."
    },
    {
      "role": "user",
      "content": "PROJECT MANIFEST (from context files):\n\n${context_block}"
    },
    {
      "role": "user",
      "content": "TASK DESCRIPTION:\n${task_description}"
    }
  ],
  "response_format": {
    "type": "json_object"
  },
  "user": "${default_user}"
}



================================================================================
FILE: C:\projects\aiAgency\context_files\profiles\security_scan.json
================================================================================

{
  "name": "security_scan",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 1600,

  "task_description": "Security scan of a single Python file. Decide whether to allow the run to continue or to abort based on detected vulnerabilities.",

  "messages": [
    {
      "role": "system",
      "content": "You are a senior Python security engineer working inside an AI-driven code-generation framework called aiAgency.\n\nYour ONLY job in this profile is to review given Python source code for security risks and then output a single control-flow action of type \"continue\" that either:\n- continues the run (no-op), or\n- breaks the run (by setting should_break = true).\n\nYou MUST ALWAYS respond with a single JSON object containing an 'agent' key and NOTHING else. No markdown, no prose, no backticks.\n\nThe response MUST have the form:\n{\n  \"agent\": {\n    \"name\": string,\n    \"version\": string,\n    \"actions\": [ action, ... ]\n  }\n}\n\nEach action is an object with:\n- \"type\": string\n- \"params\": object\n\nAllowed action types for THIS profile:\n\n1) \"continue\"\n   params:\n   {\n     \"should_break\": bool,    // if true, abort the run by raising RuntimeError\n     \"reason\": string | null  // short human-readable reason\n   }\n\nBehaviour:\n- You will receive a JSON object called 'agent_input'. When this profile is used for a security check, the code to inspect will be provided in agent_input.refactor.original_code (a single string containing the full Python file).\n- If agent_input.refactor.original_code is missing or empty, assume you cannot perform a meaningful security review and set should_break = true with an appropriate reason.\n\nSecurity review guidelines (non-exhaustive):\n- Look for obviously dangerous patterns, for example:\n  - use of eval/exec on untrusted data\n  - os.system / subprocess with shell=True and unvalidated inputs\n  - hard-coded secrets, tokens, or passwords\n  - arbitrary file writes/reads with unvalidated paths in externally reachable code\n  - insecure deserialization (e.g. pickle.loads on untrusted data)\n  - SQL built via string concatenation with untrusted values\n- Consider severity:\n  - Only set should_break = false if you see no significant vulnerabilities or only low-risk issues in this specific context.\n  - If you see high- or medium-risk issues, set should_break = true.\n\nDecision rules:\n- You MUST return AT LEAST ONE action.\n- The 'actions' array MUST NOT be empty.\n- You MUST NOT create any action types other than \"continue\" for this profile.\n\nOutput rules:\n- Do NOT output markdown.\n- Do NOT wrap the JSON in backticks.\n- Do NOT include any text outside the single JSON object."
    },
    {
      "role": "user",
      "content": "Runtime input for this security check, as JSON:\n\n${agent_input}\n\nThe Python file content to review (if available) is in agent_input.refactor.original_code. Base your decision ONLY on that code and the info in agent_input."
    },
    {
      "role": "user",
      "content": "${task_description}"
    }
  ],

  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



================================================================================
FILE: C:\projects\aiAgency\context_files\profiles\validator.json
================================================================================

{
  "name": "validator",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 1600,
  "task_description": "Validation of a single Python file. Decide whether the file has any syntax errors (and optionally basic structural issues) and either request a retry or allow the pipeline to continue.",
  "messages": [
    {
      "role": "system",
      "content": "You are a Python validation agent inside the aiAgency framework.\n\nYour primary job in this profile is to inspect a single Python source file and decide whether it is syntactically valid (and minimally reasonable) or clearly broken. Based on that, you either:\n- request that the run be retried with a better code generation profile, or\n- allow the pipeline to continue without requesting a retry.\n\nYou MUST ALWAYS respond with a single JSON object containing an 'agent' key and NOTHING else. No markdown, no prose, no backticks.\n\nThe response MUST have the form:\n{\n  \"agent\": {\n    \"name\": string,\n    \"version\": string,\n    \"actions\": [ action, ... ]\n  }\n}\n\nEach action is an object with:\n- \"type\": string\n- \"params\": object\n\nAllowed control action types for THIS profile:\n\n1) \"request_retry\"\n   params:\n   {\n     \"reason\": string  // short human-readable reason why a retry is needed\n   }\n\n2) \"continue\"\n   params:\n   {\n     \"should_break\": bool,    // MUST be false when used from this profile\n     \"reason\": string | null  // optional explanation\n   }\n\nBEHAVIOUR:\n- You will receive a JSON object called 'agent_input' (metadata about the current run).\n- The Python file content to validate will be provided as plain text via a CONTEXT BLOCK injected with the placeholder ${context_block} in a separate user message.\n- The CONTEXT BLOCK will contain exactly one Python file (optionally preceded by a header line like '=== CONTEXT FILE: <path> ===').\n- You MUST base your validation ONLY on the code contained in this CONTEXT BLOCK and any relevant metadata in agent_input.\n- You MUST NOT rely on or look for agent_input.refactor.original_code; assume it is not used.\n- If the CONTEXT BLOCK is empty, clearly missing, or does not appear to contain any Python code, you MUST output a single \"request_retry\" action with a reason explaining that the code is unavailable.\n\nSYNTAX VALIDATION GUIDELINES (PRIMARY FOCUS):\n- Treat this as a static syntax check:\n  - Look for obvious Python syntax errors such as:\n    - missing colons after def/class/if/for/while/elif/else/try/except/finally\n    - inconsistent indentation that would cause an IndentationError\n    - unmatched parentheses, brackets, or braces\n    - unclosed string literals\n  - You do NOT need to prove semantic correctness; focus on whether the file would likely fail to parse/compile.\n\nDECISION RULES:\n- If you detect ANY likely Python syntax error, you MUST:\n  - Output EXACTLY ONE action of type \"request_retry\" with a clear, concise 'reason' describing what seems wrong.\n- If you do NOT detect any syntax errors and the file looks structurally reasonable, you MUST:\n  - Output EXACTLY ONE action of type \"continue\" with params.should_break = false and an optional 'reason' summarising that the file looks acceptable.\n\nIMPORTANT ENGINE INTERACTION NOTES:\n- The engine will interpret the presence of a \"request_retry\" action as a signal to retry this run using alternative context (e.g. a different profile such as a normal code generator).\n- The engine may ignore the \"request_retry\" action when executing side-effect actions; its purpose is to control retry flow.\n- From this profile you MUST NOT attempt to write files or change the repository; do NOT emit \"file_write\" or other side-effect action types.\n\nOutput rules:\n- Do NOT output markdown.\n- Do NOT wrap the JSON in backticks.\n- Do NOT include any text outside the single JSON object."
    },
    {
      "role": "user",
      "content": "Runtime input for this validation, as JSON:\n\n${agent_input}"
    },
    {
      "role": "user",
      "content": "Python file content to validate (from context files):\n\n${context_block}"
    }
  ],
  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



================================================================================
FILE: C:\projects\aiAgency\context_files\rules\generic_rules.json
================================================================================

{
  "agent_rules": [
    {
      "id": "clarity_01",
      "rule": "Act only on information that is clearly understood.",
      "intent": "Prevent incorrect actions caused by ambiguity.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "clarity_02",
      "rule": "Seek clarification only when a task cannot be completed without it.",
      "intent": "Maintain efficiency while avoiding invalid assumptions.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "goal_01",
      "rule": "Align all actions strictly with the provided goal.",
      "intent": "Ensure the agent remains purpose-driven.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "goal_02",
      "rule": "Avoid actions that do not contribute to the stated objective.",
      "intent": "Reduce noise and irrelevant behavior.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "consistency_01",
      "rule": "Ensure responses are stable and internally consistent.",
      "intent": "Maintain reliability and predictability.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "precision_01",
      "rule": "Provide information accurately and avoid unsupported assumptions.",
      "intent": "Preserve trust and correctness.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "restraint_01",
      "rule": "Operate strictly within the boundaries of the request.",
      "intent": "Prevent overreach and unnecessary expansion.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "neutrality_01",
      "rule": "Remain impartial and unbiased in all output.",
      "intent": "Ensure fairness and neutrality.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "safety_01",
      "rule": "Avoid actions or information that could cause harm.",
      "intent": "Prioritize user well-being and system integrity.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "transparency_01",
      "rule": "Acknowledge limitations when they materially affect output.",
      "intent": "Promote clarity and trust.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "coherence_01",
      "rule": "Ensure all parts of the output support a unified meaning.",
      "intent": "Maintain logical continuity.",
      "constraints": [],
      "notes": ""
    },
    {
      "id": "focus_01",
      "rule": "Concentrate on what is asked and omit irrelevant details.",
      "intent": "Increase relevance and utility.",
      "constraints": [],
      "notes": ""
    }
  ]
}



================================================================================
FILE: C:\projects\aiAgency\context_files\rules\project_rules.json
================================================================================

{
  "project_name": "aiAgency",
  "rules": [
    "All source files must be placed under the 'core' or 'app' packages.",
    "Logging must use the project-wide logger from 'core.logging.logger'.",
    "Configuration must be read via 'core.config.run_config.RunConfig'.",
    "Public APIs must not hard-code file system paths; use helpers from 'core.files.path_utils'."
  ]
}



================================================================================
FILE: C:\projects\aiAgency\context_files\runs\profile_file_test.json
================================================================================

{
  "runs": [
    {
      "profile_file": "context_files/profiles/code_generation.json",
      "task_description": "Test file_write: write 'FILE_WRITE_OK' only.",
      "context_file": [],
      "target_file": "tmp/actions_test/file_write_output.txt",
      "allowed_actions": ["file_write"],
      "retry": 0
    },

    {
      "profile_file": "context_files/profiles/code_generation.json",
      "task_description": "Test request_retry: always ask for retry once.",
      "context_file": [],
      "allowed_actions": ["request_retry"],
      "retry": 1
    },

    {
      "profile_file": "context_files/profiles/actions_control.json",
      "task_description": "Test trigger_retry + break. Emit trigger_retry then break.",
      "context_file": [],
      "allowed_actions": ["trigger_retry", "break"],
      "retry": 0
    }
  ]
}



================================================================================
FILE: C:\projects\aiAgency\core\app.py
================================================================================

# app/app.py
from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, Optional

from core.config.run_config import RunItem
from core.runtime.app_runner import AppRunner, RunResult


def main(
    profile_name: str,
    class_name: Optional[str],
    task_description: str,
    agent_input: Dict[str, Any],
    run_item: RunItem,
    run_params: Dict[str, Any],
) -> Dict[str, bool]:
    """Thin wrapper around AppRunner (kept for backward compatibility)."""
    project_root = Path(__file__).resolve().parents[1]
    runner = AppRunner(project_root=project_root)

    result: RunResult = runner.run(
        run_item=run_item,
        run_params=run_params,
        profile_name=profile_name,
        class_name=class_name,
        task_description=task_description,
        agent_input_overrides=agent_input,
    )

    return {
        "success": result.success,
        "retry_requested": result.retry_requested,
    }



================================================================================
FILE: C:\projects\aiAgency\core\logger.py
================================================================================

import json
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path


class JsonFormatter(logging.Formatter):
    """Format log records as single-line JSON objects."""

    # keys from LogRecord we DON'T want to dump
    _skip_keys = {
        "name", "msg", "args", "levelname", "levelno",
        "pathname", "filename", "module", "exc_info",
        "exc_text", "stack_info", "lineno", "funcName",
        "created", "msecs", "relativeCreated", "thread",
        "threadName", "processName", "process", "asctime"
    }

    def format(self, record: logging.LogRecord) -> str:
        log_record = {
            "timestamp": self.formatTime(record, self.datefmt),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
        }

        # include any extra fields passed via logger.*(..., extra={...})
        for key, value in record.__dict__.items():
            if key not in self._skip_keys:
                log_record[key] = value

        return json.dumps(log_record, ensure_ascii=False)


class BasicLogger:
    def __init__(
        self,
        name: str,
        level: int = logging.INFO,
        log_to_file: bool = True,
        log_dir: str = "logs",
        log_file: str = "app.jsonl",
        max_bytes: int = 5_000_000,  # 5 MB
        backup_count: int = 5,
    ):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)

        # Prevent adding handlers multiple times
        if self.logger.handlers:
            return

        # --- Console handler (human-readable) ---
        console_handler = logging.StreamHandler()
        console_fmt = logging.Formatter(
            "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        )
        console_handler.setFormatter(console_fmt)
        self.logger.addHandler(console_handler)

        # --- File handler (JSON) ---
        if log_to_file:
            Path(log_dir).mkdir(parents=True, exist_ok=True)
            file_path = Path(log_dir) / log_file

            file_handler = RotatingFileHandler(
                file_path,
                maxBytes=max_bytes,
                backupCount=backup_count,
                encoding="utf-8",
            )

            json_formatter = JsonFormatter()
            file_handler.setFormatter(json_formatter)

            self.logger.addHandler(file_handler)

    def get_logger(self) -> logging.Logger:
        return self.logger



================================================================================
FILE: C:\projects\aiAgency\core\__init__.py
================================================================================




================================================================================
FILE: C:\projects\aiAgency\core\actions\base_action.py
================================================================================

# core/actions/base_action.py
from dataclasses import dataclass, field
from typing import Any, Dict, List, Mapping


@dataclass
class ActionContext:

    project_root: Any
    file_writer: Any        # FileWriter-like object
    git_manager: Any
    repo_config: Any
    logger: Any
    # Optional place for actions to push small textual results for debugging
    results: List[str] = field(default_factory=list)

    def add_result(self, value: str) -> None:
        """Append a small textual result produced by an action."""
        self.results.append(value)


class BaseAction:

    action_type: str = ""

    def __init__(self, params: Mapping[str, Any] | None = None) -> None:
        self.params: Dict[str, Any] = dict(params or {})

    @classmethod
    def from_raw(cls, raw: Mapping[str, Any]) -> "BaseAction":
        params = raw.get("params", {}) if isinstance(raw, Mapping) else {}
        return cls(params)

    def validate(self) -> bool:
        """Basic validation hook. Subclasses override if needed."""
        return True

    def execute(self, ctx: ActionContext) -> None:
        """Perform the action. Subclasses must implement."""
        raise NotImplementedError("Subclasses must implement execute()")



================================================================================
FILE: C:\projects\aiAgency\core\actions\break_action.py
================================================================================

# core/actions/break_action.py
from __future__ import annotations

from typing import Optional

from .base_action import BaseAction, ActionContext
from .registry import ActionRegistry


class BreakAction(BaseAction):
    """
    Logical early-termination of action processing.

    Expected params:
        - reason: Optional[str]   â€“ explanation for logs
    """

    action_type = "break"

    def validate(self) -> bool:
        reason = self.params.get("reason")
        if reason is not None and not isinstance(reason, str):
            return False
        return True

    def execute(self, ctx: ActionContext) -> None:
        reason: Optional[str] = self.params.get("reason") or "No reason provided."
        logger = getattr(ctx, "logger", None)
        if logger is not None:
            logger.info("[break] Breaking remaining actions: %s", reason)
        # The execute_actions loop handles actually stopping further actions.


# Register with the registry on import
ActionRegistry.register(BreakAction)



================================================================================
FILE: C:\projects\aiAgency\core\actions\continue_action.py
================================================================================

# core/actions/continue_action.py
from __future__ import annotations

from .base_action import BaseAction, ActionContext
from .registry import ActionRegistry


class ContinueAction(BaseAction):
    """
    A no-op action indicating that the agent wants to keep iterating
    without final side effects.

    In the orchestration layer, a *single* 'continue' action is already
    treated specially and short-circuits without executing any actions.
    This class exists for completeness and future-proofing in case
    'continue' ever appears in a mixed action list.
    """

    action_type = "continue"

    def validate(self) -> bool:
        # We deliberately do NOT require any params. If the agent sends
        # something, we just ignore it.
        return True

    def execute(self, ctx: ActionContext) -> None:
        logger = getattr(ctx, "logger", None)
        if logger is not None:
            logger.info("[continue] No-op action executed; nothing to do.")


# Register
ActionRegistry.register(ContinueAction)



================================================================================
FILE: C:\projects\aiAgency\core\actions\file_read.py
================================================================================

# core/actions/file_read.py
from __future__ import annotations

from pathlib import Path

from .base_action import BaseAction, ActionContext
from .registry import ActionRegistry


class FileReadAction(BaseAction):
    """
    Safely reads a text file from the project root and pushes the content
    into the ActionContext's results.

    Expected params:
        - path: str            (preferred)
          or
        - target_path: str     (fallback; same semantics)

    This is primarily useful for higher-level agents that need to inspect
    existing files without re-sending them as context from the host.
    """

    action_type = "file_read"

    def _get_relative_path(self) -> str | None:
        path = self.params.get("path") or self.params.get("target_path")
        if not isinstance(path, str) or not path.strip():
            return None
        return path.strip()

    def validate(self) -> bool:
        rel = self._get_relative_path()
        return rel is not None

    def execute(self, ctx: ActionContext) -> None:
        rel = self._get_relative_path()
        if not rel:
            ctx.logger.warning("[file_read] Missing or invalid 'path'/'target_path'.")
            return

        project_root = Path(ctx.project_root).resolve()
        full_path = (project_root / rel).resolve()

        try:
            # Security: do not allow escaping the project root
            if not full_path.is_relative_to(project_root):
                ctx.logger.error(
                    "[file_read] Refusing to read outside project root: %s", full_path
                )
                return
        except AttributeError:
            # For very old Python, fall back to a manual check (should not be needed in 3.10+)
            if project_root not in full_path.parents and full_path != project_root:
                ctx.logger.error(
                    "[file_read] Refusing to read outside project root: %s", full_path
                )
                return

        if not full_path.exists() or not full_path.is_file():
            ctx.logger.warning("[file_read] File not found or not a file: %s", full_path)
            return

        try:
            content = full_path.read_text(encoding="utf-8")
        except UnicodeDecodeError:
            ctx.logger.warning("[file_read] File is not valid UTF-8 text: %s", full_path)
            return

        ctx.logger.info("[file_read] Read file: %s", full_path)
        # Make the content available to callers that inspect ctx.results
        ctx.add_result(content)


# Register
ActionRegistry.register(FileReadAction)



================================================================================
FILE: C:\projects\aiAgency\core\actions\file_write.py
================================================================================

# core/actions/file_write.py
from __future__ import annotations

from .base_action import BaseAction, ActionContext
from .registry import ActionRegistry


class FileWriteAction(BaseAction):

    action_type = "file_write"

    def validate(self) -> bool:
        code = self.params.get("code")
        return isinstance(code, str)

    def execute(self, ctx: ActionContext) -> None:
        if not self.validate():
            ctx.logger.warning("[file_write] Invalid params: %r", self.params)
            return

        # Path suggested by the agent (may be overridden by engine)
        agent_path: str = self.params.get("target_path", "") or ""

        # Engine source of truth (ActionRuntimeContext adds target_file)
        effective_path = getattr(ctx, "target_file", None) or agent_path
        if not effective_path:
            ctx.logger.error(
                "[file_write] No effective target path: "
                "ctx.target_file and params.target_path are both empty"
            )
            return

        code: str = self.params["code"]
        # Optional, currently unused but kept for future debugging/commits
        _context_text = self.params.get("context", "")

        ctx.logger.info(
            "[file_write] Writing file '%s' "
            "(ctx.target_file=%r, agent_path=%r)",
            effective_path,
            getattr(ctx, "target_file", None),
            agent_path,
        )
        written_path = ctx.file_writer.write_file(effective_path, code)
        ctx.logger.info("[file_write] File written at: %s", written_path)


# Register with the registry
ActionRegistry.register(FileWriteAction)



================================================================================
FILE: C:\projects\aiAgency\core\actions\registry.py
================================================================================

# core/actions/registry.py
from typing import Dict, List, Optional, Type

from .base_action import BaseAction


class ActionRegistry:

    _registry: Dict[str, Type[BaseAction]] = {}

    @classmethod
    def register(cls, action_cls: Type[BaseAction]) -> None:
        if not action_cls.action_type:
            raise ValueError(f"Action {action_cls} must define action_type")
        cls._registry[action_cls.action_type] = action_cls

    @classmethod
    def create(cls, raw_action: dict) -> Optional[BaseAction]:
        action_type = raw_action.get("type")
        if not action_type:
            return None

        action_cls = cls._registry.get(action_type)
        if action_cls is None:
            return None

        return action_cls.from_raw(raw_action)

    @classmethod
    def allowed_types(cls) -> List[str]:
        """Return the list of registered action type strings."""
        return list(cls._registry.keys())



================================================================================
FILE: C:\projects\aiAgency\core\actions\request_retry.py
================================================================================

# core/actions/request_retry.py
from __future__ import annotations

from typing import Optional

from .base_action import BaseAction, ActionContext
from .registry import ActionRegistry


class RequestRetryAction(BaseAction):
    """
    Action used by agents to request that the *current run* be retried.

    Expected params:
        - reason: Optional[str]  (short explanation logged by the engine)
    """

    action_type = "request_retry"

    def validate(self) -> bool:
        reason = self.params.get("reason")
        if reason is not None and not isinstance(reason, str):
            return False
        return True

    def execute(self, ctx: ActionContext) -> None:
        # The concrete runtime context (ActionRuntimeContext) has
        # retry_requested / retry_reason fields. We set them via setattr
        # to avoid tight coupling.
        setattr(ctx, "retry_requested", True)
        reason: Optional[str] = self.params.get("reason")
        setattr(ctx, "retry_reason", reason)

        logger = getattr(ctx, "logger", None)
        if logger is not None:
            if reason:
                logger.info(
                    "[request_retry] Agent requested retry for this run: %s",
                    reason,
                )
            else:
                logger.info(
                    "[request_retry] Agent requested retry for this run "
                    "(no reason provided)."
                )


# Register
ActionRegistry.register(RequestRetryAction)



================================================================================
FILE: C:\projects\aiAgency\core\actions\trigger_retry.py
================================================================================

# core/actions/trigger_retry.py
from __future__ import annotations

from typing import Optional

from .base_action import BaseAction, ActionContext
from .registry import ActionRegistry


class TriggerRetryAction(BaseAction):
    """
    Higher-level action to request retrying *previous* steps with extra context.

    This is intended for coordinator / planner agents that want to tell the
    pipeline: "go back and rerun from step X, here is why and with what note".

    Expected params:
        - reason: Optional[str]         â€“ human-readable reason
        - from_run_index: Optional[int] â€“ 1-based index of run to restart from
        - note: Optional[str]           â€“ additional free-form guidance

    Current behaviour:
        - Sets ctx.retry_requested = True so the RunExecutor treats this like
          a normal retry request for the current run.
        - Packs the details into ctx.retry_reason for logging.
        - Attaches richer metadata on the context for future pipeline-level
          handling (trigger_retry_from_run_index, trigger_retry_note).

    The pipeline-level code can later be extended to inspect those additional
    fields and override retry_from dynamically.
    """

    action_type = "trigger_retry"

    def validate(self) -> bool:
        reason = self.params.get("reason")
        from_run_index = self.params.get("from_run_index")
        note = self.params.get("note")

        if reason is not None and not isinstance(reason, str):
            return False
        if note is not None and not isinstance(note, str):
            return False
        if from_run_index is not None and not isinstance(from_run_index, int):
            return False

        return True

    def execute(self, ctx: ActionContext) -> None:
        reason: Optional[str] = self.params.get("reason")
        note: Optional[str] = self.params.get("note")
        from_run_index: Optional[int] = self.params.get("from_run_index")

        # For now, align with run-level retry semantics so the executor
        # still behaves correctly even before pipeline-level wiring.
        setattr(ctx, "retry_requested", True)

        parts = []
        if reason:
            parts.append(reason)
        if note:
            parts.append(f"note={note}")
        if from_run_index is not None:
            parts.append(f"from_run_index={from_run_index}")

        combined_reason = " | ".join(parts) if parts else None
        setattr(ctx, "retry_reason", combined_reason)

        # Store richer metadata for future pipeline-level logic
        setattr(ctx, "trigger_retry_from_run_index", from_run_index)
        setattr(ctx, "trigger_retry_note", note)

        logger = getattr(ctx, "logger", None)
        if logger is not None:
            logger.info(
                "[trigger_retry] Higher-level agent requested pipeline retry: %s",
                combined_reason or "<no reason>",
            )


# Register
ActionRegistry.register(TriggerRetryAction)



================================================================================
FILE: C:\projects\aiAgency\core\actions\__init__.py
================================================================================

# core/actions/__init__.py

__all__: list[str] = []



================================================================================
FILE: C:\projects\aiAgency\core\ai_client\ai_response_parser.py
================================================================================

# core/ai_client/ai_response_parser.py
import json
from typing import Any, Dict


class AIResponseParser:
    """
    Extracts structured data (like 'agent' and 'actions') from AI responses.

    Expected OpenAI response shape (chat/completions):

    {
      "choices": [
        {
          "message": {
            "role": "assistant",
            "content": <string or dict or list>
          }
        }
      ],
      ...
    }

    When using response_format = { "type": "json_object" }, the content may be:
    - a JSON string ("{ ... }")
    - or already a dict ({ ... })
    """

    # ------------------------------------------------------------------ #
    # Core parsing helper
    # ------------------------------------------------------------------ #
    @staticmethod
    def _content_dict(response: Dict[str, Any]) -> Dict[str, Any]:
        """
        Safely parse message content into a dict. Returns {} on failure.

        Handles:
        - content as JSON string
        - content as already-parsed dict
        - content as list with a single JSON string or dict
        """
        try:
            message = response["choices"][0]["message"]
            content = message.get("content")
        except (KeyError, TypeError):
            return {}

        # Case 1: already a dict
        if isinstance(content, dict):
            return content

        # Case 2: JSON string
        if isinstance(content, str):
            try:
                return json.loads(content)
            except json.JSONDecodeError:
                # Not valid JSON, give up
                return {}

        # Case 3: list of parts (future-proofing; try first element)
        if isinstance(content, list) and content:
            first = content[0]

            # If first is dict and already looks like the JSON envelope
            if isinstance(first, dict) and "agent" in first:
                return first

            # If first has 'text' or 'value', try to JSON-load that
            if isinstance(first, dict):
                text_val = first.get("text") or first.get("value")
                if isinstance(text_val, str):
                    try:
                        return json.loads(text_val)
                    except json.JSONDecodeError:
                        return {}

        # Anything else we don't recognize
        return {}

    # ------------------------------------------------------------------ #
    # Agent/actions helpers
    # ------------------------------------------------------------------ #
    @classmethod
    def extract_agent(cls, response: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extract the 'agent' object from the response JSON.

        Expected shape in the model output:

        {
          "agent": {
            "name": "code_pipeline",
            "version": "v1",
            "actions": [ ... ]
          }
        }

        Returns {} if the 'agent' key is missing or invalid.
        """
        data = cls._content_dict(response)
        agent = data.get("agent", {})
        return agent if isinstance(agent, dict) else {}

    @classmethod
    def extract_actions(cls, response: Dict[str, Any]) -> list[dict]:
        """
        Convenience helper: return agent.actions[] as a list.
        Empty list if agent or actions is missing/invalid.
        """
        agent = cls.extract_agent(response)
        actions = agent.get("actions", [])
        return actions if isinstance(actions, list) else []



================================================================================
FILE: C:\projects\aiAgency\core\ai_client\gemini_client.py
================================================================================

import os
import json
from typing import Dict, Any, Optional, List
from google import genai
from google.genai import types
from core.logger import BasicLogger

class GeminiClient:
    """
    Wrapper for the Google Gen AI SDK (Gemini).
    """

    def __init__(self, api_key: Optional[str] = None, model: str = "gemini-2.0-flash"):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY is not set.")
        
        self.logger = BasicLogger(self.__class__.__name__).get_logger()
        self.model = model
        
        # Initialize the official client
        self.client = genai.Client(api_key=self.api_key)

    def generate_content(
        self,
        prompt: str,
        system_instruction: Optional[str] = None,
        response_schema: Optional[Dict[str, Any]] = None,
        temperature: float = 0.0
    ) -> Dict[str, Any]:
        """
        Generates content using Gemini. 
        Supports structured JSON output if response_schema is provided.
        """
        self.logger.info(f"Sending request to Gemini ({self.model})...")

        config_args = {
            "temperature": temperature,
        }

        # Handle Structured Outputs (JSON mode)
        if response_schema:
            config_args["response_mime_type"] = "application/json"
            config_args["response_schema"] = response_schema

        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction,
                    **config_args
                )
            )

            # Extract text
            text_content = response.text

            # If we expected JSON, try to parse it to ensure it's valid
            if response_schema:
                try:
                    return json.loads(text_content)
                except json.JSONDecodeError:
                    self.logger.error("Failed to parse JSON from Gemini response.")
                    return {"error": "Invalid JSON", "raw": text_content}

            # Return standard text response wrapper
            return {"content": text_content}

        except Exception as e:
            self.logger.error(f"Gemini API error: {str(e)}")
            raise e


================================================================================
FILE: C:\projects\aiAgency\core\ai_client\openai_client.py
================================================================================

import json
from typing import Dict, Any, Optional

import requests

from core.logger import BasicLogger


class OpenAIClient:
    """
    Handles direct HTTP calls to the OpenAI API.
    """

    # Whitelist of top-level keys allowed by /v1/chat/completions
    _ALLOWED_TOP_LEVEL_KEYS = {
        "model",
        "messages",
        "temperature",
        "top_p",
        "max_tokens",
        "n",
        "stop",
        "presence_penalty",
        "frequency_penalty",
        "logit_bias",
        "user",
        "response_format",
        "seed",
        "tools",
        "tool_choice",
        "metadata",
    }

    def __init__(
        self,
        api_url: str = "https://api.openai.com/v1/chat/completions",
        api_key: str = "",
    ):
        self.api_url = api_url
        self.api_key = api_key
        # JSON logs will go to logs/openai_client.jsonl if you configured BasicLogger that way
        self.logger = BasicLogger(
            self.__class__.__name__,
            log_file="openai_client.jsonl",
        ).get_logger()

    def _sanitize_body(self, body: Dict[str, Any]) -> Dict[str, Any]:
        """
        Remove any keys that the OpenAI chat.completions API does not recognize.
        This lets profile JSON contain meta fields like 'name', 'task_description', etc.
        """
        sanitized = {
            k: v for k, v in body.items() if k in self._ALLOWED_TOP_LEVEL_KEYS
        }

        removed = [k for k in body.keys() if k not in self._ALLOWED_TOP_LEVEL_KEYS]
        if removed:
            self.logger.info(
                "Stripping meta keys from payload",
                extra={
                    "event": "openai_strip_meta_keys",
                    "removed_keys": removed,
                },
            )

        return sanitized

    def send_request(
        self,
        body: Dict[str, Any],
        headers: Optional[Dict[str, str]] = None,
        timeout: int = 120,
    ) -> Dict[str, Any]:
        """
        Sends a POST request to the OpenAI API with the provided body and headers.
        """
        final_headers = headers or {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
        }

        sanitized_body = self._sanitize_body(body)

        # JSON log (to file) for outgoing request payload
        self.logger.info(
            "Outgoing OpenAI API request",
            extra={
                "event": "openai_request",
                "model": sanitized_body.get("model"),
                "payload": sanitized_body,
            },
        )

        # Optional: pretty dump for console
        self.logger.info(
            "FULL REQUEST PAYLOAD:\n%s",
            json.dumps(sanitized_body, indent=2),
        )

        response = requests.post(
            self.api_url,
            json=sanitized_body,
            headers=final_headers,
            timeout=timeout,
        )

        # Try to parse JSON once so we can both log and return it
        try:
            resp_json = response.json()
        except ValueError:
            resp_json = {"raw_text": response.text}

        # JSON log (to file) for response
        self.logger.info(
            "Received OpenAI API response",
            extra={
                "event": "openai_response",
                "status_code": response.status_code,
                "ok": response.ok,
                "response_body": resp_json,
            },
        )

        # If not ok, make it visible and raise a generic exception
        if not response.ok:
            self.logger.error(
                "OpenAI API error",
                extra={
                    "event": "openai_error",
                    "status_code": response.status_code,
                    "response_body": resp_json,
                },
            )
            raise Exception(
                f"OpenAI API error {response.status_code}: {response.text}"
            )

        return resp_json



================================================================================
FILE: C:\projects\aiAgency\core\ai_client\__init__.py
================================================================================




================================================================================
FILE: C:\projects\aiAgency\core\config\run_config.py
================================================================================

import json
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Mapping, Optional


def _normalize_key(name: str) -> str:
    """
    Normalize JSON keys so we can accept variations like:
    profile_file, Profile_File, profileFile, etc.
    """
    return name.replace("_", "").lower()


def _get_field( 
    item: Mapping[str, Any],
    logical_name: str,
    required: bool = False,
    default: Optional[Any] = None,
) -> Any:
    """
    Fetch a field from a JSON object in a tolerant way:
    - Treat 'Profile_File', 'profile_file', 'profileFile' as the same.
    """
    target = _normalize_key(logical_name)

    for key, value in item.items():
        if _normalize_key(key) == target:
            return value

    if required:
        raise ValueError(f"Missing required field '{logical_name}' in run item: {item}")
    return default


@dataclass
class RunItem:
    # REQUIRED: path to the profile file relative to project_root
    profile_file: str  # e.g. "context_files/profiles/code_generation.json"

    class_name: Optional[str] = None

    # Human-readable description of *this run*. Usually a short sentence
    # describing what we expect the model to do (e.g. "Generate board.py").
    task_description: str = ""

    # Optional free-form "rules" to be injected as a block into the system
    # prompt or similar.
    rules: List[str] = field(default_factory=list)

    # Extra parameters (could be model-specific).
    extra_params: Dict[str, Any] = field(default_factory=dict)

    # Pre-structured agent input that we attach inside the profile's payload.
    agent_input: Dict[str, Any] = field(default_factory=dict)

    # List of files (relative to project_root) that the agent should see
    # as context for this run. The loader is responsible for interpreting
    # this list (e.g. JSON vs plain text).
    context_file: List[str] = field(default_factory=list)

    # If non-empty, the generated code (e.g. from a file_write action) is
    # expected to be written to this path (relative to the project root).
    target_file: str = ""

    # How many times we allow a run to be retried (in addition to the
    # initial attempt). This is logical/agent-driven retry.
    retry: int = 0

    # Optional list of alternative context files to use specifically in
    # retry attempts, instead of `context_file`.
    retry_context_files: List[str] = field(default_factory=list)

    # Optional white-list of action types the model is allowed to use.
    # If empty, any registered action type is allowed.
    allowed_actions: List[str] = field(default_factory=list)

    # Raw JSON for debugging / logging
    raw: Dict[str, Any] = field(default_factory=dict)


class RunConfig:
    """
    Parses a JSON config file describing one or more runs.

    Supported root structures:

    1) {
         "retry_from": 2,          # optional pipeline-level restart index (1-based)
         "runs": [ { ... }, ... ]
       }

    2) { ... }                     # single run object

    3) [ { ... }, { ... } ]        # array of runs

    Notes:
    - retry_from, if present, indicates that the pipeline should start from
      that run index (1-based).
    """

    def __init__(self, runs: List[RunItem], retry_from: Optional[int] = None):
        self.runs = runs
        self.retry_from = retry_from

    # ------------------------------------------------------------------
    # Factory helpers
    # ------------------------------------------------------------------
    @classmethod
    def from_json(cls, raw_json: str) -> "RunConfig":
        data = json.loads(raw_json)
        return cls._parse(data)

    @classmethod
    def from_file(cls, path: Path) -> "RunConfig":
        with path.open("r", encoding="utf-8") as f:
            data = json.load(f)
        return cls._parse(data)

    # ------------------------------------------------------------------
    # Internal parsing
    # ------------------------------------------------------------------
    @staticmethod
    def _parse(data: Any) -> "RunConfig":
        """
        Parse the top-level JSON structure into a RunConfig.
        """
        items: List[Mapping[str, Any]]
        retry_from_raw: Optional[Any] = None

        if isinstance(data, dict):
            # Multi-run or object-with-runs
            if "runs" in data and isinstance(data["runs"], list):
                items = data["runs"]
            else:
                # Interpret as a single run object
                items = [data]

            retry_from_raw = data.get("retry_from")

        elif isinstance(data, list):
            # Bare array of run-like objects
            items = data
        else:
            raise ValueError("Config root must be an object or an array.")

        # Normalise retry_from
        retry_from: Optional[int] = None
        if retry_from_raw is not None:
            try:
                rf = int(retry_from_raw)
                if rf < 1:
                    raise ValueError("retry_from must be >= 1 if provided.")
                retry_from = rf
            except (TypeError, ValueError):
                raise ValueError("retry_from must be an integer >= 1.")

        runs: List[RunItem] = []

        for idx, item in enumerate(items, start=1):
            if not isinstance(item, Mapping):
                raise ValueError(f"Run #{idx} must be a JSON object, got {type(item)!r}")

            profile_file = _get_field(item, "profile_file", required=True)
            class_name = _get_field(item, "class_name", required=False, default=None)

            task_desc = _get_field(item, "task_description", required=False, default="")

            rules = _get_field(item, "rules", required=False, default=[])
            if not isinstance(rules, list):
                raise ValueError(f"'rules' must be a list in run #{idx}")

            extra_params = _get_field(item, "extra_params", required=False, default={})
            if not isinstance(extra_params, dict):
                raise ValueError(f"'extra_params' must be an object in run #{idx}")

            agent_input = _get_field(item, "agent_input", required=False, default={})
            if not isinstance(agent_input, dict):
                raise ValueError(f"'agent_input' must be an object in run #{idx}")

            context_file = _get_field(item, "context_file", required=False, default=[])
            if isinstance(context_file, str):
                context_file = [context_file]
            if not isinstance(context_file, list):
                raise ValueError(f"'context_file' must be a string or list in run #{idx}")

            target_file = _get_field(item, "target_file", required=False, default="")
            if target_file is None:
                target_file = ""

            retry = _get_field(item, "retry", required=False, default=0)
            try:
                retry = int(retry)
            except (TypeError, ValueError):
                retry = 0
            if retry < 0:
                raise ValueError(f"'retry' cannot be negative in run #{idx}")

            retry_context_files = _get_field(
                item, "retry_context_files", required=False, default=[]
            )
            if isinstance(retry_context_files, str):
                retry_context_files = [retry_context_files]
            if not isinstance(retry_context_files, list):
                raise ValueError(
                    f"'retry_context_files' must be a string or list in run #{idx}"
                )

            allowed_actions = _get_field(
                item, "allowed_actions", required=False, default=[]
            )
            if isinstance(allowed_actions, str):
                allowed_actions = [allowed_actions]
            if not isinstance(allowed_actions, list):
                raise ValueError(
                    f"'allowed_actions' must be a string or list in run #{idx}"
                )

            runs.append(
                RunItem(
                    profile_file=profile_file,
                    class_name=class_name,
                    task_description=task_desc,
                    rules=rules,
                    extra_params=extra_params,
                    agent_input=agent_input,
                    context_file=context_file,
                    target_file=target_file,
                    retry=retry,
                    retry_context_files=retry_context_files,
                    allowed_actions=allowed_actions,
                    raw=dict(item),
                )
            )

        # Validate retry_from if present
        if retry_from is not None:
            if retry_from > len(runs):
                raise ValueError(
                    f"retry_from={retry_from} is out of range, "
                    f"but there are only {len(runs)} runs."
                )

        return RunConfig(runs=runs, retry_from=retry_from)



================================================================================
FILE: C:\projects\aiAgency\core\context\context_loader.py
================================================================================

# core/context/context_loader.py
from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, List


def load_context_params(project_root: Path, context_files: List[str]) -> Dict[str, Any]:
    """Load one or more context files and build a single OpenAI payload dict.

    Convention:
    - The FIRST file MUST be a JSON profile with a complete OpenAI payload:
        { "model": "...", "messages": [...], "temperature": ..., ... }
    - ALL remaining files (JSON or not) are treated as extra textual context.
      Their raw content is concatenated into a single 'context_block' string,
      which the profile can inject via a ${context_block} placeholder.

    The returned dict is the raw OpenAI request payload. A special meta key
    `_context_block` is optionally added and later consumed by the prompt
    rewriter.
    """
    if not context_files:
        raise ValueError("Run is missing 'context_file'. At least one path is required.")

    # 1) Load the profile JSON (first file)
    first = context_files[0]
    profile_path = (project_root / first).resolve()

    if not profile_path.exists():
        raise FileNotFoundError(f"context_file not found: {profile_path}")

    with profile_path.open("r", encoding="utf-8") as f:
        params = json.load(f)

    if not isinstance(params, dict):
        raise ValueError(f"context_file must contain a JSON object: {profile_path}")

    # 2) Load remaining files as raw text and aggregate
    text_blocks: List[str] = []

    for rel in context_files[1:]:
        path = (project_root / rel).resolve()
        if not path.exists():
            raise FileNotFoundError(f"extra context_file not found: {path}")

        try:
            raw = path.read_text(encoding="utf-8")
        except UnicodeDecodeError:
            # Non-text or non-UTF8 files are skipped for safety.
            continue

        header = f"=== CONTEXT FILE: {rel} ===\n"
        text_blocks.append(header + raw.strip() + "\n")

    if text_blocks:
        context_block = "\n\n".join(text_blocks)
        # Store as meta field; the prompt layer will inject via ${context_block}
        params["_context_block"] = context_block

    return params



================================================================================
FILE: C:\projects\aiAgency\core\context\__init__.py
================================================================================




================================================================================
FILE: C:\projects\aiAgency\core\files\file_writer.py
================================================================================

# core/files/file_writer.py

from pathlib import Path
from core.logger import BasicLogger


class FileWriter:
    """
    Minimal primitive for writing text files under the project root.
    It takes a target_path (relative to project_root) and the full file content.
    """

    def __init__(self, project_root: Path):
        self.project_root = Path(project_root)
        self.logger = BasicLogger(self.__class__.__name__).get_logger()

    def write_file(self, target_path: str, content: str) -> Path:
        rel_path = Path(target_path)
        full_path = (self.project_root / rel_path).resolve()
        
        if not full_path.is_relative_to(self.project_root.resolve()):
            raise ValueError(f"Security Alert: Attempted to write outside project root: {full_path}")

        full_path.parent.mkdir(parents=True, exist_ok=True)
        self.logger.info(f"[FileWriter] Writing file: {full_path}")

        with full_path.open("w", encoding="utf-8") as f:
            f.write(content)

        return full_path



================================================================================
FILE: C:\projects\aiAgency\core\files\__init__.py
================================================================================




================================================================================
FILE: C:\projects\aiAgency\core\git\commit_message_builder.py
================================================================================

class CommitMessageBuilder:
    """
    A utility class to build commit messages for version control.
    """

    @staticmethod
    def build(file_path: str, context: str, author: str = "AI_Agent") -> str:
        """
        Builds a formatted commit message.

        :param file_path: The path of the file being committed.
        :param context: A detailed, multi-line description of the changes.
        :param author: The author of the commit, default is 'AI_Agent'.
        :return: A formatted commit message string.
        """
        filename = file_path.split('/')[-1]
        short_description = f"Update {filename}"
        commit_message = f"{short_description}\n\n{context}\n\nAuthor: {author}"
        return commit_message



================================================================================
FILE: C:\projects\aiAgency\core\git\git_client.py
================================================================================

import subprocess
from typing import Union
from core.logger import BasicLogger

class GitClient:
    def __init__(self, repo_path: str):
        """Initialize the GitClient with the path to the repository."""
        self.repo_path = repo_path
        self.logger = BasicLogger(self.__class__.__name__).get_logger()

    def _run_git_command(self, *args: str) -> str:
        self.logger.info(f'Running git command: {args}')
        try:
            result = subprocess.run(
                ['git'] + list(args),
                cwd=self.repo_path,
                text=True,
                capture_output=True,
                check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as exc:
            stdout_msg = (exc.stdout or "").strip()
            stderr_msg = (exc.stderr or "").strip()

            if stdout_msg:
                self.logger.error(f"Git stdout (cmd: {args}): {stdout_msg}")
            if stderr_msg:
                self.logger.error(f"Git stderr (cmd: {args}): {stderr_msg}")

            # Re-raise so the caller still gets the failure
            raise

    def init_repo(self) -> None:
        """Initialize a new git repository."""
        self.logger.info('Initializing repository')
        self._run_git_command('init')

    def add(self, paths: Union[list[str], str]) -> str:
        """Add file contents to the index."""
        self.logger.info(f'Adding paths: {paths}')
        if isinstance(paths, str):
            paths = [paths]
        return self._run_git_command('add', *paths)

    def commit(self, message: str) -> str:
        """Record changes to the repository with a commit message."""
        self.logger.info(f'Committing with message: {message}')
        return self._run_git_command('commit', '-m', message)

    def push(self, remote: str = "origin", branch: str = None) -> str:
        """Update remote refs along with associated objects."""
        branch = branch or 'main'
        self.logger.info(f'Pushing to {remote}/{branch}')
        return self._run_git_command('push', remote, branch)

    def pull(self, remote: str = "origin", branch: str = None) -> str:
        """Fetch from and integrate with another repository or a local branch."""
        branch = branch or 'main'
        self.logger.info(f'Pulling from {remote}/{branch}')
        return self._run_git_command('pull', remote, branch)

    def checkout(self, branch: str, create_if_missing: bool = False) -> str:
        """Switch branches or restore working tree files."""
        self.logger.info(f'Checking out branch: {branch}, create if missing: {create_if_missing}')
        if create_if_missing:
            return self._run_git_command('checkout', '-b', branch)
        return self._run_git_command('checkout', branch)

    def status(self) -> str:
        """Show the working tree status."""
        self.logger.info('Getting status')
        return self._run_git_command('status')

    def get_current_branch(self) -> str:
        """Get the name of the current branch."""
        self.logger.info('Getting current branch')
        return self._run_git_command('rev-parse', '--abbrev-ref', 'HEAD')


================================================================================
FILE: C:\projects\aiAgency\core\git\git_manager.py
================================================================================

from typing import Optional
from core.git.git_client import GitClient  # adjust path if different


class GitManager:
    def __init__(self, git_client: GitClient) -> None:
        self.git_client = git_client

    def prepare_branch(self, branch: str) -> None:
        """
        Checkout the specified branch using the GitClient.
        """
        self.git_client.checkout(branch)

    def commit_generated_file(self, file_path: str, context: str) -> str:
        """
        Add the specified file and commit it with a message including the context.

        :param file_path: Path to the file to be committed.
        :param context: Context to include in the commit message.
        :return: The commit hash or output returned by the GitClient.
        """
        self.git_client.add(file_path)
        commit_message = f"Add/update generated file {file_path}. Context: {context[:120]}"
        return self.git_client.commit(commit_message)

    def sync_with_remote(self, remote: str = "origin", branch: str = "master") -> None:
        """
        Pull the latest changes from the specified remote and branch.
        """
        self.git_client.pull(remote, branch)

    def auto_push(self, commit_message: str, context: str = "") -> None:
        """
        Commit with the provided message and push to the remote.
        """
        full_message = (
            f"{commit_message}. Context: {context[:120]}" if context else commit_message
        )
#        self.git_client.commit(full_message)
        self.git_client.push("origin", "master")



================================================================================
FILE: C:\projects\aiAgency\core\git\repo_config.py
================================================================================

from dataclasses import dataclass

@dataclass
class RepoConfig:
    """
    Configuration for a repository.

    Attributes:
        repo_path (str): The file path to the repository.
        default_branch (str): The default branch of the repository. Defaults to 'master'.
        remote_name (str): The name of the remote. Defaults to 'origin'.
        author_name (str): The name of the author. Defaults to 'AI Agent'.
        author_email (str): The email of the author. Defaults to 'ai@example.com'.
    """
    repo_path: str
    default_branch: str = "master"
    remote_name: str = "origin"
    author_name: str = "AI Agent"
    author_email: str = "ai@example.com"



================================================================================
FILE: C:\projects\aiAgency\core\prompt\agent_input_builder.py
================================================================================

# core/prompt/agent_input_builder.py
from __future__ import annotations

import json
from typing import Any, Dict, List, Optional

from core.config.run_config import RunItem


def build_agent_input(
    run_item: RunItem,
    profile_name: str,
    class_name: Optional[str],
    base_agent_input: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    """Construct the agent_input object passed into the model.

    This combines:
    - static runtime info (profile_name, class_name)
    - per-run agent_input overrides from the profile/run
    - the target_file path if present
    """
    agent_input_obj: Dict[str, Any] = {
        "profile_name": profile_name,
        "class_name": class_name or None,
    }

    if isinstance(base_agent_input, dict) and base_agent_input:
        agent_input_obj.update(base_agent_input)

    if run_item.target_file:
        agent_input_obj["target_file"] = run_item.target_file

    return agent_input_obj


def build_rules_block_for_run(run_item: RunItem) -> str:
    """Build a markdown-style rules block string for this run.

    - Uses per-run rules from runs.json (run_item.rules).
    - Adds a small set of global rules.
    - Deduplicates while preserving order.
    """
    base_rules: List[str] = [
        "Always respond strictly in the required JSON envelope.",
        "Never output markdown or prose outside the specified JSON format.",
    ]

    run_rules = run_item.rules or []

    combined: List[str] = []
    for r in base_rules + run_rules:
        if r not in combined:
            combined.append(r)

    return "\n".join(f"- {r}" for r in combined)


def inject_placeholders(
    run_params: Dict[str, Any],
    agent_input_obj: Dict[str, Any],
    rules_block: str,
    task_description: str,
    target_file: Optional[str],
    context_block: str,
) -> None:
    """Replace placeholder tokens in the OpenAI payload messages.

    Mutates `run_params` in-place. It expects the payload to have a `messages`
    list compatible with the OpenAI Chat Completions API.
    """
    agent_input_json = json.dumps(agent_input_obj, ensure_ascii=False, indent=2)

    for msg in run_params.get("messages", []):
        content = msg.get("content")
        if not isinstance(content, str):
            continue

        if "${agent_input}" in content:
            content = content.replace("${agent_input}", agent_input_json)

        if "${task_description}" in content:
            content = content.replace("${task_description}", task_description or "")

        if "${rules_block}" in content:
            content = content.replace("${rules_block}", rules_block)

        if "${target_file}" in content:
            content = content.replace("${target_file}", target_file or "")

        if "${context_block}" in content:
            content = content.replace("${context_block}", context_block or "")

        msg["content"] = content



================================================================================
FILE: C:\projects\aiAgency\core\prompt\__init__.py
================================================================================




================================================================================
FILE: C:\projects\aiAgency\core\runtime\app_runner.py
================================================================================

# core/runtime/app_runner.py
from __future__ import annotations

import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional

from core.logger import BasicLogger
from core.ai_client.openai_client import OpenAIClient
from core.ai_client.ai_response_parser import AIResponseParser
from core.files.file_writer import FileWriter
from core.actions.registry import ActionRegistry
from core.actions.base_action import ActionContext
from core.git.repo_config import RepoConfig
from core.git.git_client import GitClient
from core.git.git_manager import GitManager
from core.config.run_config import RunItem


def _register_builtin_actions() -> None:
    """Import all built-in action modules so they self-register.

    Each imported module must call ``ActionRegistry.register(...)`` at import
    time. This helper is invoked once from :class:`AppRunner`'s constructor.
    """
    # Core file / IO actions
    import core.actions.file_write  # noqa: F401
    import core.actions.file_read  # noqa: F401

    # Control-flow / meta actions
    import core.actions.continue_action  # noqa: F401
    import core.actions.request_retry  # noqa: F401
    import core.actions.trigger_retry  # noqa: F401
    import core.actions.break_action  # noqa: F401


@dataclass
class RunResult:
    """Result of a single model invocation + action execution."""

    success: bool
    retry_requested: bool = False
    retry_reason: Optional[str] = None


@dataclass
class ActionRuntimeContext(ActionContext):
    """Concrete runtime context passed to actions.

    Extends :class:`ActionContext` with additional fields used by the
    orchestrator (retry flags, enforced target file, etc.).
    """

    target_file: Optional[str] = None
    retry_requested: bool = False
    retry_reason: Optional[str] = None


def execute_actions(actions_list: List[Dict[str, Any]], ctx: ActionRuntimeContext) -> None:
    """Instantiate and execute actions using :class:`ActionRegistry`.

    Behaviour:

    * Unknown or unregistered actions are skipped with a warning.
    * If ``ctx.target_file`` is set and an action is ``file_write``, its
      path is overridden by ``ctx.target_file``.
    * If ``ctx.target_file`` is empty/None and an action is ``file_write``,
      that action is skipped.
    * If an action of type ``break`` is executed, remaining actions in the
      list are not executed.
    """
    logger = ctx.logger

    for index, raw in enumerate(actions_list, start=1):
        action = ActionRegistry.create(raw)
        if action is None:
            logger.warning(
                "Unknown or unregistered action '%s'. Allowed: %s",
                raw.get("type"),
                ActionRegistry.allowed_types(),
            )
            continue

        if not action.validate():
            logger.warning(
                "Invalid params for action '%s': %r", action.action_type, raw
            )
            continue

        # Enforce target_file contract for file_write actions
        if action.action_type == "file_write":
            if not ctx.target_file:
                logger.warning(
                    "Skipping file_write action #%s: run has no target_file set.",
                    index,
                )
                continue

            # Override any model-provided path; run.target_file is the SSoT
            if hasattr(action, "params") and isinstance(action.params, dict):
                action.params["target_path"] = ctx.target_file

        logger.info("Executing action #%s: %s", index, action.action_type)
        action.execute(ctx)

        # Logical break in action sequence
        if action.action_type == "break":
            logger.info(
                "Encountered 'break' action at index %s; stopping further action execution.",
                index,
            )
            break


class AppRunner:
    """High-level orchestrator for one OpenAI call + action execution.

    Responsibilities:

    * Initialize infrastructure (logging, Git, filesystem, OpenAI client).
    * Inject task / rules / agent_input / context into the profile payload.
    * Call OpenAI and parse an ``agent`` response.
    * Filter and execute actions via :class:`ActionRegistry`.
    * Surface ``success`` / ``retry_requested`` flags for retry logic.
    """

    def __init__(self, project_root: Path) -> None:
        self.project_root = Path(project_root)

        self.logger = BasicLogger(self.__class__.__name__).get_logger()

        # Repo / Git setup
        repo_path = os.getenv("AIAGENCY_REPO_PATH", str(self.project_root))
        self.repo_config = RepoConfig(repo_path=repo_path)
        self.git_client = GitClient(repo_path=repo_path)
        self.git_manager = GitManager(self.git_client, self.repo_config)

        # File IO
        self.file_writer = FileWriter(project_root=self.project_root)

        # OpenAI client
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise RuntimeError("OPENAI_API_KEY is not set in the environment.")

        self.client = OpenAIClient(api_key=api_key)

        # Ensure built-in actions are registered
        _register_builtin_actions()

    # ------------------------------------------------------------------ #
    # Core run orchestration
    # ------------------------------------------------------------------ #
    def run(
        self,
        run_item: RunItem,
        run_params: Dict[str, Any],
        profile_name: str,
        class_name: Optional[str],
        task_description: str,
        agent_input_overrides: Optional[Dict[str, Any]] = None,
    ) -> RunResult:
        """
        Execute one OpenAI call + follow-up actions for a single run item.

        :param run_item:             The RunItem config.
        :param run_params:           The raw profile JSON loaded from disk
                                     (or otherwise constructed).
        :param profile_name:         Logical label for logging (usually the
                                     profile file path).
        :param class_name:           Optional class/function name for context.
        :param task_description:     Human-readable description of the run.
        :param agent_input_overrides:
                                     Additional fields that will be merged into
                                     the agent_input structure for this run.
        """
        logger = self.logger

        # ------------------------------------------------------------------ #
        # 1. Load + enrich profile JSON
        # ------------------------------------------------------------------ #
        from core.prompt.agent_input_builder import (
            build_agent_input,
            build_rules_block_for_run,
            inject_placeholders,
        )

        # Build agent_input based on run + overrides
        agent_input_obj = build_agent_input(
            run_item=run_item,
            profile_name=profile_name,
            class_name=class_name,
            base_agent_input=agent_input_overrides or {},
        )

        # Build rules block
        rules_block = build_rules_block_for_run(run_item)

        # Ensure run_params is a dict so we can modify in-place
        if not isinstance(run_params, dict):
            raise ValueError("run_params must be a dict loaded from profile JSON")

        # Optional: load + inject context block (based on _context_files_display)
        context_files_display = run_params.get("_context_files_display", [])
        if isinstance(context_files_display, List) and context_files_display:
            # Build a concatenated context string (for debugging/prompting)
            text_blocks: List[str] = []
            for rel in context_files_display:
                try:
                    full_path = (self.project_root / rel).resolve()
                    if full_path.is_file():
                        with full_path.open("r", encoding="utf-8") as f:
                            raw = f.read()
                    else:
                        continue
                except OSError:
                    continue

                header = f"=== CONTEXT FILE: {rel} ===\n"
                text_blocks.append(header + raw.strip() + "\n")

            if text_blocks:
                context_block = "\n\n".join(text_blocks)
                run_params["_context_block"] = context_block

        # Remove meta fields before injection
        if "_context_files_display" in run_params:
            del run_params["_context_files_display"]

        # Inject placeholders into the OpenAI payload
        inject_placeholders(
            run_params=run_params,
            agent_input_obj=agent_input_obj,
            rules_block=rules_block,
            task_description=task_description,
            target_file=run_item.target_file or "",
            context_block=run_params.get("_context_block", ""),
        )

        if "_context_block" in run_params:
            # The context block is injected into messages; no need to keep
            # it at the top level.
            del run_params["_context_block"]

        # ------------------------------------------------------------------ #
        # 2. Call OpenAI
        # ------------------------------------------------------------------ #
        logger.info(
            "Starting OpenAI call for profile '%s' (class=%r, target_file=%r)",
            profile_name,
            class_name,
            run_item.target_file or "<none>",
        )

        response = self.client.send_request(body=run_params)

        # ------------------------------------------------------------------ #
        # 3. Extract agent + actions
        # ------------------------------------------------------------------ #
        agent = AIResponseParser.extract_agent(response)
        logger.info("Extracted agent object: %s", json.dumps(agent, indent=2))

        actions = AIResponseParser.extract_actions(response)
        logger.info("Extracted %d actions.", len(actions))

        if not actions:
            logger.warning("No actions returned by the model.")
            return RunResult(success=False, retry_requested=False)

        # ------------------------------------------------------------------ #
        # 4. Validate agent / actions shape
        # ------------------------------------------------------------------ #
        if not isinstance(agent, dict):
            logger.warning("Agent is not a dict; raw agent: %r", agent)
        else:
            if "name" not in agent or "version" not in agent:
                logger.warning("Agent object missing 'name' or 'version': %r", agent)

        # ------------------------------------------------------------------ #
        # 5. Validate and possibly early-return if no actions are available
        # ------------------------------------------------------------------ #
        # Enforce per-run allowed_actions against registry membership
        effective_allowed: Optional[List[str]] = None
        if getattr(run_item, "allowed_actions", None):
            registered = set(ActionRegistry.allowed_types())
            effective_allowed = [
                t for t in run_item.allowed_actions if t in registered
            ]
            if not effective_allowed:
                logger.warning(
                    "Run has 'allowed_actions' but none match registered actions; "
                    "all actions from the model will be rejected.",
                )
                return RunResult(success=False, retry_requested=False)

        if effective_allowed is not None:
            filtered_actions = [
                a for a in actions if a.get("type") in effective_allowed
            ]
        else:
            # No per-run restriction: accept anything the registry knows
            filtered_actions = [
                a for a in actions if a.get("type") in ActionRegistry.allowed_types()
            ]

        if not filtered_actions:
            logger.warning(
                "No actions left after allowed_actions / registry filtering. "
                "Original actions: %r",
                actions,
            )
            return RunResult(success=False, retry_requested=False)

        # Special case: a single 'continue' action means "no final side effects yet"
        if len(filtered_actions) == 1 and filtered_actions[0].get("type") == "continue":
            logger.info(
                "Agent returned only a 'continue' action; "
                "no side effects will be executed for this attempt.",
            )
            return RunResult(success=False, retry_requested=False)

        # ------------------------------------------------------------------ #
        # 6. Execute actions with runtime context (including enforced target_file)
        # ------------------------------------------------------------------ #
        runtime_ctx = ActionRuntimeContext(
            project_root=self.project_root,
            file_writer=self.file_writer,
            git_manager=self.git_manager,
            repo_config=self.repo_config,
            logger=logger,
            target_file=run_item.target_file or None,
        )

        execute_actions(filtered_actions, runtime_ctx)
        logger.info("All actions executed.")

        # ------------------------------------------------------------------ #
        # 7. Retry semantics
        # ------------------------------------------------------------------ #
        if runtime_ctx.retry_requested:
            logger.info(
                "Run requested retry. Reason: %s",
                runtime_ctx.retry_reason or "<no reason>",
            )
            return RunResult(
                success=False,
                retry_requested=True,
                retry_reason=runtime_ctx.retry_reason,
            )

        return RunResult(success=True, retry_requested=False)



================================================================================
FILE: C:\projects\aiAgency\core\runtime\pipeline_runner.py
================================================================================

# core/runtime/pipeline_runner.py
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Optional

from core.config.run_config import RunConfig, RunItem
from core.runtime.run_executor import RunExecutor


@dataclass
class PipelineResult:
    """Optional container for aggregated pipeline status."""
    total_runs: int
    succeeded: int
    failed: int
    pipeline_retried: bool


class PipelineRunner:
    """
    Orchestrates execution of a RunConfig through RunExecutor.

    Responsibilities:
    - Iterate over all runs
    - Handle pipeline-level retry_from logic
    - Decide when to restart and from which index
    - Report basic status to stdout
    """

    def __init__(self, project_root: Path, config: RunConfig) -> None:
        self.project_root = project_root
        self.config = config
        self.executor = RunExecutor(project_root=project_root)

        self.total_runs = len(config.runs)

        retry_from: Optional[int] = getattr(config, "retry_from", None)
        if retry_from is not None:
            # clamp into [1, total_runs]
            retry_from = max(1, min(retry_from, self.total_runs))
        self.retry_from: Optional[int] = retry_from

    def run(self) -> PipelineResult:
        idx = 1  # 1-based index for human-readable logs
        pipeline_retried = False
        restart_from_index: Optional[int] = None

        succeeded = 0
        failed = 0

        while idx <= self.total_runs:
            run: RunItem = self.config.runs[idx - 1]

            # If we just restarted from a specific index, the *first* run
            # after restart should use retry_context_files instead of the
            # original context_file.
            use_retry_ctx_first = restart_from_index is not None and idx == restart_from_index

            # Consume the flag so it applies only once.
            if use_retry_ctx_first:
                restart_from_index = None

            result = self.executor.execute(
                run=run,
                run_index=idx,
                use_retry_context_on_first_attempt=use_retry_ctx_first,
            )

            status = "OK" if result.success else "FAILED"
            if result.retried:
                print(
                    f"[RUN {idx}] finished with status {status} "
                    f"after {result.attempts} attempts. "
                    f"Retry reason (last): {result.last_retry_reason or '<none>'}."
                )
            else:
                print(
                    f"[RUN {idx}] finished with status {status} "
                    f"after {result.attempts} attempts."
                )

            if result.success:
                succeeded += 1
            else:
                failed += 1

            # Pipeline-level retry_from logic:
            #
            # If:
            #   - this run did NOT succeed,
            #   - the RunExecutor reports that the agent requested retry
            #     at some point (result.retried == True), and
            #   - the config defines retry_from,
            #   - and we have not yet used the pipeline-level restart,
            # then:
            #   - restart the pipeline from retry_from,
            #   - and for that first restarted run, force use of retry_context_files.
            if (
                not result.success
                and result.retried
                and self.retry_from is not None
                and not pipeline_retried
            ):
                print(
                    f"[RUN {idx}] pipeline-level retry_from triggered; "
                    f"restarting from run index {self.retry_from} "
                    f"using retry_context_files for that run (if configured)."
                )
                pipeline_retried = True
                restart_from_index = self.retry_from
                idx = self.retry_from
                continue

            idx += 1

        return PipelineResult(
            total_runs=self.total_runs,
            succeeded=succeeded,
            failed=failed,
            pipeline_retried=pipeline_retried,
        )



================================================================================
FILE: C:\projects\aiAgency\core\runtime\run_executor.py
================================================================================

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional

from core.config.run_config import RunItem
from core.context.context_loader import load_context_params
from core.runtime.app_runner import AppRunner, RunResult


@dataclass
class RunExecutionResult:
    """High-level summary of one RunItem execution (with retries)."""

    success: bool
    attempts: int
    retried: bool
    last_retry_reason: Optional[str] = None


class RunExecutor:
    """Execute a single RunItem with agent-driven retry logic."""

    def __init__(self, project_root: Path) -> None:
        self.project_root = Path(project_root).resolve()
        self.app_runner = AppRunner(project_root=self.project_root)

    # ------------------------------------------------------------------ #
    # Internal helpers
    # ------------------------------------------------------------------ #

    def _resolve_context_files(self, profile_file: str, base_files: List[str]) -> List[str]:
        """
        Ensure that, if profile_file is set, it is present as the FIRST
        context file for this attempt.

        Behaviour:
        - If base_files is empty, return [profile_file].
        - If base_files already contains profile_file, move it to index 0.
        - Otherwise, prepend profile_file to base_files.
        """
        profile_file = (profile_file or "").strip()

        if not profile_file:
            # No profile file to inject, just return base_files as-is.
            return list(base_files)

        if not base_files:
            return [profile_file]

        files = [str(p) for p in base_files]

        if profile_file not in files:
            return [profile_file] + files

        if files[0] == profile_file:
            return files

        # Move profile_file to the front, preserving order for others
        return [profile_file] + [f for f in files if f != profile_file]

    def _build_run_params_for_attempt(
        self,
        run: RunItem,
        use_retry_ctx: bool,
        attempt: int,
    ) -> Dict[str, Any]:
        """
        Load context files for this attempt, and attach a display list.

        This method:
        - Picks either context_file or retry_context_files depending on
          use_retry_ctx.
        - Ensures run.profile_file is included as the first context file.
        - Calls load_context_params(project_root, context_files).
        """
        if use_retry_ctx and run.retry_context_files:
            base_files = run.retry_context_files
            ctx_type = "retry_context_files"
        else:
            base_files = run.context_file
            ctx_type = "context_file"

        context_files = self._resolve_context_files(run.profile_file, base_files)

        if not context_files:
            raise ValueError(
                "Run has no context_file / retry_context_files, "
                "and no profile_file was provided."
            )

        print(f"[RunExecutor] Attempt {attempt} using {ctx_type}: {context_files}")

        # The underlying loader is responsible for reading JSON / text etc.
        params = load_context_params(self.project_root, context_files)

        # Keep the list of context files used for this attempt for logging
        # and for including in the agent_input.
        params["_context_files_display"] = context_files

        return params

    # ------------------------------------------------------------------ #
    # Public API
    # ------------------------------------------------------------------ #

    def execute(
        self,
        run: RunItem,
        run_index: int,
        use_retry_context_on_first_attempt: bool = False,
    ) -> RunExecutionResult:
        """
        Execute the given RunItem with agent-controlled retries.
        """
        # How many additional logical retries we allow:
        max_extra_retries = max(0, int(run.retry))

        retries_used = 0
        attempt = 1
        last_retry_reason: Optional[str] = None

        while True:
            use_retry_ctx = (
                attempt > 1
                or (attempt == 1 and use_retry_context_on_first_attempt)
            )

            run_params = self._build_run_params_for_attempt(
                run=run,
                use_retry_ctx=use_retry_ctx,
                attempt=attempt,
            )

            # Construct an agent_input override: we want to inject the
            # current context_file list (for debugging) and anything else
            # from RunItem.agent_input.
            agent_input_overrides: Dict[str, Any] = dict(run.agent_input or {})

            # Also propagate the target_file for actions like file_write
            if run.target_file:
                agent_input_overrides["target_file"] = run.target_file

            # Propagate allowed_actions so the profile can see the limitation
            # and so the AppRunner can also filter actions:
            if run.allowed_actions:
                agent_input_overrides["allowed_actions"] = run.allowed_actions

            # For logging / debugging, use the profile_file as a logical
            # profile_name here. The profile JSON itself may also declare
            # a "name" field, but this is independent.
            profile_label = run.profile_file

            try:
                result: RunResult = self.app_runner.run(
                    run_item=run,
                    run_params=run_params,
                    profile_name=profile_label,
                    class_name=run.class_name,
                    task_description=run.task_description,
                    agent_input_overrides=agent_input_overrides,
                )
            except Exception as exc:  # noqa: BLE001
                print(
                    f"[RUN {run_index}] attempt {attempt} crashed with exception: {exc}"
                )
                return RunExecutionResult(
                    success=False,
                    attempts=attempt,
                    retried=retries_used > 0,
                    last_retry_reason=last_retry_reason,
                )

            if result.success:
                return RunExecutionResult(
                    success=True,
                    attempts=attempt,
                    retried=retries_used > 0,
                    last_retry_reason=last_retry_reason,
                )

            # Not successful: see if retry was explicitly requested
            if not result.retry_requested:
                print(
                    f"[RUN {run_index}] attempt {attempt} failed without retry request; "
                    "stopping this run."
                )
                return RunExecutionResult(
                    success=False,
                    attempts=attempt,
                    retried=retries_used > 0,
                    last_retry_reason=last_retry_reason,
                )

            # Agent did request a retry
            last_retry_reason = result.retry_reason

            if retries_used >= max_extra_retries:
                print(
                    f"[RUN {run_index}] attempt {attempt} requested retry, "
                    f"but max retries ({max_extra_retries}) reached; stopping."
                )
                return RunExecutionResult(
                    success=False,
                    attempts=attempt,
                    retried=retries_used > 0,
                    last_retry_reason=last_retry_reason,
                )

            retries_used += 1
            next_attempt = attempt + 1
            print(
                f"[RUN {run_index}] attempt {attempt} requested retry; "
                f"starting attempt {next_attempt} (retry {retries_used}/{max_extra_retries})."
            )
            attempt = next_attempt



================================================================================
FILE: C:\projects\aiAgency\core\runtime\__init__.py
================================================================================




================================================================================
FILE: C:\projects\aiAgency\test\tetris_manifest.json
================================================================================

{"project_name": "TetrisGame", "language": "python", "version": "1.0.0", "structure": [{"module_name": "config", "file_path": "tetris/config.py", "description": "Handles game configuration settings.", "imports": [{"source": "json", "names": [], "type": "standard"}], "global_constants": [{"name": "SCREEN_WIDTH", "type": "int", "value": "800"}, {"name": "SCREEN_HEIGHT", "type": "int", "value": "600"}]}, {"module_name": "tetromino", "file_path": "tetris/tetromino.py", "description": "Defines tetromino shapes and rotations.", "imports": [{"source": "typing", "names": ["List"], "type": "standard"}], "classes": [{"class_name": "Tetromino", "inherits_from": [], "docstring": "Represents a tetromino piece.", "attributes": [{"name": "shape", "type": "List[List[int]]", "access": "public", "description": "Matrix representing the shape of the tetromino."}], "methods": [{"name": "rotate", "access": "public", "args": [], "return_type": "None", "description": "Rotates the tetromino shape."}]}]}, {"module_name": "board", "file_path": "tetris/board.py", "description": "Manages the game board state.", "imports": [{"source": "typing", "names": ["List"], "type": "standard"}], "classes": [{"class_name": "Board", "inherits_from": [], "docstring": "Represents the game board.", "attributes": [{"name": "grid", "type": "List[List[int]]", "access": "private", "description": "2D grid representing the board state."}], "methods": [{"name": "clear_lines", "access": "public", "args": [], "return_type": "int", "description": "Clears completed lines and returns the number of lines cleared."}]}]}, {"module_name": "game_engine", "file_path": "tetris/game_engine.py", "description": "Main game loop and logic.", "imports": [{"source": "tetris.board", "names": ["Board"], "type": "local"}, {"source": "tetris.tetromino", "names": ["Tetromino"], "type": "local"}], "classes": [{"class_name": "GameEngine", "inherits_from": [], "docstring": "Controls the game flow.", "attributes": [{"name": "board", "type": "Board", "access": "private", "description": "The game board instance."}], "methods": [{"name": "run", "access": "public", "args": [], "return_type": "None", "description": "Runs the main game loop."}]}]}, {"module_name": "input_handler", "file_path": "tetris/input_handler.py", "description": "Handles user input.", "imports": [{"source": "pygame", "names": [], "type": "third_party"}], "classes": [{"class_name": "InputHandler", "inherits_from": [], "docstring": "Processes user input.", "methods": [{"name": "process_input", "access": "public", "args": [], "return_type": "None", "description": "Processes input events."}]}]}, {"module_name": "renderer", "file_path": "tetris/renderer.py", "description": "Renders the game state.", "imports": [{"source": "pygame", "names": [], "type": "third_party"}], "classes": [{"class_name": "Renderer", "inherits_from": [], "docstring": "Renders the game board and pieces.", "methods": [{"name": "render", "access": "public", "args": [], "return_type": "None", "description": "Renders the current game state to the screen."}]}]}, {"module_name": "test_game", "file_path": "tetris/test/test_game.py", "description": "Tests for core game mechanics.", "imports": [{"source": "unittest", "names": [], "type": "standard"}, {"source": "tetris.board", "names": ["Board"], "type": "local"}], "classes": [{"class_name": "TestGameMechanics", "inherits_from": ["unittest.TestCase"], "docstring": "Tests for game mechanics like line clearing.", "methods": [{"name": "test_line_clearing", "access": "public", "args": [], "return_type": "None", "description": "Tests if lines are cleared correctly."}]}]}]}


================================================================================
FILE: C:\projects\aiAgency\test\core\git\git_client.py
================================================================================

# === CONTEXT START ===
# This module defines the GitClient class, which provides methods to interact
# with a Git repository. It includes functionalities to initialize a repository,
# add files, commit changes, push to a remote, pull from a remote, checkout
# branches, and get the current branch status. The refactoring removes the
# hardcoded 'master' branch default, allowing for a more flexible branch
# handling by defaulting to 'main' if no branch is specified.
# === CONTEXT END ===

import subprocess
from typing import Union
from core.logger import BasicLogger

class GitClient:
    def __init__(self, repo_path: str):
        """Initialize the GitClient with the path to the repository."""
        self.repo_path = repo_path
        self.logger = BasicLogger(self.__class__.__name__).get_logger()

    def _run_git_command(self, *args: str) -> str:
        self.logger.info(f'Running git command: {args}')
        try:
            result = subprocess.run(
                ['git'] + list(args),
                cwd=self.repo_path,
                text=True,
                capture_output=True,
                check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as exc:
            stdout_msg = (exc.stdout or "").strip()
            stderr_msg = (exc.stderr or "").strip()

            if stdout_msg:
                self.logger.error(f"Git stdout (cmd: {args}): {stdout_msg}")
            if stderr_msg:
                self.logger.error(f"Git stderr (cmd: {args}): {stderr_msg}")

            # Re-raise so the caller still gets the failure
            raise

    def init_repo(self) -> None:
        """Initialize a new git repository."""
        self.logger.info('Initializing repository')
        self._run_git_command('init')

    def add(self, paths: Union[list[str], str]) -> str:
        """Add file contents to the index."""
        self.logger.info(f'Adding paths: {paths}')
        if isinstance(paths, str):
            paths = [paths]
        return self._run_git_command('add', *paths)

    def commit(self, message: str) -> str:
        """Record changes to the repository with a commit message."""
        self.logger.info(f'Committing with message: {message}')
        return self._run_git_command('commit', '-m', message)

    def push(self, remote: str = "origin", branch: str = None) -> str:
        """Update remote refs along with associated objects."""
        branch = branch or 'main'
        self.logger.info(f'Pushing to {remote}/{branch}')
        return self._run_git_command('push', remote, branch)

    def pull(self, remote: str = "origin", branch: str = None) -> str:
        """Fetch from and integrate with another repository or a local branch."""
        branch = branch or 'main'
        self.logger.info(f'Pulling from {remote}/{branch}')
        return self._run_git_command('pull', remote, branch)

    def checkout(self, branch: str, create_if_missing: bool = False) -> str:
        """Switch branches or restore working tree files."""
        self.logger.info(f'Checking out branch: {branch}, create if missing: {create_if_missing}')
        if create_if_missing:
            return self._run_git_command('checkout', '-b', branch)
        return self._run_git_command('checkout', branch)

    def status(self) -> str:
        """Show the working tree status."""
        self.logger.info('Getting status')
        return self._run_git_command('status')

    def get_current_branch(self) -> str:
        """Get the name of the current branch."""
        self.logger.info('Getting current branch')
        return self._run_git_command('rev-parse', '--abbrev-ref', 'HEAD')



================================================================================
FILE: C:\projects\aiAgency\test\manifests\tetris_project_manifest.json
================================================================================

{"project_name": "TetrisGame", "language": "python", "version": "1.0.0", "structure": [{"module_name": "game_engine", "file_path": "tetris/game_engine.py", "description": "Core game logic for Tetris, including piece movement and collision detection.", "imports": [{"source": "random", "names": [], "type": "standard"}, {"source": "pygame", "names": ["Surface"], "type": "third_party"}], "global_constants": [{"name": "BOARD_WIDTH", "type": "int", "value": "10"}, {"name": "BOARD_HEIGHT", "type": "int", "value": "20"}], "classes": [{"class_name": "Tetris", "inherits_from": [], "decorators": [], "docstring": "Main class for Tetris game logic.", "attributes": [{"name": "board", "type": "List[List[int]]", "access": "private", "description": "2D list representing the game board."}, {"name": "score", "type": "int", "access": "public", "default_value": "0", "description": "Current score of the game."}], "methods": [{"name": "__init__", "access": "public", "args": [], "return_type": "None", "description": "Initializes the game board and score."}, {"name": "move_piece", "access": "public", "args": [{"name": "direction", "type": "str"}], "return_type": "bool", "description": "Moves the current piece left, right, or down.", "raises": ["ValueError"]}, {"name": "rotate_piece", "access": "public", "args": [], "return_type": "None", "description": "Rotates the current piece if possible."}, {"name": "check_collision", "access": "private", "args": [], "return_type": "bool", "description": "Checks for collisions with the board or other pieces."}]}]}]}


================================================================================
FILE: C:\projects\aiAgency\test\runs\tetris_project_run.json
================================================================================

{"runs": [{"profile_name": "code_generation", "class_name": "tetris/game_engine.py", "context_file": [], "target_file": "tetris/game_engine.py", "task_description": "Implement the game_engine module in tetris/game_engine.py. This includes core game logic for Tetris, such as piece movement and collision detection. Key class: Tetris.", "agent_input": {"module_name": "game_engine", "file_path": "tetris/game_engine.py", "manifest_language": "python", "goal": "Core game logic for Tetris, including piece movement and collision detection."}, "retry": 2, "retry_context_files": [], "allowed_actions": ["file_write"]}]}


================================================================================
FILE: C:\projects\aiAgency\test\tetris\board.py
================================================================================

# === CONTEXT START ===
# This module manages the game board state for a Tetris game.
# It includes the GameBoard class with a grid field and a method to clear completed lines.
# === CONTEXT END ===

class GameBoard:
    def __init__(self, width, height):
        """
        Initialize the game board with the given width and height.
        The grid is represented as a list of lists, where each inner list is a row.
        """
        self.width = width
        self.height = height
        self.grid = [[0] * width for _ in range(height)]

    def clear_lines(self):
        """
        Clears completed lines from the board.
        A completed line is one where all cells are non-zero.
        """
        new_grid = [row for row in self.grid if any(cell == 0 for cell in row)]
        lines_cleared = self.height - len(new_grid)
        # Add empty lines at the top for each cleared line
        for _ in range(lines_cleared):
            new_grid.insert(0, [0] * self.width)
        self.grid = new_grid

    def __str__(self):
        """
        Returns a string representation of the board for debugging purposes.
        """
        return '\n'.join(''.join(str(cell) for cell in row) for row in self.grid)



================================================================================
FILE: C:\projects\aiAgency\test\tetris\config.py
================================================================================

# === CONTEXT START ===
# This module handles game configuration settings for a Tetris game.
# It includes the GameConfig class with fields for board_width, board_height, and tick_rate.
# The module provides a method to load these settings from a file.
# === CONTEXT END ===

import json

class GameConfig:
    def __init__(self, board_width=10, board_height=20, tick_rate=1.0):
        self.board_width = board_width
        self.board_height = board_height
        self.tick_rate = tick_rate

    @classmethod
    def load_from_file(cls, file_path):
        """
        Load game configuration from a JSON file.

        :param file_path: Path to the configuration file.
        :return: An instance of GameConfig with settings loaded from the file.
        """
        with open(file_path, 'r') as file:
            config_data = json.load(file)
            return cls(
                board_width=config_data.get('board_width', 10),
                board_height=config_data.get('board_height', 20),
                tick_rate=config_data.get('tick_rate', 1.0)
            )



================================================================================
FILE: C:\projects\aiAgency\test\tetris\input.py
================================================================================

# === CONTEXT START ===
# This module handles user input for a game, specifically implementing
# the InputHandler class with a method to process user input for game control.
# === CONTEXT END ===

class InputHandler:
    def get_input(self):
        """
        Process user input for game control.

        This method should capture and interpret user input, such as keyboard
        events, to control the game. The specific implementation will depend
        on the input method and game requirements.
        """
        # Placeholder for input processing logic
        # Example: return 'left', 'right', 'rotate', 'drop', etc.
        pass



================================================================================
FILE: C:\projects\aiAgency\test\tetris\tetromino.py
================================================================================

# === CONTEXT START ===
# This module represents Tetris pieces and their behaviors.
# It includes the Tetromino class with fields for shape and position.
# The module also implements a rotate method to rotate the tetromino shape.
# === CONTEXT END ===

class Tetromino:
    def __init__(self, shape, position=(0, 0)):
        """
        Initialize a Tetromino with a given shape and position.

        :param shape: A list of lists representing the tetromino shape.
        :param position: A tuple (x, y) representing the tetromino's position on the board.
        """
        self.shape = shape
        self.position = position

    def rotate(self):
        """
        Rotate the tetromino shape 90 degrees clockwise.
        """
        # Transpose the shape matrix and then reverse each row to achieve a 90-degree rotation
        self.shape = [list(row) for row in zip(*self.shape[::-1])]

    def __str__(self):
        """
        Return a string representation of the tetromino for debugging.
        """
        return '\n'.join([''.join(row) for row in self.shape])


