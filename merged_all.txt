
================================================================================
FILE: C:\projects\aiAgency\main.py
================================================================================

# main.py
from dotenv import load_dotenv
import argparse

from app.app import main as app_main
from core.config.run_config import RunConfig

load_dotenv()  # load .env once at entry point


def parse_args():
    parser = argparse.ArgumentParser(description="AI Code Generation Framework")
    parser.add_argument(
        "--config",
        type=str,
        required=True,
        help="Path to a JSON config file describing one or more runs.",
    )
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()

    config = RunConfig.from_file(args.config)

    for idx, run in enumerate(config.runs, start=1):
        print(
            f"[RUN {idx}] profile={run.profile_name}, "
            f"class_name={run.class_name}, "
            f"refactor_class={run.refactor_class}"
        )

        app_main(
            profile_name=run.profile_name,
            class_name=run.class_name,
            refactor_class=run.refactor_class,
            task_description=run.task_description,
            run_params=run.raw or {},
        )



================================================================================
FILE: C:\projects\aiAgency\merge_py.py
================================================================================

import os
import json

OUTPUT_NAME = "merged_all.txt"

def collect_all_files(root_dir, output_name):
    files = []
    for dirpath, _, filenames in os.walk(root_dir):
        for fname in filenames:
            # include .py and .json
            if fname.endswith((".py", ".json")) and fname != output_name:
                files.append(os.path.join(dirpath, fname))
    return files


def merge_all(files, output_path):
    with open(output_path, "w", encoding="utf-8") as out:
        for f in files:
            out.write("\n")
            out.write("=" * 80 + "\n")
            out.write(f"FILE: {f}\n")
            out.write("=" * 80 + "\n\n")

            try:
                with open(f, "r", encoding="utf-8") as src:
                    content = src.read()
                out.write(content)
            except Exception as e:
                out.write(f"!! ERROR READING FILE: {e} !!")

            out.write("\n\n")

    print(f"Merged {len(files)} files into: {output_path}")


if __name__ == "__main__":
    root = os.getcwd()
    files = collect_all_files(root, OUTPUT_NAME)
    output_file = os.path.join(root, OUTPUT_NAME)
    merge_all(files, output_file)



================================================================================
FILE: C:\projects\aiAgency\app\app.py
================================================================================

# app/app.py
from __future__ import annotations

import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Mapping, Optional

from core.logger import BasicLogger
from core.ai_client.ai_client import OpenAIClient
from core.ai_client.api_param_generator import AIParamGenerator
from core.ai_client.ai_profile_loader import AIProfileLoader
from core.ai_client.ai_response_parser import AIResponseParser

from core.files.class_generator import ClassGenerator
from core.files.class_reader import PythonFileReader

from core.git.repo_config import RepoConfig
from core.git.git_client import GitClient
from core.git.git_manager import GitManager


# ---------------------------------------------------------------------------
# Runtime context for action execution
# ---------------------------------------------------------------------------

ALLOWED_ACTION_TYPES = {
    "generate_class_file",
    "git_commit_and_push",
    "generate_test_file"
}


@dataclass
class ActionRuntimeContext:
    """
    Objects and configuration that actions may need at runtime.
    This keeps 'main()' thin and the dispatcher generic.
    """
    project_root: Path
    class_generator: ClassGenerator
    git_manager: GitManager
    repo_config: RepoConfig
    logger: Any  # logging.Logger


# ---------------------------------------------------------------------------
# Action execution
# ---------------------------------------------------------------------------

from core.actions.registry import ActionRegistry
from core.actions.base_action import ActionContext

def execute_actions(actions_list: list, ctx: ActionContext) -> None:
    logger = ctx.logger

    for index, raw in enumerate(actions_list, start=1):
        action = ActionRegistry.create(raw)
        if action is None:
            logger.warning(
                f"Unknown or unregistered action '{raw.get('type')}'. "
                f"Allowed: {ActionRegistry.allowed_types()}"
            )
            continue

        if not action.validate():
            logger.warning(f"Invalid params for action '{action.action_type}': {raw}")
            continue

        logger.info(f"Executing action #{index}: {action.action_type}")
        action.execute(ctx)

# ---------------------------------------------------------------------------
# Main entry point from main.py
# ---------------------------------------------------------------------------

def main(
    profile_name: str,
    class_name: str = "",
    refactor_class: str = "",
    task_description: str = "",
    run_params: Optional[Mapping[str, Any]] = None,
) -> None:

    """
    High-level orchestration:

    1. Build runtime / Git / AI clients.
    2. Load profile presets.
    3. Build agent_input (runtime info + optional refactor code).
    4. Inject ${agent_input} into the profile messages.
    5. Call OpenAI, expecting an 'agent' JSON object.
    6. Execute actions returned under agent.actions[].
    """
    project_root = Path(__file__).resolve().parents[1]
    logger = BasicLogger(__name__).get_logger()
    logger.info("Starting AI action dispatcher app")

    # --- GIT SETUP -----------------------------------------------------
    repo_config = RepoConfig(
        repo_path=str(project_root),
        default_branch="master",
        remote_name="origin",
        author_name="Onat Agent",
        author_email="onat@gegeoglu.com",
    )
    git_client = GitClient(repo_path=repo_config.repo_path)
    git_manager = GitManager(git_client=git_client)

    # --- OPENAI CLIENT SETUP -------------------------------------------
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY is not set in .env")

    client = OpenAIClient(api_key=api_key)

    # --- PROFILE LOADING -----------------------------------------------
    profiles_dir = project_root / "profiles"
    profile_loader = AIProfileLoader(
        profiles_dir=profiles_dir,
        default_user="onat",
    )
    presets = profile_loader.load_profiles()

    if profile_name not in presets:
        raise ValueError(
            f"Profile '{profile_name}' not found. "
            f"Available profiles: {', '.join(presets.keys())}"
        )

    param_gen = AIParamGenerator(
        client=client,
        presets=presets,
        default_user="onat",
    )

    # --- BUILD agent_input RUNTIME OBJECT ------------------------------
    agent_input: Dict[str, Any] = {
        "profile_name": profile_name,
        "class_name": class_name or None,
        "refactor_class": refactor_class or None,
    }

    # If refactor_class is provided, read its current content so the model
    # does not have to perform filesystem I/O.
    if refactor_class:
        reader = PythonFileReader(refactor_class)
        try:
            original_code = reader.read_file()
        except Exception as exc:
            logger.error(f"Could not read refactor_class '{refactor_class}': {exc}")
            original_code = ""

        agent_input["refactor"] = {
            "file_path": refactor_class,
            "original_code": original_code,
        }

    # --- BUILD REQUEST PAYLOAD FROM PROFILE ----------------------------
    params = param_gen.build_params(profile_name)

    # Inject agent_input into the messages using a simple ${agent_input} placeholder.
    # Profiles are expected to reference this placeholder in one or more messages.
    agent_input_json = json.dumps(agent_input, ensure_ascii=False, indent=2)

    for msg in params.get("messages", []):
        content = msg.get("content")
        if isinstance(content, str) and "${agent_input}" in content:
            msg["content"] = content.replace("${agent_input}", agent_input_json)

    logger.info(f"Calling OpenAI for profile '{profile_name}'")
    response = client.send_request(body=params)

    # --- PARSE AGENT + ACTIONS -----------------------------------------
    agent_obj = AIResponseParser.extract_agent(response)
    if not agent_obj:
        logger.error("Model did not return a valid 'agent' object. Aborting.")
        return


    actions = agent_obj.get("actions", [])
    if not isinstance(actions, list) or not actions:
        logger.warning(
            "No actions returned by the model. Parsed agent object: %r", agent_obj
        )
        return
    
    # --- EXECUTE ACTIONS -----------------------------------------------
    runtime_ctx = ActionRuntimeContext(
        project_root=project_root,
        class_generator=ClassGenerator(base_path=str(project_root)),
        git_manager=git_manager,
        repo_config=repo_config,
        logger=logger,
    )

    execute_actions(actions, runtime_ctx)

    logger.info("All actions executed.")



================================================================================
FILE: C:\projects\aiAgency\app\__pycache__\__init__.py
================================================================================




================================================================================
FILE: C:\projects\aiAgency\configs\calculator_runs.json
================================================================================

{
  "runs": [
    {
      "profile_name": "code_generation",
      "class_name": "core/calculator.py",
      "task_description": "Create me a basic calculator"
    },
    {
      "profile_name": "code_refactor",
      "class_name": "core/calculator.py",
      "task_description": "Add logging to this calculator"
    }
  ]
}



================================================================================
FILE: C:\projects\aiAgency\core\logger.py
================================================================================

# === CONTEXT START ===
# This code defines a BasicLogger class that can be easily initialized in other
# classes to provide logging functionality. The logger is configured with a stream
# handler and a formatter, and it ensures that multiple handlers are not added to
# the logger. The example in the comment shows how to use the BasicLogger in
# another class by initializing it with the class name and using it to log
# messages.
# === CONTEXT END ===

import logging

class BasicLogger:
    def __init__(self, name: str, level: int = logging.INFO):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)
        handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        if not self.logger.handlers:
            self.logger.addHandler(handler)

    def get_logger(self):
        return self.logger

# Example of how to implement the logger in another class:
#
# class MyClass:
#     def __init__(self):
#         self.logger = BasicLogger(self.__class__.__name__).get_logger()
#
#     def do_something(self):
#         self.logger.info('Doing something')
#
# my_instance = MyClass()
# my_instance.do_something()



================================================================================
FILE: C:\projects\aiAgency\core\__init__.py
================================================================================




================================================================================
FILE: C:\projects\aiAgency\core\actions\base_action.py
================================================================================

from dataclasses import dataclass
from typing import Any, Dict, Mapping

@dataclass
class ActionContext:
    project_root: Any
    class_generator: Any
    git_manager: Any
    repo_config: Any
    logger: Any

class BaseAction:
    """
    Abstract base class for all actions.
    """

    action_type: str = None  # override in subclasses

    def __init__(self, params: Mapping[str, Any]):
        self.params = params

    @classmethod
    def from_raw(cls, raw: Mapping[str, Any]):
        params = raw.get("params", {})
        return cls(params)

    def validate(self):
        """Override if needed."""
        return True

    def execute(self, ctx: ActionContext):
        """Override in subclasses."""
        raise NotImplementedError



================================================================================
FILE: C:\projects\aiAgency\core\actions\generate_class_file.py
================================================================================

# core/actions/generate_class_file.py
from pathlib import Path
from .base_action import BaseAction, ActionContext
from .registry import ActionRegistry


class GenerateClassFileAction(BaseAction):
    action_type = "generate_class_file"

    def validate(self) -> bool:
        if not isinstance(self.params.get("target_path"), str):
            return False
        if not isinstance(self.params.get("code"), str):
            return False
        return True

    def execute(self, ctx: ActionContext) -> None:
        logger = ctx.logger

        target_path = self.params["target_path"]
        code = self.params["code"]
        context_text = self.params.get("context", "")

        target_rel_path = Path(target_path)
        abs_target_dir = (ctx.project_root / target_rel_path).parent
        abs_target_dir.mkdir(parents=True, exist_ok=True)

        gen = ctx.class_generator
        original_base = gen.base_path
        try:
            gen.base_path = str(abs_target_dir)
            generated_path = gen.generate_with_comments(
                filename=target_rel_path.name,
                content=code,
                comments=context_text,
            )
        finally:
            gen.base_path = original_base

        logger.info(f"Generated class file at: {generated_path}")


# ðŸ‘‡ THIS LINE IS CRITICAL
ActionRegistry.register(GenerateClassFileAction)



================================================================================
FILE: C:\projects\aiAgency\core\actions\generate_path_index.py
================================================================================

# === CONTEXT START ===
# This class scans a specified directory for Python files, extracts class names,
# and builds an index mapping class names to their file paths.
# === CONTEXT END ===

class GeneratePathIndexAction:
    def __init__(self, directory):
        self.directory = directory

    def build_index(self):
        import os
        index = {}
        for root, _, files in os.walk(self.directory):
            for file in files:
                if file.endswith('.py'):
                    module_path = os.path.join(root, file)
                    class_name = self.extract_class_name(module_path)
                    if class_name:
                        index[class_name] = module_path
        return index

    def extract_class_name(self, file_path):
        with open(file_path, 'r') as file:
            for line in file:
                if line.startswith('class '):
                    return line.split()[1].split('(')[0]
        return None


================================================================================
FILE: C:\projects\aiAgency\core\actions\generate_test_file.py
================================================================================

# === CONTEXT START ===
# This action generates a test file at the specified target path with the provided
# code. It validates the presence of 'code' and 'target_path' in the parameters
# before execution. The action is registered with the ActionRegistry under the
# action type 'generate_test_file'.
# === CONTEXT END ===

from core.actions.base_action import BaseAction
from core.actions.registry import ActionRegistry

class GenerateTestFileAction(BaseAction):
    action_type = 'generate_test_file'

    def validate(self, params):
        if 'code' not in params or 'target_path' not in params:
            raise ValueError("Parameters must include 'code' and 'target_path'.")

    def execute(self, params):
        self.validate(params)
        code = params['code']
        target_path = params['target_path']
        with open(target_path, 'w') as file:
            file.write(code)
        return {'status': 'success', 'message': f'Test file generated at {target_path}'}

ActionRegistry.register(GenerateTestFileAction)


================================================================================
FILE: C:\projects\aiAgency\core\actions\registry.py
================================================================================

from typing import Dict, Type
from .base_action import BaseAction

class ActionRegistry:
    _registry: Dict[str, Type[BaseAction]] = {}

    @classmethod
    def register(cls, action_cls: Type[BaseAction]):
        cls._registry[action_cls.action_type] = action_cls

    @classmethod
    def create(cls, raw_action: dict) -> BaseAction | None:
        action_type = raw_action.get("type")
        params = raw_action.get("params", {})

        if action_type not in cls._registry:
            return None

        return cls._registry[action_type].from_raw(raw_action)

    @classmethod
    def allowed_types(cls):
        return list(cls._registry.keys())



================================================================================
FILE: C:\projects\aiAgency\core\actions\__init__.py
================================================================================

# core/actions/__init__.py

# Import all action modules here so they self-register in the registry.
from . import generate_class_file  # noqa: F401
# from . import git_commit_and_push  # noqa: F401
# from . import generate_test_file   # noqa: F401



================================================================================
FILE: C:\projects\aiAgency\core\ai_client\ai_client.py
================================================================================

import requests
from typing import Dict, Any, Optional
from core.logger import BasicLogger


class OpenAIClient:
    """
    Handles direct HTTP calls to the OpenAI API.
    """

    # Whitelist of top-level keys allowed by /v1/chat/completions
    _ALLOWED_TOP_LEVEL_KEYS = {
        "model",
        "messages",
        "temperature",
        "top_p",
        "max_tokens",
        "n",
        "stop",
        "presence_penalty",
        "frequency_penalty",
        "logit_bias",
        "user",
        "response_format",
        "seed",
        "tools",
        "tool_choice",
        "metadata",
    }

    def __init__(
        self,
        api_url: str = "https://api.openai.com/v1/chat/completions",
        api_key: str = "",
    ):
        self.api_url = api_url
        self.api_key = api_key
        self.logger = BasicLogger(self.__class__.__name__).get_logger()

    def _sanitize_body(self, body: Dict[str, Any]) -> Dict[str, Any]:
        """
        Remove any keys that the OpenAI chat.completions API does not recognize.
        This lets profile JSON contain meta fields like 'name', 'task_description', etc.
        """
        sanitized = {
            k: v for k, v in body.items() if k in self._ALLOWED_TOP_LEVEL_KEYS
        }

        removed = [k for k in body.keys() if k not in self._ALLOWED_TOP_LEVEL_KEYS]
        if removed:
            self.logger.info(
                f"OpenAIClient: stripping meta keys from payload: {', '.join(removed)}"
            )

        return sanitized

    def send_request(
        self,
        body: Dict[str, Any],
        headers: Optional[Dict[str, str]] = None,
        timeout: int = 30,
    ) -> Dict[str, Any]:
        """
        Sends a POST request to the OpenAI API with the provided body and headers.
        """
        final_headers = headers or {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
        }

        sanitized_body = self._sanitize_body(body)

        self.logger.info("Sending request to OpenAI API")
        response = requests.post(
            self.api_url,
            json=sanitized_body,
            headers=final_headers,
            timeout=timeout,
        )

        if response.status_code != 200:
            self.logger.error(f"OpenAI API error {response.status_code}: {response.text}")
            raise Exception(f"OpenAI API error {response.status_code}: {response.text}")

        return response.json()



================================================================================
FILE: C:\projects\aiAgency\core\ai_client\ai_profile_loader.py
================================================================================

from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, Mapping, Optional
import copy


class AIProfileLoader:
    """
    Loads JSON preset profiles from a directory and provides them as dictionaries.

    Features:
    - Loads all *.json files from a directory.
    - Each file may contain:
        A) a single profile object  (with keys like 'model', 'messages', etc.), or
        B) a mapping of multiple profiles, e.g. { "fast_chat": {...}, "code_generation": {...} }.
    - Uses the JSON 'name' field or filename stem (case A), or the dict key (case B) as profile name.
    - Applies simple placeholder substitution (e.g. ${default_user}).
    - Caches loaded profiles in-memory.
    """

    def __init__(
        self,
        profiles_dir: str | Path,
        default_user: str = "onat",
        extra_placeholders: Optional[Mapping[str, str]] = None,
        encoding: str = "utf-8",
    ) -> None:
        self.profiles_dir = Path(profiles_dir)
        self.encoding = encoding

        # Placeholder map, e.g. {"${default_user}": "onat"}
        placeholder_map: Dict[str, str] = {
            "${default_user}": default_user,
        }
        if extra_placeholders:
            placeholder_map.update(extra_placeholders)

        self._placeholder_map = placeholder_map

        self._profiles: Dict[str, Dict[str, Any]] = {}
        self._loaded: bool = False

    # ------------------------------------------------------------------ #
    # Public API
    # ------------------------------------------------------------------ #
    def load_profiles(self, force_reload: bool = False) -> Dict[str, Dict[str, Any]]:
        """
        Load all JSON profiles from profiles_dir into memory.

        Returns a mapping:
            { profile_name: profile_dict }
        """
        if self._loaded and not force_reload:
            return copy.deepcopy(self._profiles)

        if not self.profiles_dir.exists():
            raise FileNotFoundError(
                f"Profiles directory does not exist: {self.profiles_dir}"
            )

        loaded: Dict[str, Dict[str, Any]] = {}

        for path in sorted(self.profiles_dir.glob("*.json")):
            with path.open("r", encoding=self.encoding) as f:
                raw = json.load(f)

            # Case A: file holds a single profile dict at the top level.
            # We treat it as a profile if it looks like a payload: has 'model' or 'messages'
            # or explicitly defines 'name'.
            if isinstance(raw, dict) and (
                "model" in raw or "messages" in raw or "name" in raw
            ):
                profile_name = raw.get("name") or path.stem
                processed = self._apply_placeholders(raw)
                loaded[profile_name] = processed
                continue

            # Case B: file holds multiple profiles in a mapping:
            # { "fast_chat": {...}, "code_generation": {...} }
            if isinstance(raw, dict):
                for profile_name, profile_body in raw.items():
                    if not isinstance(profile_body, dict):
                        # Skip non-dict items silently; they are not valid profiles.
                        continue
                    processed = self._apply_placeholders(profile_body)
                    loaded[profile_name] = processed
                continue

            # Anything else is considered invalid.
            raise ValueError(
                f"Unsupported JSON structure in profile file: {path}. "
                "Expected a dict representing a single profile or a dict of profiles."
            )

        self._profiles = loaded
        self._loaded = True

        return copy.deepcopy(self._profiles)

    def get_profile(self, name: str) -> Dict[str, Any]:
        """
        Return a single profile by name.

        Raises KeyError if not found.
        """
        if not self._loaded:
            self.load_profiles()

        try:
            return copy.deepcopy(self._profiles[name])
        except KeyError as exc:
            known = ", ".join(sorted(self._profiles)) or "<none>"
            raise KeyError(
                f"Unknown profile '{name}'. Known profiles: {known}"
            ) from exc

    def get_all_profiles(self) -> Dict[str, Dict[str, Any]]:
        """
        Convenience: return all loaded profiles.
        """
        if not self._loaded:
            self.load_profiles()
        return copy.deepcopy(self._profiles)

    # ------------------------------------------------------------------ #
    # Internal helpers
    # ------------------------------------------------------------------ #
    def _apply_placeholders(self, obj: Any) -> Any:
        """
        Recursively apply string placeholder substitution on a JSON-like object.
        """
        if isinstance(obj, dict):
            return {k: self._apply_placeholders(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._apply_placeholders(v) for v in obj]
        if isinstance(obj, str):
            return self._replace_in_string(obj)
        return obj

    def _replace_in_string(self, value: str) -> str:
        """
        Replace occurrences of ${...} placeholders in a string.
        """
        result = value
        for placeholder, replacement in self._placeholder_map.items():
            if placeholder in result:
                result = result.replace(placeholder, replacement)
        return result



================================================================================
FILE: C:\projects\aiAgency\core\ai_client\ai_response_parser.py
================================================================================

# core/ai_client/ai_response_parser.py
import json
from typing import Any, Dict


class AIResponseParser:
    """
    Extracts structured data (like 'code', 'context', or 'agent') from AI responses.

    Expected OpenAI response shape (chat/completions):

    {
      "choices": [
        {
          "message": {
            "role": "assistant",
            "content": <string or dict or list>
          }
        }
      ],
      ...
    }

    When using response_format = { "type": "json_object" }, the content may be:
    - a JSON string (\"{ ... }\")
    - or already a dict ( { ... } )
    """

    # ------------------------------------------------------------------ #
    # Core parsing helper
    # ------------------------------------------------------------------ #
    @staticmethod
    def _content_dict(response: Dict[str, Any]) -> Dict[str, Any]:
        """
        Safely parse message content into a dict. Returns {} on failure.

        Handles:
        - content as JSON string
        - content as already-parsed dict
        - content as list with a single JSON string or dict
        """
        try:
            message = response["choices"][0]["message"]
            content = message.get("content")
        except (KeyError, TypeError):
            return {}

        # Case 1: already a dict
        if isinstance(content, dict):
            return content

        # Case 2: JSON string
        if isinstance(content, str):
            try:
                return json.loads(content)
            except json.JSONDecodeError:
                # Not valid JSON, give up
                return {}

        # Case 3: list of parts (future-proofing; try first element)
        if isinstance(content, list) and content:
            first = content[0]
            # If first is dict and looks like JSON already
            if isinstance(first, dict) and "agent" in first:
                return first
            # If first has 'text' or 'value' we can try to load
            if isinstance(first, dict):
                text_val = first.get("text") or first.get("value")
                if isinstance(text_val, str):
                    try:
                        return json.loads(text_val)
                    except json.JSONDecodeError:
                        return {}

        # Anything else we don't recognize
        return {}

    # ------------------------------------------------------------------ #
    # Legacy code/context helpers
    # ------------------------------------------------------------------ #
    @classmethod
    def extract_code(cls, response: Dict[str, Any]) -> str:
        data = cls._content_dict(response)
        val = data.get("code", "")
        return val if isinstance(val, str) else ""

    @classmethod
    def extract_context(cls, response: Dict[str, Any]) -> str:
        data = cls._content_dict(response)
        val = data.get("context", "")
        return val if isinstance(val, str) else ""

    @classmethod
    def extract(cls, response: Dict[str, Any]) -> Dict[str, str]:
        """
        Legacy combined extractor for code + context.
        Returns: {"code": str, "context": str}
        """
        data = cls._content_dict(response)
        code = data.get("code", "")
        context = data.get("context", "")
        return {
            "code": code if isinstance(code, str) else "",
            "context": context if isinstance(context, str) else "",
        }

    # ------------------------------------------------------------------ #
    # New: agent/actions helpers
    # ------------------------------------------------------------------ #
    @classmethod
    def extract_agent(cls, response: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extract the 'agent' object from the response JSON.

        Expected shape in the model output:

        {
          "agent": {
            "name": "code_pipeline",
            "version": "v1",
            "actions": [ ... ]
          }
        }

        Returns {} if the 'agent' key is missing or invalid.
        """
        data = cls._content_dict(response)
        agent = data.get("agent", {})
        return agent if isinstance(agent, dict) else {}

    @classmethod
    def extract_actions(cls, response: Dict[str, Any]) -> list[dict]:
        """
        Convenience helper: return agent.actions[] as a list.
        Empty list if agent or actions is missing/invalid.
        """
        agent = cls.extract_agent(response)
        actions = agent.get("actions", [])
        return actions if isinstance(actions, list) else []



================================================================================
FILE: C:\projects\aiAgency\core\ai_client\api_param_generator.py
================================================================================

# === CONTEXT START ===
# Added logging to the AIParamGenerator class using BasicLogger. A logger instance
# is created in the __init__ method, and minimal logging is added to the
# build_params and send methods to log important actions.
# === CONTEXT END ===

from __future__ import annotations

from typing import Any, Dict, Mapping, MutableMapping, Optional
import copy
from core.logger import BasicLogger


class AIParamGenerator:
    """
    Builds ready-to-send payloads for OpenAI's /v1/chat/completions
    and dispatches them using an injected OpenAIClient-compatible instance.

    Presets are provided externally (e.g. from JSON via AIProfileLoader).

    Expected shape of a preset (minimal):

    {
        "model": "gpt-5-turbo",
        "temperature": 0,
        "max_output_tokens": 1200,
        "response_format": {...},   # optional
        "messages": [...],          # optional, can be overridden
        "metadata": {...},          # optional
        "user": "onat"              # optional, default_user is filled if missing
    }

    The actual keys can be any valid /v1/chat/completions payload parameters.
    """

    def __init__(
        self,
        client: Any,
        presets: Mapping[str, Mapping[str, Any]],
        default_user: str = "onat",
    ) -> None:
        self.logger = BasicLogger(self.__class__.__name__).get_logger()
        self.client = client
        self.default_user = default_user
        self._presets: Dict[str, Dict[str, Any]] = {
            name: dict(value) for name, value in presets.items()
        }

    # ------------------------------------------------------------------ #
    # Preset management
    # ------------------------------------------------------------------ #
    def set_presets(self, presets: Mapping[str, Mapping[str, Any]]) -> None:
        """
        Replace the internal preset mapping at runtime.
        """
        self._presets = {name: dict(value) for name, value in presets.items()}

    def get_preset_names(self) -> tuple[str, ...]:
        """
        Return tuple of known preset names.
        """
        return tuple(sorted(self._presets))

    def _get_base_preset(self, name: str) -> Dict[str, Any]:
        try:
            return copy.deepcopy(self._presets[name])
        except KeyError as exc:
            known = ", ".join(sorted(self._presets)) or "<none>"
            raise KeyError(
                f"Unknown preset '{name}'. Known presets: {known}"
            ) from exc

    # ------------------------------------------------------------------ #
    # Core API
    # ------------------------------------------------------------------ #
    def build_params(
        self,
        preset_name: str,
        overrides: Optional[Mapping[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Build a chat/completions payload from a preset, applying overrides.

        - Deep-merges overrides into the base preset.
        - Ensures 'user' key is present (using default_user) if missing.
        """
        self.logger.info(f"Building parameters for preset: {preset_name}")
        params = self._get_base_preset(preset_name)

        if overrides:
            self._deep_merge(params, overrides)

        if "user" not in params and self.default_user:
            params["user"] = self.default_user

        return params

    def send(
        self,
        preset_name: str,
        overrides: Optional[Mapping[str, Any]] = None,
    ) -> Any:
        """
        Build params and dispatch the request via the injected client.

        The client is expected to expose a method compatible with:
            client.post_chat_completions(payload: dict) -> dict
        Adjust this call to match your real OpenAIClient interface.
        """
        self.logger.info(f"Sending request for preset: {preset_name}")
        payload = self.build_params(preset_name, overrides=overrides)

        # Ã°Å¸â€Â§ Adjust this to your real client API:
        # e.g. self.client.create_chat_completion(**payload)
        # or    self.client.post("chat/completions", json=payload)
        return self.client.post_chat_completions(payload)

    # ------------------------------------------------------------------ #
    # Utilities
    # ------------------------------------------------------------------ #
    @classmethod
    def _deep_merge(
        cls,
        target: MutableMapping[str, Any],
        updates: Mapping[str, Any],
    ) -> None:
        """
        In-place deep merge of 'updates' into 'target'.

        - Dict values are merged recursively.
        - Non-dict values overwrite.
        - Lists are overwritten by default (you can customize if needed).
        """
        for key, value in updates.items():
            if (
                key in target
                and isinstance(target[key], dict)
                and isinstance(value, Mapping)
            ):
                cls._deep_merge(target[key], value)
            else:
                target[key] = copy.deepcopy(value)



================================================================================
FILE: C:\projects\aiAgency\core\ai_client\__init__.py
================================================================================




================================================================================
FILE: C:\projects\aiAgency\core\config\run_config.py
================================================================================

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Mapping, Optional


def _normalize_key(name: str) -> str:
    """
    Normalize JSON keys so we can accept variations like:
    profile_name, Profile_Name, profileName, etc.
    """
    return name.replace("_", "").lower()


def _get_field(
    item: Mapping[str, Any],
    logical_name: str,
    required: bool = False,
    default: Optional[Any] = None,
) -> Any:
    """
    Fetch a field from a JSON object in a tolerant way:
    - Treat 'Profile_Name', 'profile_name', 'profilename' as the same.
    """
    target = _normalize_key(logical_name)

    for key, value in item.items():
        if _normalize_key(key) == target:
            return value

    if required:
        raise ValueError(f"Missing required field '{logical_name}' in run item: {item}")
    return default


@dataclass
class RunItem:
    """
    A single run/task configuration.
    """
    profile_name: str
    class_name: str
    task_description: str
    refactor_class: str = ""
    raw: Dict[str, Any] = None  # full raw dict for future use


class RunConfig:
    """
    Parses a JSON config file describing one or more runs.

    Supported root structures:

    1) { "runs": [ { ... }, { ... } ] }
    2) [ { ... }, { ... } ]
    """

    def __init__(self, runs: List[RunItem]) -> None:
        self.runs = runs

    @staticmethod
    def from_file(path: str) -> "RunConfig":
        file_path = Path(path)
        if not file_path.exists():
            raise FileNotFoundError(f"Config file not found: {path}")

        with file_path.open("r", encoding="utf-8") as f:
            data = json.load(f)

        return RunConfig._parse(data)

    @staticmethod
    def _parse(data: Any) -> "RunConfig":
        if isinstance(data, dict):
            if "runs" in data and isinstance(data["runs"], list):
                items = data["runs"]
            else:
                # Single run as object
                items = [data]
        elif isinstance(data, list):
            items = data
        else:
            raise ValueError("Config root must be an object or an array.")

        runs: List[RunItem] = []

        for idx, item in enumerate(items, start=1):
            if not isinstance(item, dict):
                raise ValueError(f"Run #{idx} must be an object, got: {type(item)}")

            profile_name = _get_field(item, "profile_name", required=True)
            class_name = _get_field(item, "class_name", required=True)
            task_description = _get_field(item, "task_description", required=True)
            refactor_class = _get_field(item, "refactor_class", required=False, default="")

            # Heuristic: for refactor-type profiles, if no explicit refactor_class is
            # provided, assume we refactor the same file as class_name.
            if not refactor_class and "refactor" in str(profile_name).lower():
                refactor_class = class_name

            runs.append(
                RunItem(
                    profile_name=str(profile_name),
                    class_name=str(class_name),
                    task_description=str(task_description),
                    refactor_class=str(refactor_class),
                    raw=dict(item),
                )
            )

        return RunConfig(runs)



================================================================================
FILE: C:\projects\aiAgency\core\files\class_generator.py
================================================================================

# === CONTEXT START ===
# Added logging to the ClassGenerator class using BasicLogger. A logger instance
# is created in the __init__ method, and an info log is added in the generate
# method to log when a file is being generated.
# === CONTEXT END ===

# === CONTEXT START ===
# The ClassGenerator class is responsible for writing Python source code to disk
# and ensuring that generated files are saved in a clean, structured, and
# predictable way. It serves as the main output layer of the AI-driven
# code-generation pipeline, receiving raw code strings from the model and
# converting them into .py files located within the configured project
# directory.
#
# The class provides two modes of operation: a basic file-generation method that
# writes code exactly as received, and an enhanced method that automatically
# prefixes the file with a formatted CONTEXT block. This comment block embeds
# human-readable metadata or explanation produced by the AI, wrapped to 80
# characters for readability and delimited with START and END markers. This
# allows each generated file to carry its own reasoning, intent, or description,
# which becomes valuable for future maintenance, refactoring, and tracing logic.
#
# To maintain portability and prevent unexpected filesystem errors, the class
# guarantees that the target output directory is created on initialization. It
# performs no interpretation of the code itself; its sole responsibility is to
# accurately persist the given content to the filesystem in a clean and
# repeatable manner, forming the foundation for downstream processes such as Git
# commits or subsequent model iterations.
# === CONTEXT END ===

import os
import textwrap
from typing import Optional
from core.logger import BasicLogger

class ClassGenerator:
    """
    Generates a .py file from a provided string at the specified path.
    """

    def __init__(self, base_path: str):
        """
        Initialize the file generator with the base path for output.
        :param base_path: Directory where the .py file will be created.
        """
        self.logger = BasicLogger(self.__class__.__name__).get_logger()
        self.base_path = os.path.abspath(base_path)
        os.makedirs(self.base_path, exist_ok=True)

    def _build_comment_block(self, comments: str) -> str:
        """
        Build a readable, wrapped, multi-line Python comment block.
        Long lines are wrapped at ~80 characters for readability.
        """
        if not comments or not comments.strip():
            return ""

        # Wrap long text into multiple lines (80 chars per line)
        wrapped = textwrap.fill(comments.strip(), width=80)
        lines = wrapped.split("\n")

        header = ["# === CONTEXT START ==="]
        header.extend(f"# {line}" for line in lines)
        header.append("# === CONTEXT END ===")
        header.append("")  # blank line after the block

        return "\n".join(header)

    def generate(self, filename: str, content: str) -> str:
        """
        Writes the given string content to a .py file in the base path.
        :param filename: Name of the file (without .py extension).
        :param content: Python source code to write.
        :return: Full path of the generated file.
        """
        self.logger.info(f"Generating file: {filename}")
        if not filename.endswith(".py"):
            filename = f"{filename}.py"

        full_path = os.path.join(self.base_path, filename)

        with open(full_path, "w", encoding="utf-8") as f:
            f.write(content)

        return full_path

    def generate_with_comments(self, filename: str, content: str, comments: Optional[str] = None) -> str:
        """
        Writes the given content to a .py file, optionally prefixed with a
        formatted comment block built from the provided comments string.
        """
        if comments:
            comment_block = self._build_comment_block(comments)
            content = f"{comment_block}\n{content}"

        return self.generate(filename, content)



================================================================================
FILE: C:\projects\aiAgency\core\files\class_reader.py
================================================================================

# === CONTEXT START ===
# The PythonFileReader class provides a simple and reliable utility for loading
# Python source files from disk and returning their contents as a raw string.
# It ensures that the requested file actually exists and validates that the
# target is a .py file before attempting to read it.
#
# This class is used by the AI-driven development framework when existing Python
# files need to be ingested, analyzed, or passed back to the model for
# refactoring. By centralizing file reading logic, the codebase avoids repetitive
# I/O operations throughout different components and maintains consistent error
# handling for missing or invalid file paths.
#
# The implementation intentionally avoids any post-processing or parsing of the
# file's content. It returns the exact text of the file as-is, preserving
# formatting, comments, and structure so that downstream processes â€” such as
# code generation, diffing, or context injection â€” receive the full and accurate
# representation of the original source.
# === CONTEXT END ===


import os

class PythonFileReader:
    def __init__(self, file_path):
        self.file_path = file_path

    def read_file(self):
        if not os.path.isfile(self.file_path):
            raise FileNotFoundError(f"The file {self.file_path} does not exist.")
        if not self.file_path.endswith('.py'):
            raise ValueError("The file is not a Python (.py) file.")
        with open(self.file_path, 'r') as file:
            return file.read()

# Example usage:
# reader = PythonFileReader('example.py')
# code_string = reader.read_file()
# print(code_string)



================================================================================
FILE: C:\projects\aiAgency\core\files\__init__.py
================================================================================




================================================================================
FILE: C:\projects\aiAgency\core\git\commit_message_builder.py
================================================================================

# === CONTEXT START ===
# The CommitMessageBuilder class is designed to create standardized commit
# messages for version control systems. It includes a static method 'build' that
# constructs a commit message using the file name, a short description, a detailed
# context, and the author's name. This utility can be used to ensure consistency
# in commit messages across a project.
# === CONTEXT END ===

class CommitMessageBuilder:
    """
    A utility class to build commit messages for version control.
    """

    @staticmethod
    def build(file_path: str, context: str, author: str = "AI_Agent") -> str:
        """
        Builds a formatted commit message.

        :param file_path: The path of the file being committed.
        :param context: A detailed, multi-line description of the changes.
        :param author: The author of the commit, default is 'AI_Agent'.
        :return: A formatted commit message string.
        """
        filename = file_path.split('/')[-1]
        short_description = f"Update {filename}"
        commit_message = f"{short_description}\n\n{context}\n\nAuthor: {author}"
        return commit_message



================================================================================
FILE: C:\projects\aiAgency\core\git\git_client.py
================================================================================

# === CONTEXT START ===
# Added logging to the GitClient class using BasicLogger. Each method now logs its
# main action, providing traceability for operations performed by the class.
# === CONTEXT END ===

import subprocess
from typing import Union
from core.logger import BasicLogger

class GitClient:
    def __init__(self, repo_path: str):
        """Initialize the GitClient with the path to the repository."""
        self.repo_path = repo_path
        self.logger = BasicLogger(self.__class__.__name__).get_logger()

    def _run_git_command(self, *args: str) -> str:
        self.logger.info(f'Running git command: {args}')
        try:
            result = subprocess.run(
                ['git'] + list(args),
                cwd=self.repo_path,
                text=True,
                capture_output=True,
                check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as exc:
            stdout_msg = (exc.stdout or "").strip()
            stderr_msg = (exc.stderr or "").strip()

            if stdout_msg:
                self.logger.error(f"Git stdout (cmd: {args}): {stdout_msg}")
            if stderr_msg:
                self.logger.error(f"Git stderr (cmd: {args}): {stderr_msg}")

            # Re-raise so the caller still gets the failure
            raise



    def init_repo(self) -> None:
        """Initialize a new git repository."""
        self.logger.info('Initializing repository')
        self._run_git_command('init')

    def add(self, paths: Union[list[str], str]) -> str:
        """Add file contents to the index."""
        self.logger.info(f'Adding paths: {paths}')
        if isinstance(paths, str):
            paths = [paths]
        return self._run_git_command('add', *paths)

    def commit(self, message: str) -> str:
        """Record changes to the repository with a commit message."""
        self.logger.info(f'Committing with message: {message}')
        return self._run_git_command('commit', '-m', message)

    def push(self, remote: str = "origin", branch: str = "master") -> str:
        """Update remote refs along with associated objects."""
        self.logger.info(f'Pushing to {remote}/{branch}')
        return self._run_git_command('push', remote, branch)

    def pull(self, remote: str = "origin", branch: str = "master") -> str:
        """Fetch from and integrate with another repository or a local branch."""
        self.logger.info(f'Pulling from {remote}/{branch}')
        return self._run_git_command('pull', remote, branch)

    def checkout(self, branch: str, create_if_missing: bool = False) -> str:
        """Switch branches or restore working tree files."""
        self.logger.info(f'Checking out branch: {branch}, create if missing: {create_if_missing}')
        if create_if_missing:
            return self._run_git_command('checkout', '-b', branch)
        return self._run_git_command('checkout', branch)

    def status(self) -> str:
        """Show the working tree status."""
        self.logger.info('Getting status')
        return self._run_git_command('status')

    def get_current_branch(self) -> str:
        """Get the name of the current branch."""
        self.logger.info('Getting current branch')
        return self._run_git_command('rev-parse', '--abbrev-ref', 'HEAD')



================================================================================
FILE: C:\projects\aiAgency\core\git\git_manager.py
================================================================================

# core/git/git_manager.py

# === CONTEXT START ===
# The GitManager class provides a higher-level orchestration layer for handling
# version-control operations within the AI-driven code-generation workflow.
# === CONTEXT END ===

from typing import Optional
from core.git.git_client import GitClient  # adjust path if different


class GitManager:
    def __init__(self, git_client: GitClient) -> None:
        self.git_client = git_client

    def prepare_branch(self, branch: str) -> None:
        """
        Checkout the specified branch using the GitClient.
        """
        self.git_client.checkout(branch)

    def commit_generated_file(self, file_path: str, context: str) -> str:
        """
        Add the specified file and commit it with a message including the context.

        :param file_path: Path to the file to be committed.
        :param context: Context to include in the commit message.
        :return: The commit hash or output returned by the GitClient.
        """
        self.git_client.add(file_path)
        commit_message = f"Add/update generated file {file_path}. Context: {context[:120]}"
        return self.git_client.commit(commit_message)

    def sync_with_remote(self, remote: str = "origin", branch: str = "master") -> None:
        """
        Pull the latest changes from the specified remote and branch.
        """
        self.git_client.pull(remote, branch)

    def auto_push(self, commit_message: str, context: str = "") -> None:
        """
        Commit with the provided message and push to the remote.
        """
        full_message = (
            f"{commit_message}. Context: {context[:120]}" if context else commit_message
        )
#        self.git_client.commit(full_message)
        self.git_client.push("origin", "master")



================================================================================
FILE: C:\projects\aiAgency\core\git\repo_config.py
================================================================================

# === CONTEXT START ===
# This code defines a Python data class named RepoConfig using the @dataclass
# decorator. It includes type hints for each field and a class-level docstring
# that describes the purpose of the class and its attributes. Default values are
# provided for all fields except repo_path.
# === CONTEXT END ===

from dataclasses import dataclass

@dataclass
class RepoConfig:
    """
    Configuration for a repository.

    Attributes:
        repo_path (str): The file path to the repository.
        default_branch (str): The default branch of the repository. Defaults to 'master'.
        remote_name (str): The name of the remote. Defaults to 'origin'.
        author_name (str): The name of the author. Defaults to 'AI Agent'.
        author_email (str): The email of the author. Defaults to 'ai@example.com'.
    """
    repo_path: str
    default_branch: str = "master"
    remote_name: str = "origin"
    author_name: str = "AI Agent"
    author_email: str = "ai@example.com"



================================================================================
FILE: C:\projects\aiAgency\core\services\refactor_service.py
================================================================================

# === CONTEXT START ===
# Added logging to the RefactorService class using BasicLogger. A logger instance
# is created in the __init__ method, and an info log is added in the
# build_messages method to indicate when message building starts.
# === CONTEXT END ===

from core.files.class_reader import PythonFileReader
from core.logger import BasicLogger

class RefactorService:
    """
    Prepares refactor messages for the model by injecting file content
    and optional class name hints into a clean, deterministic message structure.
    """

    def __init__(self, file_path: str, class_name: str | None = None):
        self.logger = BasicLogger(self.__class__.__name__).get_logger()
        self.file_path = file_path
        self.class_name = class_name

    def build_messages(self) -> list[dict]:
        self.logger.info('Building messages for refactoring')
        reader = PythonFileReader(self.file_path)
        content = reader.read_file()

        class_hint = (
            f"\nFocus on improving the class named `{self.class_name}`.\n"
            if self.class_name else ""
        )

        system_msg = {
            "role": "system",
            "content": (
                "You are a senior Python engineer. Refactor the provided code into a "
                "clean, maintainable, readable, idiomatic form. Preserve external "
                "behavior and public API. Do not add comments explaining changes."
            )
        }

        user_msg = {
            "role": "user",
            "content": (
                f"Refactor the following file.{class_hint}\n"
                "Return ONLY the final refactored Python code.\n\n"
                "```python\n"
                f"{content}\n"
                "```"
            )
        }

        return [system_msg, user_msg]



================================================================================
FILE: C:\projects\aiAgency\core\utils\file_index_generator.py
================================================================================

# === CONTEXT START ===
# Class that scans a base directory and builds a universal file index for all
# files, excluding only files named .gitignore.
# === CONTEXT END ===

from pathlib import Path
from typing import Union, Dict, Any

class FileIndexGenerator:
    def __init__(self, base_directory: Union[str, Path]):
        self.base_directory = Path(base_directory)

    def build_index(self) -> Dict[str, Any]:
        if not self.base_directory.exists():
            return {"files": []}

        files = []
        for file in self.base_directory.rglob('*'):
            if file.is_file() and file.name != '.gitignore':
                try:
                    files.append({
                        "name": file.name,
                        "relative_path": str(file.relative_to(self.base_directory)),
                        "absolute_path": str(file.resolve()),
                        "extension": file.suffix,
                        "size": file.stat().st_size
                    })
                except (OSError, PermissionError):
                    continue

        files.sort(key=lambda x: x["relative_path"])
        return {"files": files}



================================================================================
FILE: C:\projects\aiAgency\core\utils\generate_path_index.py
================================================================================

# === CONTEXT START ===
# Class that generates a path index for all files in a given directory, excluding
# files listed in .gitignore, and saves the index to a JSON file.
# === CONTEXT END ===

class PathIndexGenerator:
    def __init__(self, base_path):
        self.base_path = base_path
        self.index = {}

    def generate_index(self):
        import os
        for root, dirs, files in os.walk(self.base_path):
            for file in files:
                if file != '.gitignore':
                    file_path = os.path.join(root, file)
                    self.index[file_path] = os.path.getsize(file_path)
        return self.index

    def save_index(self, output_file):
        import json
        with open(output_file, 'w') as f:
            json.dump(self.index, f, indent=4)



================================================================================
FILE: C:\projects\aiAgency\profiles\code_generation.json
================================================================================

{
  "name": "code_generation",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 1200,

  "task_description": "Create a basic py calculator",

  "messages": [
    {
      "role": "system",
      "content": "You are a senior software engineer acting as an AI code agent inside an automated pipeline.\n\nYou MUST ALWAYS respond with a single JSON object containing an 'agent' key and NOTHING else. No markdown, no prose, no backticks.\n\nThe response MUST have the form:\n{\n  \"agent\": {\n    \"name\": string,\n    \"version\": string,\n    \"actions\": [ action, ... ]\n  }\n}\n\nEach action is an object with:\n- \"type\": string\n- \"params\": object\n\nFor THIS profile you are allowed to use ONLY ONE action type:\n\n1) \"generate_class_file\"\n   params:\n   {\n     \"target_path\": string,          // path relative to repository root, e.g. \"core/utils/file_index_generator.py\"\n     \"code\": string,                 // complete Python source code for the FileIndexGenerator class\n     \"context\": string               // human-readable explanation; will be embedded into CONTEXT comments\n   }\n\nHARD CONSTRAINTS FOR THE GENERATED CODE (NON-NEGOTIABLE):\n\n1) CLASS NAME\n- You MUST define exactly ONE public class.\n- The class name MUST be exactly: FileIndexGenerator\n- You MUST NOT use any other class name (no PathIndexGenerator, no variations).\n\n2) IMPORTS AND FILESYSTEM API\n- You MUST NOT import or use the 'os' module at all.\n  - NO 'import os'\n  - NO 'os.walk(...)'\n  - NO 'os.path.join(...)'\n  - NO 'os.path' usage of any kind.\n- You MUST use 'pathlib.Path' exclusively for all filesystem operations.\n\n3) BEHAVIOR\n- The class MUST recursively scan a base directory and build a universal file index of ALL files.\n- Include ALL file types: .py, .json, .txt, .md, .env, binary files, images, configs, and any other extension.\n- EXCLUDE ONLY files whose NAME is exactly '.gitignore'.\n  - Do NOT parse .gitignore contents.\n  - Do NOT interpret ignore patterns.\n  - The only exclusion rule is: skip files where name == '.gitignore'.\n\n4) OUTPUT STRUCTURE\n- Implement the following interface:\n\n  from pathlib import Path\n  from typing import Union, Dict, Any\n\n  class FileIndexGenerator:\n      def __init__(self, base_directory: Union[str, Path]):\n          ...\n\n      def build_index(self) -> Dict[str, Any]:\n          \"\"\"\n          Returns a dictionary of the form:\n          {\n              \"files\": [\n                  {\n                      \"name\": str,\n                      \"relative_path\": str,\n                      \"absolute_path\": str,\n                      \"extension\": str,\n                      \"size\": int,\n                      ... (optional extra fields)\n                  },\n                  ...\n              ]\n          }\n          \"\"\"\n          ...\n\n- In build_index(), you MUST:\n  - Use 'Path(base_directory)' as the starting point.\n  - Use Path(base_directory).rglob('*') (or equivalent Path methods) to scan recursively.\n  - For each file (excluding '.gitignore') populate at least:\n    - name          -> file.name\n    - relative_path -> string path relative to base_directory\n    - absolute_path -> string with resolved absolute path\n    - extension     -> file.suffix (may be \"\" if no extension)\n    - size          -> file.stat().st_size\n  - Sort the resulting list of files by 'relative_path' for deterministic output.\n  - If a file cannot be read (e.g. permission error), skip it gracefully and continue.\n  - If the base directory does not exist, either:\n    - return {\"files\": []}, OR\n    - raise a clean, explicit exception like ValueError with a clear message.\n\n5) COMPLETENESS\n- You MUST fully implement all required methods.\n- NO 'pass'.\n- NO TODO comments.\n- NO placeholder logic.\n- NO stub implementations.\n\n6) SCOPE\n- You MUST NOT generate additional public classes or utilities.\n- You MUST focus solely on FileIndexGenerator and its required behavior.\n\nThe code you generate in 'code' MUST strictly follow these constraints and the final user instruction (task_description). You MUST NOT rename the class, you MUST NOT use 'os'/'os.path', and you MUST NOT leave any method body incomplete.\n\nDecision rules:\n- When the user asks you to generate or refactor code, you MUST return AT LEAST ONE 'generate_class_file' action.\n- The 'actions' array MUST NOT be empty in that case.\n- Do NOT create any git-related actions for this profile. Do NOT use any action type other than 'generate_class_file'.\n\nOutput rules:\n- Do NOT invent new action types.\n- Do NOT output markdown.\n- Do NOT wrap the JSON in backticks.\n- Do NOT include any text outside the single JSON object.\n\nExample (illustrative only):\n{\n  \"agent\": {\n    \"name\": \"CodeGenerationAgent\",\n    \"version\": \"1.0\",\n    \"actions\": [\n      {\n        \"type\": \"generate_class_file\",\n        \"params\": {\n          \"target_path\": \"core/utils/file_index_generator.py\",\n          \"code\": \"class FileIndexGenerator:\\n    ...\",\n          \"context\": \"Class that scans a base directory and builds a universal file index for all files, excluding only files named .gitignore.\"\n        }\n      }\n    ]\n  }\n}"
    },
    {
      "role": "user",
      "content": "Runtime input for this request, as JSON:\n\n${agent_input}\n\nUse 'agent_input' and the next instruction to decide which actions to perform."
    },
    {
      "role": "user",
      "content": "${task_description}"
    }
  ],

  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



================================================================================
FILE: C:\projects\aiAgency\profiles\code_refactor.json
================================================================================

{
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 2000,
  "messages": [
    {
      "role": "system",
      "content": "You are a senior software engineer. Produce clean, correct code and minimal explanations. Your answer must be formatted strictly as JSON with two keys: 'code' and 'context'. Example: {\"code\": \"...\", \"context\": \"...\"}. Do not include anything else outside this JSON structure."
    },
    {
      "role": "user",
      "content": "You will receive a Python file. Your task is to inject logging into each class using the BasicLogger utility.\n\nRules:\n- Assume BasicLogger is available as: from core.logger import BasicLogger.\n- For every class that does not have a logger yet, add an instance attribute in __init__:\n\n    self.logger = BasicLogger(self.__class__.__name__).get_logger()\n\n- Do NOT change the public behaviour of methods.\n- Do NOT modify the BasicLogger implementation itself.\n- You MAY add one or two self.logger.info(...) calls in important methods, but keep it minimal.\n- Keep the rest of the code structure the same (imports, classes, methods).\n\nHere is the usage pattern (for reference only, do not duplicate this verbatim):\n\n# Example of how to implement the logger in another class:\n#\n# class MyClass:\n#     def __init__(self):\n#         self.logger = BasicLogger(self.__class__.__name__).get_logger()\n#\n#     def do_something(self):\n#         self.logger.info('Doing something')\n#\n# my_instance = MyClass()\n# my_instance.do_something()"
    },
    {
      "role": "user",
      "content": "Here is the current code:\n```python\n${class_content}\n```"
    }
  ],
  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}



================================================================================
FILE: C:\projects\aiAgency\profiles\framework_action_generator.json
================================================================================

{
  "name": "framework_action_generator",
  "model": "gpt-4o",
  "temperature": 0,
  "top_p": 1,
  "max_tokens": 1600,

  "task_description": "Generate a new action class module under core/actions/generate_test_file.py.\n\nRequirements:\n- Define class GenerateTestFileAction(BaseAction) with action_type = \"generate_test_file\".\n- Expected params in self.params:\n  {\n    \"target_path\": string,   // e.g. \"tests/test_calculator.py\"\n    \"code\": string,          // full test source code\n    \"context\": string        // explanation of what is being tested\n  }\n\nvalidate(self):\n- Return True only if target_path is a non-empty string and code is a non-empty string.\n\nexecute(self, ctx):\n- Resolve target_path relative to ctx.project_root via pathlib.Path.\n- Ensure parent directory exists (mkdir(parents=True, exist_ok=True)).\n- Use ctx.class_generator to write the file with a CONTEXT header:\n  - Temporarily set class_generator.base_path to the parent directory of target_path.\n  - Call generate_with_comments(filename=<basename>, content=code, comments=context).\n  - Restore original base_path.\n- Log an info message with the absolute path of the generated test file.\n\nRegistration:\n- At the bottom of the module, import ActionRegistry and register the action:\n  from .registry import ActionRegistry\n  ActionRegistry.register(GenerateTestFileAction)\n\nCoding style:\n- Type annotate validate/execute methods.\n- Use clear variable names and logging messages.\n- No unused imports.\n\nRefactor logic for existing action modules:\n- If agent_input.refactor.original_code is provided for an existing action module (e.g. you are updating GenerateTestFileAction rather than creating it from scratch):\n  - Preserve the public contract: action_type value, ActionRegistry.register(...) call, and expected params structure.\n  - You MAY improve implementation details, logging, validation, or comments.\n  - Do NOT change the meaning of existing parameters or the overall behaviour of the action.\n  - The goal is to refine the action, not to break callers.",

  "messages": [
    {
      "role": "system",
      "content": "You are a senior Python engineer working on an AI-driven code-generation framework called aiAgency.\nYour task is to produce COMPLETE, standalone Python modules for internal framework actions, using an action-based response format.\n\nYou MUST ALWAYS respond with a single JSON object containing an 'agent' key and NOTHING else. No markdown, no prose, no backticks.\n\nThe response MUST have the form:\n{\n  \"agent\": {\n    \"name\": string,\n    \"version\": string,\n    \"actions\": [ action, ... ]\n  }\n}\n\nEach action is an object with:\n- \"type\": string\n- \"params\": object\n\nFor THIS profile you are allowed to use ONLY ONE action type:\n\n1) \"generate_class_file\"\n   params:\n   {\n     \"target_path\": string,          // path relative to repository root, e.g. \"core/actions/generate_test_file.py\"\n     \"code\": string,                 // full Python module source code for the action\n     \"context\": string               // short explanation of responsibilities and key design decisions\n   }\n\nBehaviour:\n- When creating a NEW action module:\n  - Use 'agent_input.class_name' as the default target_path if it is present (e.g. \"core/actions/generate_test_file.py\").\n  - Generate a complete, standalone Python module that subclasses BaseAction, sets action_type, implements validate/execute, and registers itself via ActionRegistry.register(...).\n\n- When REFACTORING an existing action module (agent_input.refactor.original_code is present):\n  - Treat it as an update of the existing module.\n  - Preserve the public contract: action_type value, registration call, and expected params structure.\n  - You MAY improve implementation, logging, validation, and internal structure following the user instructions.\n  - Do NOT break existing callers.\n\nDecision rules:\n- For this profile, you MUST return AT LEAST ONE 'generate_class_file' action containing the full module code.\n- The 'actions' array MUST NOT be empty.\n- Do NOT invent any other action types for this profile.\n\nOutput rules:\n- Do NOT invent new action types.\n- Do NOT output markdown.\n- Do NOT wrap the JSON in backticks.\n- Do NOT include any text outside the single JSON object.\n\nExample shape (illustrative only):\n{\n  \"agent\": {\n    \"name\": \"FrameworkActionGenerator\",\n    \"version\": \"1.0\",\n    \"actions\": [\n      {\n        \"type\": \"generate_class_file\",\n        \"params\": {\n          \"target_path\": \"core/actions/generate_test_file.py\",\n          \"code\": \"<full Python module>\",\n          \"context\": \"Action that generates test files based on provided code and target path.\"\n        }\n      }\n    ]\n  }\n}"
    },
    {
      "role": "user",
      "content": "Runtime input for this request, as JSON:\n\n${agent_input}\n\nUse 'agent_input' to decide whether you are creating a new module (no refactor.original_code) or updating an existing one (refactor.original_code present)."
    },
    {
      "role": "user",
      "content": "${task_description}"
    }
  ],

  "response_format": { "type": "json_object" },
  "user": "${default_user}"
}


